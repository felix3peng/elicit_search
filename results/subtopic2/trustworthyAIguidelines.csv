Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
An agile framework for trustworthy AI,The AI High Level Expert Group (AI-HLEG) ethics guidelines present a list of requirements that trustworthy AI systems should meet.,Search,2020,2,"Stefan  Leijnen, Huib  Aldewereld, Rudy van Belkom, Roland  Bijvank, Roelant  Ossewaarde",NeHuAI@ECAI,,,,https://semanticscholar.org/paper/880049a16c8fea47dcfe07450668f5507db5e96d,,"From the article: The ethics guidelines put forward by the AI High Level Expert Group (AI-HLEG) present a list of seven key requirements that Human-centered, trustworthy AI systems should meet. These guidelines are useful for the evaluation of AI systems, but can be complemented by applied methods and tools for the development of trustworthy AI systems in practice. In this position paper we propose a framework for translating the AI-HLEG ethics guidelines into the specific context within which an AI system operates. This approach aligns well with a set of Agile principles commonly employed in software engineering. http://ceur-ws.org/Vol-2659/",,
Establishing the rules for building trustworthy AI,The European Commission’s report ‘Ethics guidelines for trustworthy AI’ facilitates international support for AI solutions that are good for humanity and the environment.,Search,2019,67,Luciano  Floridi,Nature Machine Intelligence,,10.1038/S42256-019-0055-Y,https://doi.org/10.1038/S42256-019-0055-Y,https://semanticscholar.org/paper/dc44e2be0f85b6225f05390c570885337a99ef83,https://philpapers.org/archive/FLOETR.pdf,"The European Commission’s report ‘Ethics guidelines for trustworthy AI’ provides a clear benchmark to evaluate the responsible development of AI systems, and facilitates international support for AI solutions that are good for humanity and the environment, says Luciano Floridi.",,
Comments on the “Draft Ethics Guidelines for Trustworthy AI” by the High-LevelExpert Group on Artificial Intelligence.,The European Commission appointed the High-Level Expert Group on Artificial Intelligence.,Search,2019,49,Ninja  Marnau,,,,,https://semanticscholar.org/paper/01040c2897ea82bb801931dbfe8a85a3b64d2e7f,,"The European Commission appointed the High-Level Expert Group on Artificial Intelligence (AI HLEG). The AI HLEG has the objective to support the implementation of the European strategy on Artificial Intelligence. This will include the elaboration of recommendations on future-related policy development and on ethical, legal and societal issues related to AI. In January 2019, the Commission asked stakeholders for comments on the AI HLEG’s “Draft Ethics Guidelines for Trustworthy AI”. CISPA submitted the following comments and remarks in the Stakeholders’ Consultation.",,
The Ethical Guidelines for Trustworthy AI – A Procrastination of Effective Law Enforcement,The Ethical Guidelines for Trustworthy Artificial Intelligence by the EU Commission are ineffective.,Search,2019,2,Ramak Molavi Vasse’i,Computer Law Review International,,10.9785/cri-2019-200502,https://doi.org/10.9785/cri-2019-200502,https://semanticscholar.org/paper/64223e4aa1a20a6406cd036417245385b6b33cc0,,"In the august issue of the CRi, Nathalie Smuha, the coordinator of the work of the High-Level Expert Group on AI, outlined the approach and considerations leading to the “The EU Approach to Ethics Guidelines for Trustworthy Artificial Intelligence”. This paper provides a critical assessment of the Ethical Guidelines of the EU Commission and points out why a law enforcement focused approach must be the essential next step towards a beneficial and humane development of AI. Questioning the diversity of the Commssion’s High Level Expert Group on Artificial Intelligence, the dangers of ethics shopping are exposed as well as the UN Universal Declaration of Human Rights explored as already well established alternative reference framework for AI. Having exposed the need for effective red lines, not only the hidden social and ecological cost are assessed, but also the risk of “buying-out” research and other ethical issues neglected in the Ethics Guidelines for Trustworthy Artificial Intelligence. Finally, three key weaknesses concerning the crucial translation of ethical principles into practice (enforcement) are highlighted.",,
GSMA Response to the Draft Ethics Guidelines for Trustworthy AI,The development and deployment of AI systems should respect fundamental human rights and applicable regulation.,Search,2019,10,,,,,,https://semanticscholar.org/paper/0a87bcc17b0f385ed52cae4b4bfb235256f88eb3,,"Introduction The GSMA supports the European Commission’s endeavour to maximise the benefits of artificial intelligence (AI) while minimising the risks to individuals and communities, and appreciates the opportunity to comment on the Commission’s new draft ethics guidelines. We support the view that the development and deployment of AI systems should respect fundamental human rights and applicable regulation, as well as principles and values ensuring an ‘ethical purpose’. A growing number of GSMA members have already committed to responsible development of AI technologies.",,
The EU Approach to Ethics Guidelines for Trustworthy Artificial Intelligence,The EU Commission established an independent High-Level Expert Group on Artificial Intelligence (AI HLEG).,Search,2019,56,Nathalie A. Smuha,Computer Law Review International,,10.9785/cri-2019-200402,https://doi.org/10.9785/cri-2019-200402,https://semanticscholar.org/paper/a00ee7ae4642b986b622e0f48c845e79707b707b,https://lirias.kuleuven.be/bitstream/123456789/640572/2/EU%20Approach%20for%20Trustworthy%20AI%20-%20a%20continuous%20journey.pdf,"As part of its European strategy for Artificial Intelligence (AI), and as a response to the increasing ethical questions raised by this technology, the European Commission established an independent High-Level Expert Group on Artificial Intelligence (AI HLEG) in June 2018. The group was tasked to draft two deliverables: AI Ethics Guidelines and Policy and Investment Recommendations. Nine months later, its first deliverable was published, putting forward a comprehensive framework to achieve “Trustworthy AI” by offering ethical guidance to AI practitioners. This paper dives into the work carried out by the group, focusing in particular on its AI Ethics Guidelines. First, this paper clarifies the context that led to the creation of the AI HLEG and its mandate (I.). Subsequently, it elaborates on the Guidelines’ aim and purpose (II.), and analyses the Guidelines’ drafting process (III.). Particular focus is given to the questions surrounding the respective role played by ethics and law in the AI governance landscape (IV.), as well as some of the challenges that had to be overcome throughout the process (V.). Finally, this paper places the Guidelines in an international context, and sets out the next steps (VI.) ahead on the journey towards an appropriate governance framework for AI (VII.).",,
Trustworthy AI Development Guidelines for Human System Interaction,AI development guidelines can improve the user trust in AI systems to enhance human-AI interactions.,Search,2020,3,"Chathurika S. Wickramasinghe, Daniel L. Marino, Javier  Grandio, Milos  Manic",2020 13th International Conference on Human System Interaction (HSI),,10.1109/HSI49210.2020.9142644,https://doi.org/10.1109/HSI49210.2020.9142644,https://semanticscholar.org/paper/238fa66062114f39e404c40d0b1abc03b86e54bd,,"Artificial Intelligence (AI) is influencing almost all areas of human life. Even though these AI-based systems frequently provide state-of-the-art performance, humans still hesitate to develop, deploy, and use AI systems. The main reason for this is the lack of trust in AI systems caused by the deficiency of transparency of existing AI systems. As a solution, “Trustworthy AI” research area merged with the goal of defining guidelines and frameworks for improving user trust in AI systems, allowing humans to use them without fear. While trust in AI is an active area of research, very little work exists where the focus is to build human trust to improve the interactions between human and AI systems. In this paper, we provide a concise survey on concepts of trustworthy AI. Further, we present trustworthy AI development guidelines for improving the user trust to enhance the interactions between AI systems and humans, that happen during the AI system life cycle.",,
Guidelines for Trustworthy AI application in clinical trials,The European Commission established the High-Level Expert Group on Artificial Intelligence (AI HLEG).,Search,2020,,"N  Leventi, A  Vodenitcharova, K  Popova",,,10.1093/eurpub/ckaa165.806,https://doi.org/10.1093/eurpub/ckaa165.806,https://semanticscholar.org/paper/29898969890b3d4d8a5813a6750d308b3fb7117e,https://academic.oup.com/eurpub/article-pdf/30/Supplement_5/ckaa165.806/33817815/ckaa165.806.pdf,"Innovative information technologies (IIT) like artificial intelligence (AI), big data, etc. promise to support individual patient care, and promote public health. Their use raises ethical, social and legal issues. Here we demonstrate how the guidelines for trustworthy AI, can assist to answer those ethical issues in the case of clinical trials (CT).

In 2018 the European Commission established the High-Level Expert Group on Artificial Intelligence (AI HLEG). The group proposed Guidelines to promote Trustworthy AI, with three components, which should be met throughout the system's entire life cycle, as it should be lawful, ethical and robust.

Trustworthiness is a prerequisite for people and societies to develop, and use AI systems. We used a focus group methodology to explore how the guidelines for trustworthy AI can assist to answer the ethical issues that rise by the application of AI in CTs.

The discussion was directed to the seven requirements for trustworthy AI in CTs, by questions like:

Are they relevant in CTs as a whole? Would they be applicable to the use of IIT as AI in CTs? Are you currently applying part, or all, of the proposed list? In the future, would you attach some, or all, of the proposed list? Is the administrative burden of applying the requirements justified by the effect?

It was recommended that:

the guidelines are relevant in the conduct of the CT; planning and implementation of CTs using IIT, should take them into account; ethical aspects and challenges are of the utmost importance; the proposed list is a very comprehensive framework; particular attention should be paid where more vulnerable groups are affected; the administrative burden is acceptable, as the effect exceeds the resources invested.

IIT are becoming increasingly important in medicine, and requirements for trustworthy IIT, and AI are necessary. Appropriate instrument in the case of the CTs are the provided by AI HLEG guidelines.",,
Trustworthy AI and Corporate Governance – The EU’s Ethics Guidelines For Trustworthy Artificial Intelligence from a Company Law Perspective,The EU Ethics Guidelines for Trustworthy AI require businesses to establish trustworthy AI.,Search,2020,5,"Eleanore  Hickman, Martin  Petrin",,,10.2139/ssrn.3607225,https://doi.org/10.2139/ssrn.3607225,https://semanticscholar.org/paper/72b39cf03173e4ced50e54873dac32258bbbfe16,,"AI will change many aspects of the world we live in, including the way corporations are governed. Many efficiencies and improvements are likely, but there are also potential dangers, including the threat of harmful impacts on third parties, discriminatory practices, data and privacy breaches, fraudulent practices and even ‘rogue AI’. To address these dangers, the EU published its 'Ethics Guidelines for Trustworthy AI’. The Guidelines produce seven principles from its four foundational pillars of respect for human autonomy, prevention of harm, fairness and explicability.

If implemented by business, the impact on corporate governance will be substantial. Fundamental questions at the intersection of ethics and law are considered but, because the Guidelines only address the former without much reference to the latter, their practical application is challenging for business. Further, while they promote many positive corporate governance principles, it is clear that the Guidelines' general nature leaves many questions and concerns unanswered.

In this paper we examine the potential significance and impact of the Guidelines on selected corporate law and governance issues. We conclude that more specificity is needed in relation to how the principles therein will harmonise with company law rules and governance practices. However, despite their imperfections, until harder legislative instruments emerge, the Guidelines provide a useful starting point for directing businesses towards establishing trustworthy AI.",,
Trustworthy AI: From Principles to Practices,There is a need for paradigm shift towards comprehensive trustworthy AI systems.,Search,2021,1,"Bo  Li, Peng  Qi, Bo  Liu, Shuai  Di, Jingen  Liu, Jiquan  Pei, Jinfeng  Yi, Bowen  Zhou",ArXiv,,,,https://semanticscholar.org/paper/c3689493757f90267908e776aeada9194fce55c7,,"Fast developing artificial intelligence (AI) technology has enabled various applied systems deployed in the real world, impacting people’s everyday lives. However, many current AI systems were found vulnerable to imperceptible attacks, biased against underrepresented groups, lacking in user privacy protection, etc., which not only degrades user experience but erodes the society’s trust in all AI systems. In this review, we strive to provide AI practitioners a comprehensive guide towards building trustworthy AI systems. We first introduce the theoretical framework of important aspects of AI trustworthiness, including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, alignment with human values, and accountability. We then survey leading approaches in these aspects in the industry. To unify the current fragmented approaches towards trustworthy AI, we propose a systematic approach that considers the entire lifecycle of AI systems, ranging from data acquisition to model development, to development and deployment, finally to continuous monitoring and governance. In this framework, we offer concrete action items to practitioners and societal stakeholders (e.g., researchers and regulators) to improve AI trustworthiness. Finally, we identify key opportunities and challenges in the future development of trustworthy AI systems, where we identify the need for paradigm shift towards comprehensive trustworthy AI systems.",,Review
Designing Trustworthy AI: A Human-Machine Teaming Framework to Guide Development,"The Human-Machine Teaming Framework for Designing Ethical AI Experiences will guide AI development teams to create AI systems that are accountable, de-risked, respectful, secure, honest, and usable.",Search,2019,4,Carol J. Smith,ArXiv,,10.1184/R1/12119847.V1,https://doi.org/10.1184/R1/12119847.V1,https://semanticscholar.org/paper/e4213c10a8894e9a767633ed12a605fd65beb95b,,"Artificial intelligence (AI) holds great promise to empower us with knowledge and augment our effectiveness. We can -- and must -- ensure that we keep humans safe and in control, particularly with regard to government and public sector applications that affect broad populations. How can AI development teams harness the power of AI systems and design them to be valuable to humans? Diverse teams are needed to build trustworthy artificial intelligent systems, and those teams need to coalesce around a shared set of ethics. There are many discussions in the AI field about ethics and trust, but there are few frameworks available for people to use as guidance when creating these systems. The Human-Machine Teaming (HMT) Framework for Designing Ethical AI Experiences described in this paper, when used with a set of technical ethics, will guide AI development teams to create AI systems that are accountable, de-risked, respectful, secure, honest, and usable. To support the team's efforts, activities to understand people's needs and concerns will be introduced along with the themes to support the team's efforts. For example, usability testing can help determine if the audience understands how the AI system works and complies with the HMT Framework. The HMT Framework is based on reviews of existing ethical codes and best practices in human-computer interaction and software development. Human-machine teams are strongest when human users can trust AI systems to behave as expected, safely, securely, and understandably. Using the HMT Framework to design trustworthy AI systems will provide support to teams in identifying potential issues ahead of time and making great experiences for humans.",,Review
Trustworthy AI and Corporate Governance: The EU’s Ethics Guidelines for Trustworthy Artificial Intelligence from a Company Law Perspective,The EU Ethics Guidelines for Trustworthy Artificial Intelligence provide a useful starting point for directing businesses towards establishing trustworthy AI.,Search,2021,1,"Eleanore  Hickman, Martin  Petrin",European Business Organization Law Review,,10.1007/s40804-021-00224-0,https://doi.org/10.1007/s40804-021-00224-0,https://semanticscholar.org/paper/89b6823aea0f7306bd2ee9a4dac7206256ecd5cc,https://link.springer.com/content/pdf/10.1007/s40804-021-00224-0.pdf,"AI will change many aspects of the world we live in, including the way corporations are governed. Many efficiencies and improvements are likely, but there are also potential dangers, including the threat of harmful impacts on third parties, discriminatory practices, data and privacy breaches, fraudulent practices and even ‘rogue AI’. To address these dangers, the EU published ‘The Expert Group’s Policy and Investment Recommendations for Trustworthy AI’ (the Guidelines). The Guidelines produce seven principles from its four foundational pillars of respect for human autonomy, prevention of harm, fairness, and explicability. If implemented by business, the impact on corporate governance will be substantial. Fundamental questions at the intersection of ethics and law are considered, but because the Guidelines only address the former without (much) reference to the latter, their practical application is challenging for business. Further, while they promote many positive corporate governance principles—including a stakeholder-oriented (‘human-centric’) corporate purpose and diversity, non-discrimination, and fairness—it is clear that their general nature leaves many questions and concerns unanswered. In this paper we examine the potential significance and impact of the Guidelines on selected corporate law and governance issues. We conclude that more specificity is needed in relation to how the principles therein will harmonise with company law rules and governance principles. However, despite their imperfections, until harder legislative instruments emerge, the Guidelines provide a useful starting point for directing businesses towards establishing trustworthy AI.",,
A critical perspective on guidelines for responsible and trustworthy artificial intelligence,The ethical issues of AI technology vary from privacy and confidentiality of personal data to the ethical status and value of AI entities.,Search,2020,4,"Banu  Buruk, Perihan Elif Ekmekci, Berna  Arda","Medicine, health care, and philosophy",,10.1007/s11019-020-09948-1,https://doi.org/10.1007/s11019-020-09948-1,https://semanticscholar.org/paper/4990df10e6423ad5d44888697dd8bc523287fd14,,"Artificial intelligence (AI) is among the fastest developing areas of advanced technology in medicine. The most important qualia of AI which makes it different from other advanced technology products is its ability to improve its original program and decision-making algorithms via deep learning abilities. This difference is the reason that AI technology stands out from the ethical issues of other advanced technology artifacts. The ethical issues of AI technology vary from privacy and confidentiality of personal data to ethical status and value of AI entities in a wide spectrum, depending on their capability of deep learning and scope of the domains in which they operate. Developing ethical norms and guidelines for planning, development, production, and usage of AI technology has become an important issue to overcome these problems. In this respect three outstanding documents have been produced: 1. The Montréal Declaration for Responsible Development of Artificial Intelligence 2. Ethics Guidelines for Trustworthy AI 3. Asilomar Artificial Intelligence Principles In this study, these three documents will be analyzed with respect to the ethical principles and values they involve, their perspectives for approaching ethical issues, and their prospects for ethical reasoning when one or more of these values and principles are in conflict. Then, the sufficiency of these guidelines for addressing current or prospective ethical issues emerging from the existence of AI technology in medicine will be evaluated. The discussion will be pursued in terms of the ambiguity of interlocutors and efficiency for working out ethical dilemmas occurring in practical life.",,
Opening the software engineering toolbox for the assessment of trustworthy AI,The European Commission's AI high-level expert group defined seven key requirements for Trustworthy AI.,Search,2020,2,"Mohit Kumar Ahuja, Mohamed-Bachir  Belaid, Pierre  Bernab'e, Mathieu  Collet, Arnaud  Gotlieb, Chhagan  Lal, Dusica  Marijan, Sagar  Sen, Aizaz  Sharif, Helge  Spieker",NeHuAI@ECAI,,,,https://semanticscholar.org/paper/3b0ff6bd000e9c615d024614343f2c1cf12bf124,,"Trustworthiness is a central requirement for the acceptance and success of human-centered artificial intelligence (AI). To deem an AI system as trustworthy, it is crucial to assess its behaviour and characteristics against a gold standard of Trustworthy AI, consisting of guidelines, requirements, or only expectations. While AI systems are highly complex, their implementations are still based on software. The software engineering community has a long-established toolbox for the assessment of software systems, especially in the context of software testing. In this paper, we argue for the application of software engineering and testing practices for the assessment of trustworthy AI. We make the connection between the seven key requirements as defined by the European Commission's AI high-level expert group and established procedures from software engineering and raise questions for future work.",,
Trustworthy artificial intelligence,"Trustworthy AI bases on the idea that trust builds the foundation of societies, economies, and sustainable development.",Search,2021,21,"Scott  Thiebes, Sebastian  Lins, Ali  Sunyaev",Electron. Mark.,,10.1007/S12525-020-00441-4,https://doi.org/10.1007/S12525-020-00441-4,https://semanticscholar.org/paper/9da092d7c7674e96830f8d6713a9a4f8101f984c,https://link.springer.com/content/pdf/10.1007/s12525-020-00441-4.pdf,"Artificial intelligence (AI) brings forth many opportunities to contribute to the wellbeing of individuals and the advancement of economies and societies, but also a variety of novel ethical, legal, social, and technological challenges. Trustworthy AI (TAI) bases on the idea that trust builds the foundation of societies, economies, and sustainable development, and that individuals, organizations, and societies will therefore only ever be able to realize the full potential of AI, if trust can be established in its development, deployment, and use. With this article we aim to introduce the concept of TAI and its five foundational principles (1) beneficence, (2) non-maleficence, (3) autonomy, (4) justice, and (5) explicability. We further draw on these five principles to develop a data-driven research framework for TAI and demonstrate its utility by delineating fruitful avenues for future research, particularly with regard to the distributed ledger technology-based realization of TAI.",,
Global Challenges in the Standardization of Ethics for Trustworthy AI,Ethical guidelines for Trustworthy AI are required to address the potential negative effects of AI on society.,Search,2020,2,"Dave  Lewis, Linda  Hogan, David  Filip, P. J. Wall",J. ICT Stand.,,10.13052/jicts2245-800x.823,https://doi.org/10.13052/jicts2245-800x.823,https://semanticscholar.org/paper/6e32b0f0aa67d7cf11d199a41a68a9d755897151,https://journals.riverpublishers.com/index.php/JICTS/article/download/2645/1741,"In this paper, we examine the challenges of developing international standards for Trustworthy AI that aim both to be global applicable and to address the ethical questions key to building trust at a commercial and societal level. We begin by examining the validity of grounding standards that aim for international reach on human right agreements, and the need to accommodate variations in prioritization and tradeoffs in implementing rights in different societal and cultural settings. We then examine the major recent proposals from the OECD, the EU and the IEEE on ethical governance of Trustworthy AI systems in terms of their scope and use of normative language. From this analysis, we propose a preliminary minimal model for the functional roles relevant to Trustworthy AI as a framing for further standards development in this area. We also identify the different types of interoperability reference points that may exist between these functional roles and remark on the potential role they could play in future standardization. Finally we examine a current AI standardization effort under ISO/IEC JTC1 to consider how future Trustworthy AI standards may be able to build on existing standards in developing ethical guidelines and in particular on the ISO standard on Social Responsibility.We conclude by proposing some future directions for research and development of Trustworthy AI standards.",,