Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
An agile framework for trustworthy AI,The AI High Level Expert Group (AI-HLEG) ethics guidelines present a list of requirements that trustworthy AI systems should meet.,Search,2020,2,"Stefan  Leijnen, Huib  Aldewereld, Rudy van Belkom, Roland  Bijvank, Roelant  Ossewaarde",NeHuAI@ECAI,,,,https://semanticscholar.org/paper/880049a16c8fea47dcfe07450668f5507db5e96d,,"From the article: The ethics guidelines put forward by the AI High Level Expert Group (AI-HLEG) present a list of seven key requirements that Human-centered, trustworthy AI systems should meet. These guidelines are useful for the evaluation of AI systems, but can be complemented by applied methods and tools for the development of trustworthy AI systems in practice. In this position paper we propose a framework for translating the AI-HLEG ethics guidelines into the specific context within which an AI system operates. This approach aligns well with a set of Agile principles commonly employed in software engineering. http://ceur-ws.org/Vol-2659/",,
Trustworthy artificial intelligence,A data-driven research framework for Trustworthy Artificial Intelligence (TAI) is useful for researching TAI.,Search,2021,21,"Scott  Thiebes, Sebastian  Lins, Ali  Sunyaev",Electron. Mark.,,10.1007/S12525-020-00441-4,https://doi.org/10.1007/S12525-020-00441-4,https://semanticscholar.org/paper/9da092d7c7674e96830f8d6713a9a4f8101f984c,https://link.springer.com/content/pdf/10.1007/s12525-020-00441-4.pdf,"Artificial intelligence (AI) brings forth many opportunities to contribute to the wellbeing of individuals and the advancement of economies and societies, but also a variety of novel ethical, legal, social, and technological challenges. Trustworthy AI (TAI) bases on the idea that trust builds the foundation of societies, economies, and sustainable development, and that individuals, organizations, and societies will therefore only ever be able to realize the full potential of AI, if trust can be established in its development, deployment, and use. With this article we aim to introduce the concept of TAI and its five foundational principles (1) beneficence, (2) non-maleficence, (3) autonomy, (4) justice, and (5) explicability. We further draw on these five principles to develop a data-driven research framework for TAI and demonstrate its utility by delineating fruitful avenues for future research, particularly with regard to the distributed ledger technology-based realization of TAI.",,
"Information Theoretic Evaluation of Privacy-Leakage, Interpretability, and Transferability for a Novel Trustworthy AI Framework",A novel trustworthy AI framework takes into account ethical AI principles during the development of machine learning and deep learning models.,Search,2021,,"Mohit  Kumar, Bernhard A. Moser, Lukas  Fischer, Bernhard  Freudenthaler",ArXiv,,,,https://semanticscholar.org/paper/4deb5a713cba1b041092bcb923719b22bf8fcc56,,"Guidelines and principles of trustworthy AI should be adhered to in practice during the development of AI systems. This work suggests a novel information theoretic trustworthy AI framework based on the hypothesis that information theory enables taking into account the ethical AI principles during the development of machine learning and deep learning models via providing a way to study and optimize the inherent tradeoffs between trustworthy AI principles. Under the proposed framework, a unified approach to “privacy-preserving interpretable and transferable learning” is considered to introduce the information theoretic measures for privacy-leakage, interpretability, and transferability. A technique based on variational optimization, employing conditionally deep autoencoders, is developed for practically calculating the defined information theoretic measures for privacy-leakage, interpretability, and transferability.",,
Designing Trustworthy AI: A User Experience (UX) Framework at RSA Conference 2020,"A new user experience framework can guide the creation of AI systems that are accountable, de-risked, respectful, secure, honest and usable.",Search,2020,,Carol  Smith,,,10.1184/R1/12198321.V1,https://doi.org/10.1184/R1/12198321.V1,https://semanticscholar.org/paper/a2a2e1d11f3738113b182d5d4e6366a033d96fab,,"Artificial intelligence (AI) holds great promise to empower us with knowledge and scaled effectiveness. To harness the power of AI systems, we can—and must—ensure that we keep humans safe and in control. This session will introduce a new user experience (UX) framework to guide the creation of AI systems that are accountable, de-risked, respectful, secure, honest and usable.",,
Trustworthy AI Implementation (TAII) Framework for AI Systems,The Trustworthy AI Implementation (TAII) framework combines AI ethics research with previous research findings to create the AI ethics implementation kickoff.,Search,2021,1,Josef  Baker-Brunnbauer,,,10.2139/SSRN.3796799,https://doi.org/10.2139/SSRN.3796799,https://semanticscholar.org/paper/3337ff3dd257ae6cb5d276e34aa06f190ab06265,,"Companies and their stakeholder need practical tools and implementation guidelines besides abstract frameworks to kick off the realization of Artificial Intelligence (AI) ethics. Based on my previous research outcome AI development companies are still in the beginning of this process or have not even started yet. How is it possible to decrease the entry level barrier to kickoff AI ethics implementation? I tackle this question by combining AI ethics research with previous research findings to create the Trustworthy AI Implementation (TAII) framework. A literature review was conducted and that specifies the research and implementation status for each process step. The aim is to kickoff AI ethics and to transfer research and abstract guidelines from academia to business. The TAII process generates a meta perspective on the systemic dependencies of ethics for the company ecosystem. It generates orienteering for the AI ethics kickoff without requiring a deep background in philosophy and considers perspectives of social impact outside the software and data engineering setting. Depending on the legal regulation or area of application, the TAII process can be adapted and used with different regulations and ethical principles.",,Review
Designing Trustworthy AI: A Human-Machine Teaming Framework to Guide Development,"A Human-Machine Teaming Framework for Designing Ethical AI Experiences will guide AI development teams to create AI systems that are accountable, de-risked, respectful, secure, honest, and usable.",Search,2019,4,Carol J. Smith,ArXiv,,10.1184/R1/12119847.V1,https://doi.org/10.1184/R1/12119847.V1,https://semanticscholar.org/paper/e4213c10a8894e9a767633ed12a605fd65beb95b,,"Artificial intelligence (AI) holds great promise to empower us with knowledge and augment our effectiveness. We can -- and must -- ensure that we keep humans safe and in control, particularly with regard to government and public sector applications that affect broad populations. How can AI development teams harness the power of AI systems and design them to be valuable to humans? Diverse teams are needed to build trustworthy artificial intelligent systems, and those teams need to coalesce around a shared set of ethics. There are many discussions in the AI field about ethics and trust, but there are few frameworks available for people to use as guidance when creating these systems. The Human-Machine Teaming (HMT) Framework for Designing Ethical AI Experiences described in this paper, when used with a set of technical ethics, will guide AI development teams to create AI systems that are accountable, de-risked, respectful, secure, honest, and usable. To support the team's efforts, activities to understand people's needs and concerns will be introduced along with the themes to support the team's efforts. For example, usability testing can help determine if the audience understands how the AI system works and complies with the HMT Framework. The HMT Framework is based on reviews of existing ethical codes and best practices in human-computer interaction and software development. Human-machine teams are strongest when human users can trust AI systems to behave as expected, safely, securely, and understandably. Using the HMT Framework to design trustworthy AI systems will provide support to teams in identifying potential issues ahead of time and making great experiences for humans.",,Review
A Trustworthy Framework of Artificial Intelligence for Power Grid Dispatching Systems,The HGAT-Explainer model can provide more favorable support for trustworthy-AI systems.,Search,2021,,"Ke  Zhang, Peidong  Xu, Tianlu  Gao, Jun  ZHANG",2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI),,10.1109/DTPI52967.2021.9540198,https://doi.org/10.1109/DTPI52967.2021.9540198,https://semanticscholar.org/paper/b48289ecaf70a5ef5de7f28f1590107581c4348d,,"With the widespread application of artificial intelligence (AI) technologies in power systems, the properties of lack of reliability and transparency for AI technologies have revealed gradually. Here, how to build a trustworthy-AI framework based on the power system is the focus. Due to the multidimensional and heterogeneous information of power grid data, the heterogeneous graph attention network (HGAT) model of power grid dispatching is established, and the corresponding explainer (HGAT-Explainer) for the model of power equipment faults is proposed to provide more favorable support for the trustworthy-AI systems.",,
An Explainable Artificial Intelligence (xAI) Framework for Improving Trust in Automated ATM Tools,There is a gap between research projects and practical implementation of artificial intelligence and machine learning due to the need for transparency and explainability of solutions.,Search,2021,,"Carolina Sanchez Hernandez, Samuel  Ayo, Dimitrios  Panagiotakopoulos",2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC),,10.1109/dasc52595.2021.9594341,https://doi.org/10.1109/dasc52595.2021.9594341,https://semanticscholar.org/paper/bf3f1666259b71110cdd5540cac9f0058482272e,http://dspace.lib.cranfield.ac.uk/bitstream/1826/17344/1/improving_trust_in_automated_ATM_tools-2021.pdf,"With the increased use of intelligent Decision Support Tools in Air Traffic Management (ATM) and inclusion of non-traditional entities, regulators and end users need assurance that new technologies such as Artificial Intelligence (AI) and Machine Learning (ML) are trustworthy and safe. Although there is a wide amount of research on the technologies themselves, there seem to be a gap between research projects and practical implementation due to different regulatory and practical challenges including the need for transparency and explainability of solutions. In order to help address these challenges, a novel framework to enable trust on AI-based automated solutions is presented based on current guidelines and end user feedback. Finally, recommendations are provided to bridge the gap between research and implementation of AI and ML-based solutions using our framework as a mechanism to aid advances of AI technology within ATM.",,
TAII Framework for Trustworthy AI Systems,The Trustworthy Artificial Intelligence Implementation (TAII) Framework identifies ethical dependencies within companies.,Search,2021,,Josef  Baker-Brunnbauer,,,,,https://semanticscholar.org/paper/c0b7aba59db8da49ca2109b4e90244a7fbb2153c,,"Organizations and companies need practical tools and guidelines to kick-off the implementation of Trustworthy Artificial Intelligence (TAI) systems. AI development companies are still in the beginning of this process or have not even started yet. The findings of this article address to decrease the entry level barrier for AI ethics implementation by introducing the Trustworthy Artificial Intelligence Implementation (TAII) Framework. The outcome is comparatively unique given that it considers a meta perspective of implementing TAI within organizations. As such, this research aims to fill a literature gap for management guidance to tackle trustworthy AI implementation while considering ethical dependencies within the company. The TAII Framework takes a holistic approach to identify the systemic relationships of ethics for the company ecosystem and considers corporate values, business models, and common good aspects like the Sustainable Development Goals and the Universal Declaration of Human Rights. The TAII Framework creates guidance to initiate the implementation of AI ethics in organizations without requiring a deep background in philosophy and considers the social impacts outside of a software and data engineering setting. Depending on the legal regulation or area of application, the TAII Framework can be adapted and used with different regulations and ethical principles.",,
Trustworthy AI: From Principles to Practices,"A comprehensive trustworthy AI framework involves various aspects including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, alignment with human values, and accountability.",Search,2021,1,"Bo  Li, Peng  Qi, Bo  Liu, Shuai  Di, Jingen  Liu, Jiquan  Pei, Jinfeng  Yi, Bowen  Zhou",ArXiv,,,,https://semanticscholar.org/paper/c3689493757f90267908e776aeada9194fce55c7,,"Fast developing artificial intelligence (AI) technology has enabled various applied systems deployed in the real world, impacting people’s everyday lives. However, many current AI systems were found vulnerable to imperceptible attacks, biased against underrepresented groups, lacking in user privacy protection, etc., which not only degrades user experience but erodes the society’s trust in all AI systems. In this review, we strive to provide AI practitioners a comprehensive guide towards building trustworthy AI systems. We first introduce the theoretical framework of important aspects of AI trustworthiness, including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, alignment with human values, and accountability. We then survey leading approaches in these aspects in the industry. To unify the current fragmented approaches towards trustworthy AI, we propose a systematic approach that considers the entire lifecycle of AI systems, ranging from data acquisition to model development, to development and deployment, finally to continuous monitoring and governance. In this framework, we offer concrete action items to practitioners and societal stakeholders (e.g., researchers and regulators) to improve AI trustworthiness. Finally, we identify key opportunities and challenges in the future development of trustworthy AI systems, where we identify the need for paradigm shift towards comprehensive trustworthy AI systems.",,Review
"Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy",The methods of the Human-Centered Artificial Intelligence (HCAI) framework are more likely to produce RST technologies.,Search,2020,105,Ben  Shneiderman,Int. J. Hum. Comput. Interact.,,10.1080/10447318.2020.1741118,https://doi.org/10.1080/10447318.2020.1741118,https://semanticscholar.org/paper/e49f67fa5c946ad24afcf59699a9cacf1ca53924,http://arxiv.org/pdf/2002.04087,"ABSTRACT Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The methods of HCAI are more likely to produce designs that are Reliable, Safe & Trustworthy (RST). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.",,
Blockchain for explainable and trustworthy artificial intelligence,"A blockchain, smart contracts, oracles, and decentralized storage can help make artificial intelligence more trustworthy and explainable.",Search,2020,34,"Mohamed  Nassar, Khaled  Salah, Muhammad Habib ur Rehman, Davor  Svetinovic",WIREs Data Mining Knowl. Discov.,,10.1002/widm.1340,https://doi.org/10.1002/widm.1340,https://semanticscholar.org/paper/960f5f6d648ae14f7c5359a2492af5f90aae4308,,"The increasing computational power and proliferation of big data are now empowering Artificial Intelligence (AI) to achieve massive adoption and applicability in many fields. The lack of explanation when it comes to the decisions made by today's AI algorithms is a major drawback in critical decision‐making systems. For example, deep learning does not offer control or reasoning over its internal processes or outputs. More importantly, current black‐box AI implementations are subject to bias and adversarial attacks that may poison the learning or the inference processes. Explainable AI (XAI) is a new trend of AI algorithms that provide explanations of their AI decisions. In this paper, we propose a framework for achieving a more trustworthy and XAI by leveraging features of blockchain, smart contracts, trusted oracles, and decentralized storage. We specify a framework for complex AI systems in which the decision outcomes are reached based on decentralized consensuses of multiple AI and XAI predictors. The paper discusses how our proposed framework can be utilized in key application areas with practical use cases.",,
Towards trustworthy AI: safe-visor architecture for uncertified controllers in stochastic cyber-physical systems,A history-based supervisor and a safety advisor can provide safety guarantees for a stochastic cyber-physical system using an AI-based controller.,Search,2021,,"Abolfazl  Lavaei, Bingzhuo  Zhong, Marco  Caccamo, Majid  Zamani",CAADCPS@CPSIoTWeek,,10.1145/3457335.3461705,https://doi.org/10.1145/3457335.3461705,https://semanticscholar.org/paper/8d4b027951bd4bde6933e457bc89323cf8d9ea43,,"Artificial intelligence-based (a.k.a. AI-based) controllers have received significant attentions in the past few years due to their broad applications in cyber-physical systems (CPSs) to accomplish complex control missions. However, guaranteeing safety and reliability of CPSs equipped with this kind of (uncertified) controllers is currently very challenging, which is of vital importance in many real-life safety-critical applications. To cope with this difficulty, we propose a Safe-visor architecture for sandboxing AI-based controllers in stochastic CPSs. The proposed framework contains (i) a history-based supervisor which checks inputs from the AI-based controller and makes compromise between functionality and safety of the system, and (ii) a safety advisor that provides fallback when the AI-based controller endangers the safety of the system. By employing this architecture, we provide formal probabilistic guarantees on the satisfaction of those classes of safety specifications which can be represented by the accepting languages of deterministic finite automata (DFA), while AI-based controllers can still be employed in the control loop even though they are not reliable.",,
Trustworthy Artificial Intelligence and Process Mining: Challenges and Opportunities,"Process mining can provide for an automated approach to analyze, remediate, and monitor uncertainty in AI regulatory compliance processes.",Search,2021,,"Andrew  Pery, Majid  Rafiei, Michael  Simon, Wil M.P. van der Aalst",ArXiv,,,,https://semanticscholar.org/paper/cdaf33302d24c9f2830bdf19e5b7e83e5a8acd9f,,"The premise of this paper is that compliance with Trustworthy AI governance best practices and regulatory frameworks is an inherently fragmented process spanning across diverse organizational units, external stakeholders, and systems of record, resulting in process uncertainties and in compliance gaps that may expose organizations to reputational and regulatory risks. Moreover, there are complexities associated with meeting the specific dimensions of Trustworthy AI best practices such as data governance, conformance testing, quality assurance of AI model behaviors, transparency, accountability, and confidentiality requirements. These processes involve multiple steps, hand-offs, re-works, and human-in-the-loop oversight. In this paper, we demonstrate that process mining can provide a useful framework for gaining fact-based visibility to AI compliance process execution, surfacing compliance bottlenecks, and providing for an automated approach to analyze, remediate and monitor uncertainty in AI regulatory compliance processes.",,
The relationship between trust in AI and trustworthy machine learning technologies,Trust can be impacted throughout the life cycle of AI-based systems.,Search,2020,50,"Ehsan  Toreini, Mhairi  Aitken, Kovila  Coopamootoo, Karen  Elliott, Carlos Gonzalez Zelaya, Aad van Moorsel",FAT*,,10.1145/3351095.3372834,https://doi.org/10.1145/3351095.3372834,https://semanticscholar.org/paper/bd4cf5a6987ef0f39b7e4e88d59b3a3365abcc70,http://arxiv.org/pdf/1912.00782,"To design and develop AI-based systems that users and the larger public can justifiably trust, one needs to understand how machine learning technologies impact trust. To guide the design and implementation of trusted AI-based systems, this paper provides a systematic approach to relate considerations about trust from the social sciences to trustworthiness technologies proposed for AI-based services and products. We start from the ABI+ (Ability, Benevolence, Integrity, Predictability) framework augmented with a recently proposed mapping of ABI+ on qualities of technologies that support trust. We consider four categories of trustworthiness technologies for machine learning, namely these for Fairness, Explainability, Auditability and Safety (FEAS) and discuss if and how these support the required qualities. Moreover, trust can be impacted throughout the life cycle of AI-based systems, and we therefore introduce the concept of Chain of Trust to discuss trustworthiness technologies in all stages of the life cycle. In so doing we establish the ways in which machine learning technologies support trusted AI-based systems. Finally, FEAS has obvious relations with known frameworks and therefore we relate FEAS to a variety of international 'principled AI' policy and technology frameworks that have emerged in recent years.",,
Formal Model of Trustworthy Artificial Intelligence Based on Standardization,The regulatory framework for artificial intelligence is built on a human-centric basis.,Search,2021,1,"Eduard  Manziuk, Olexander  Barmak, Iurii  Krak, Olexander  Mazurets, Tetiana  Skrypnyk",IntelITSIS,,,,https://semanticscholar.org/paper/746cf930349beb3557ccd171fd4249347755ca10,,"The widespread and rapid distribution and application of artificial intelligence (AI) systems requires the development of formalized approaches and the construction of basic principles for the functioning of domain areas of AI use. This need is embodied in the development of recommendations and standards to obtain maximum benefits from the use of AI and minimize possible risks. The regulatory framework is being built on a human-centric basis. Accordingly, the developed standards should form the basis for further activities aimed at the use of AI and be applicable at all stages of creating practical solutions. Therefore, an important stage is the formalization of requirements, principles and provisions of legal and ethical norms in the form of practical template approaches for practical application. With this method, models and ontology of standardized concept of AI credibility are developed within the research. This made it possible to identify the main concepts that allow forming a position of trust, are a meaningful part of the concept of trustworthy AI, determine the need for its existence and pose a threat to it. On the basis of ontology of the domain area, models were developed and further decomposition of structural substantive concepts was carried out. In the future, the characteristics of the concept of trustworthiness formation are defined.",,