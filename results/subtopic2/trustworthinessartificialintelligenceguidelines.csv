Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Establishing the rules for building trustworthy AI,The European Commission’s report ‘Ethics guidelines for trustworthy AI’ facilitates international support for AI solutions that are good for humanity and the environment.,Search,2019,67,Luciano  Floridi,Nature Machine Intelligence,,10.1038/S42256-019-0055-Y,https://doi.org/10.1038/S42256-019-0055-Y,https://semanticscholar.org/paper/dc44e2be0f85b6225f05390c570885337a99ef83,https://philpapers.org/archive/FLOETR.pdf,"The European Commission’s report ‘Ethics guidelines for trustworthy AI’ provides a clear benchmark to evaluate the responsible development of AI systems, and facilitates international support for AI solutions that are good for humanity and the environment, says Luciano Floridi.",,
Trustworthy AI Development Guidelines for Human System Interaction,AI development guidelines can improve the user trust in AI systems to enhance human-AI interactions.,Search,2020,3,"Chathurika S. Wickramasinghe, Daniel L. Marino, Javier  Grandio, Milos  Manic",2020 13th International Conference on Human System Interaction (HSI),,10.1109/HSI49210.2020.9142644,https://doi.org/10.1109/HSI49210.2020.9142644,https://semanticscholar.org/paper/238fa66062114f39e404c40d0b1abc03b86e54bd,,"Artificial Intelligence (AI) is influencing almost all areas of human life. Even though these AI-based systems frequently provide state-of-the-art performance, humans still hesitate to develop, deploy, and use AI systems. The main reason for this is the lack of trust in AI systems caused by the deficiency of transparency of existing AI systems. As a solution, “Trustworthy AI” research area merged with the goal of defining guidelines and frameworks for improving user trust in AI systems, allowing humans to use them without fear. While trust in AI is an active area of research, very little work exists where the focus is to build human trust to improve the interactions between human and AI systems. In this paper, we provide a concise survey on concepts of trustworthy AI. Further, we present trustworthy AI development guidelines for improving the user trust to enhance the interactions between AI systems and humans, that happen during the AI system life cycle.",,
The Ethical Guidelines for Trustworthy AI – A Procrastination of Effective Law Enforcement,The Ethical Guidelines for Trustworthy Artificial Intelligence by the EU Commission are ineffective.,Search,2019,2,Ramak Molavi Vasse’i,Computer Law Review International,,10.9785/cri-2019-200502,https://doi.org/10.9785/cri-2019-200502,https://semanticscholar.org/paper/64223e4aa1a20a6406cd036417245385b6b33cc0,,"In the august issue of the CRi, Nathalie Smuha, the coordinator of the work of the High-Level Expert Group on AI, outlined the approach and considerations leading to the “The EU Approach to Ethics Guidelines for Trustworthy Artificial Intelligence”. This paper provides a critical assessment of the Ethical Guidelines of the EU Commission and points out why a law enforcement focused approach must be the essential next step towards a beneficial and humane development of AI. Questioning the diversity of the Commssion’s High Level Expert Group on Artificial Intelligence, the dangers of ethics shopping are exposed as well as the UN Universal Declaration of Human Rights explored as already well established alternative reference framework for AI. Having exposed the need for effective red lines, not only the hidden social and ecological cost are assessed, but also the risk of “buying-out” research and other ethical issues neglected in the Ethics Guidelines for Trustworthy Artificial Intelligence. Finally, three key weaknesses concerning the crucial translation of ethical principles into practice (enforcement) are highlighted.",,
How to achieve trustworthy artificial intelligence for health,"The EU's guidelines for artificial intelligence leave room for local, contextualized discretion.",Search,2020,15,"Kristine  Bærøe, Ainar  Miyata-Sturm, Edmund  Henden",Bulletin of the World Health Organization,,10.2471/BLT.19.237289,https://doi.org/10.2471/BLT.19.237289,https://semanticscholar.org/paper/0a3c92d6c4fa4670743fb13758916067e772a143,https://europepmc.org/articles/pmc7133476?pdf=render,"Abstract Artificial intelligence holds great promise in terms of beneficial, accurate and effective preventive and curative interventions. At the same time, there is also awareness of potential risks and harm that may be caused by unregulated developments of artificial intelligence. Guiding principles are being developed around the world to foster trustworthy development and application of artificial intelligence systems. These guidelines can support developers and governing authorities when making decisions about the use of artificial intelligence. The High-Level Expert Group on Artificial Intelligence set up by the European Commission launched the report Ethical guidelines for trustworthy artificial intelligence in2019. The report aims to contribute to reflections and the discussion on the ethics of artificial intelligence technologies also beyond the countries of the European Union (EU). In this paper, we use the global health sector as a case and argue that the EU’s guidance leaves too much room for local, contextualized discretion for it to foster trustworthy artificial intelligence globally. We point to the urgency of shared globalized efforts to safeguard against the potential harms of artificial intelligence technologies in health care.",,
Trustworthy AI: From Principles to Practices,There is a need for a paradigm shift towards comprehensive trustworthy AI systems.,Search,2021,1,"Bo  Li, Peng  Qi, Bo  Liu, Shuai  Di, Jingen  Liu, Jiquan  Pei, Jinfeng  Yi, Bowen  Zhou",ArXiv,,,,https://semanticscholar.org/paper/c3689493757f90267908e776aeada9194fce55c7,,"Fast developing artificial intelligence (AI) technology has enabled various applied systems deployed in the real world, impacting people’s everyday lives. However, many current AI systems were found vulnerable to imperceptible attacks, biased against underrepresented groups, lacking in user privacy protection, etc., which not only degrades user experience but erodes the society’s trust in all AI systems. In this review, we strive to provide AI practitioners a comprehensive guide towards building trustworthy AI systems. We first introduce the theoretical framework of important aspects of AI trustworthiness, including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, alignment with human values, and accountability. We then survey leading approaches in these aspects in the industry. To unify the current fragmented approaches towards trustworthy AI, we propose a systematic approach that considers the entire lifecycle of AI systems, ranging from data acquisition to model development, to development and deployment, finally to continuous monitoring and governance. In this framework, we offer concrete action items to practitioners and societal stakeholders (e.g., researchers and regulators) to improve AI trustworthiness. Finally, we identify key opportunities and challenges in the future development of trustworthy AI systems, where we identify the need for paradigm shift towards comprehensive trustworthy AI systems.",,Review
Trustworthy artificial intelligence,"Trustworthy AI bases on the idea that trust builds the foundation of societies, economies, and sustainable development.",Search,2021,21,"Scott  Thiebes, Sebastian  Lins, Ali  Sunyaev",Electron. Mark.,,10.1007/S12525-020-00441-4,https://doi.org/10.1007/S12525-020-00441-4,https://semanticscholar.org/paper/9da092d7c7674e96830f8d6713a9a4f8101f984c,https://link.springer.com/content/pdf/10.1007/s12525-020-00441-4.pdf,"Artificial intelligence (AI) brings forth many opportunities to contribute to the wellbeing of individuals and the advancement of economies and societies, but also a variety of novel ethical, legal, social, and technological challenges. Trustworthy AI (TAI) bases on the idea that trust builds the foundation of societies, economies, and sustainable development, and that individuals, organizations, and societies will therefore only ever be able to realize the full potential of AI, if trust can be established in its development, deployment, and use. With this article we aim to introduce the concept of TAI and its five foundational principles (1) beneficence, (2) non-maleficence, (3) autonomy, (4) justice, and (5) explicability. We further draw on these five principles to develop a data-driven research framework for TAI and demonstrate its utility by delineating fruitful avenues for future research, particularly with regard to the distributed ledger technology-based realization of TAI.",,
Trustworthy Artificial Intelligence and Process Mining: Challenges and Opportunities,"Process mining can provide for an automated approach to analyze, remediate, and monitor uncertainty in AI regulatory compliance processes.",Search,2021,,"Andrew  Pery, Majid  Rafiei, Michael  Simon, Wil M.P. van der Aalst",ArXiv,,,,https://semanticscholar.org/paper/cdaf33302d24c9f2830bdf19e5b7e83e5a8acd9f,,"The premise of this paper is that compliance with Trustworthy AI governance best practices and regulatory frameworks is an inherently fragmented process spanning across diverse organizational units, external stakeholders, and systems of record, resulting in process uncertainties and in compliance gaps that may expose organizations to reputational and regulatory risks. Moreover, there are complexities associated with meeting the specific dimensions of Trustworthy AI best practices such as data governance, conformance testing, quality assurance of AI model behaviors, transparency, accountability, and confidentiality requirements. These processes involve multiple steps, hand-offs, re-works, and human-in-the-loop oversight. In this paper, we demonstrate that process mining can provide a useful framework for gaining fact-based visibility to AI compliance process execution, surfacing compliance bottlenecks, and providing for an automated approach to analyze, remediate and monitor uncertainty in AI regulatory compliance processes.",,
Trustworthiness of Artificial Intelligence,A AI has a lot of benefits but any mistake in either the development or in the working phase of the AI system can be disastrous.,Search,2020,4,"Sonali  Jain, Manan  Luthra, Shagun  Sharma, Mehtab  Fatima",2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS),,10.1109/ICACCS48705.2020.9074237,https://doi.org/10.1109/ICACCS48705.2020.9074237,https://semanticscholar.org/paper/2efae53ba8d84c6f11d3f7151f23b9e22ca806e4,,"This paper discusses the need for a trustworthy AI, along with the ethics which are required to keep that trust intact. AI has a lot of benefits when it comes to societal, individual or cultural development. But any mistake in either the development or in the working phase of the AI system can be disastrous, especially when human lives are involved. The main goal of this paper is to understand what really makes an Artificial Intelligence system trustworthy.",,
An agile framework for trustworthy AI,The AI High Level Expert Group (AI-HLEG) ethics guidelines present a list of requirements that trustworthy AI systems should meet.,Search,2020,2,"Stefan  Leijnen, Huib  Aldewereld, Rudy van Belkom, Roland  Bijvank, Roelant  Ossewaarde",NeHuAI@ECAI,,,,https://semanticscholar.org/paper/880049a16c8fea47dcfe07450668f5507db5e96d,,"From the article: The ethics guidelines put forward by the AI High Level Expert Group (AI-HLEG) present a list of seven key requirements that Human-centered, trustworthy AI systems should meet. These guidelines are useful for the evaluation of AI systems, but can be complemented by applied methods and tools for the development of trustworthy AI systems in practice. In this position paper we propose a framework for translating the AI-HLEG ethics guidelines into the specific context within which an AI system operates. This approach aligns well with a set of Agile principles commonly employed in software engineering. http://ceur-ws.org/Vol-2659/",,
The European way of doing Artificial Intelligence: The state of play implementing Trustworthy AI,There are few examples of implementing Trustworthy AI on a company level.,Search,2021,,Bernd  Beckert,"2021 60th FITCE Communication Days Congress for ICT Professionals: Industrial Data – Cloud, Low Latency and Privacy (FITCE)",,10.1109/fitce53297.2021.9588560,https://doi.org/10.1109/fitce53297.2021.9588560,https://semanticscholar.org/paper/53b39326e583bb2d44a0a43c9d647a4516de2c27,,"“Trustworthy AI” is the concept of the European Commission to facilitate acceptance and diffusion of Artificial Intelligence in Europe. The concept claims that European AI applications shall be lawful, ethical and robust, both from a technical and societal perspective. The contribution asks for the state of play of implementing the concept of Trustworthy AI. More concretely, it sets out to identify concrete cases of implementing Trustworthy AI in order to analyse approaches and experiences. However, it turns out that such projects currently only exist in a research context and at neither large companies nor start-ups or medium-sized companies provide suitable examples, with only a few exceptions. This gives rise to the question, why companies today ignore or even avoid the carefully worked out guidelines to implement Trustworthy AI. Three answers are given which refer to time-to-market considerations, different mindsets of software engineers and social scientists, and the fact that implementing Trustworthy AI requires of firms to go the extra mile with additional expertise and governance structures. Following this, two possibilities are presented to increase in the number of companies actually picking up on the guidelines and concretely implementing Trustworthy AI. These possibilities are firstly to break down existing implementation guidelines to the requirements of software engineers, computer scientists and managers, and secondly to embed social scientists and stakeholders in the implementation process.",,
Requirements for Trustworthy Artificial Intelligence - A Review,"The field of algorithmic decision-making, particularly Artificial Intelligence (AI), has been drastically changing.",Search,2020,8,"Davinder  Kaur, Suleyman  Uslu, Arjan  Durresi",NBiS,,10.1007/978-3-030-57811-4_11,https://doi.org/10.1007/978-3-030-57811-4_11,https://semanticscholar.org/paper/ab7f6628cbbafae1ce994929af2482efbd092d61,https://scholarworks.iupui.edu/bitstream/1805/28055/1/Kaur2020Requirements-AAM.pdf,"The field of algorithmic decision-making, particularly Artificial Intelligence (AI), has been drastically changing. With the availability of a massive amount of data and an increase in the processing power, AI systems have been used in a vast number of high-stake applications. So, it becomes vital to make these systems reliable and trustworthy. Different approaches have been proposed to make theses systems trustworthy. In this paper, we have reviewed these approaches and summarized them based on the principles proposed by the European Union for trustworthy AI. This review provides an overview of different principles that are important to make AI trustworthy.",,Review
Trustworthy Artificial Intelligence in Education: Pitfalls and Pathways,The Ethics Guidelines of the European Commission’s High-Level Expert Group on AI provide a normative framework for assessing the ethical challenges of Artificial Intelligence in education.,Search,2020,,Nathalie A. Smuha,,,10.2139/ssrn.3742421,https://doi.org/10.2139/ssrn.3742421,https://semanticscholar.org/paper/9b17ebc72dee3cfda651f657106d88d43a486a71,https://lirias.kuleuven.be/bitstream/123456789/677889/2/SSRN-id3742421.pdf,"Across the world, Artificial Intelligence (AI) applications are entering all domains of our lives, including the educational environment. This development was further spurred by the COVID-19 pandemic, which rendered many educational institutions dependent on (AI-enabled) digital learning tools to continue their activities. While the use of AI systems can lead to numerous benefits, it can also entail ethical risks, which are increasingly appearing on legislators’ agendas. Many of these risks are context-specific and increase in significance when vulnerable individuals are involved, asymmetries of power exist, or human rights and democratic values are at stake more generally. Surprisingly, however, regulators have thus far paid only little attention to the specific risks arising in the context of Artificial Intelligence in education (AIED). This paper hence aims to assess the ethical challenges posed by AIED. Its normative framework consists of the seven requirements for Trustworthy AI, as set out in the Ethics Guidelines of the European Commission’s High-Level Expert Group on AI. After an overview of the broader context in which these requirements took shape (Section 2), the paper examines each requirement in the educational realm, as well as the pitfalls that should be addressed to enable their realisation (Section 3). Particular attention is given to the special role of education in shaping people’s minds, and the manner in which this role can be used both to empower and exploit individuals. The paper notes that AIED’s main strengths – offering education on a wider scale, through more flexible and individualised learning methods, and through the closer monitoring of students’ reception of the materials – are also its main liabilities when left unchecked. Finally, the paper discusses various pathways that policymakers should consider to foster Trustworthy AIED beyond the adoption of guidelines (Section 4), before concluding (Section 5).",,Review
Trustworthy AI,"Ensuring the privacy and security of the data, assigning appropriate credits to data sources, and delivering decent outputs are required features of an AI system.",Search,2021,,"Richa  Singh, Mayank  Vatsa, Nalini  Ratha",COMAD/CODS,,10.1145/3430984.3431966,https://doi.org/10.1145/3430984.3431966,https://semanticscholar.org/paper/4f52a1c995d5b7ba2be6d419146dbf9ee6b0316c,,"Modern AI systems are reaping the advantage of novel learning methods. With their increasing usage, we are realizing the limitations and shortfalls of these systems. Brittleness to minor adversarial changes in the input data, ability to explain the decisions, address the bias in their training data, high opacity in terms of revealing the lineage of the system, how they were trained and tested, and under which parameters and conditions they can reliably guarantee a certain level of performance, are some of the most prominent limitations. Ensuring the privacy and security of the data, assigning appropriate credits to data sources, and delivering decent outputs are also required features of an AI system. We propose the tutorial on “Trustworthy AI” to address six critical issues in enhancing user and public trust in AI systems, namely: (i) bias and fairness, (ii) explainability, (iii) robust mitigation of adversarial attacks, (iv) improved privacy and security in model building, (v) being decent, and (vi) model attribution, including the right level of credit assignment to the data sources, model architectures, and transparency in lineage.",,
Formal Model of Trustworthy Artificial Intelligence Based on Standardization,The regulatory framework for artificial intelligence is built on a human-centric basis.,Search,2021,1,"Eduard  Manziuk, Olexander  Barmak, Iurii  Krak, Olexander  Mazurets, Tetiana  Skrypnyk",IntelITSIS,,,,https://semanticscholar.org/paper/746cf930349beb3557ccd171fd4249347755ca10,,"The widespread and rapid distribution and application of artificial intelligence (AI) systems requires the development of formalized approaches and the construction of basic principles for the functioning of domain areas of AI use. This need is embodied in the development of recommendations and standards to obtain maximum benefits from the use of AI and minimize possible risks. The regulatory framework is being built on a human-centric basis. Accordingly, the developed standards should form the basis for further activities aimed at the use of AI and be applicable at all stages of creating practical solutions. Therefore, an important stage is the formalization of requirements, principles and provisions of legal and ethical norms in the form of practical template approaches for practical application. With this method, models and ontology of standardized concept of AI credibility are developed within the research. This made it possible to identify the main concepts that allow forming a position of trust, are a meaningful part of the concept of trustworthy AI, determine the need for its existence and pose a threat to it. On the basis of ontology of the domain area, models were developed and further decomposition of structural substantive concepts was carried out. In the future, the characteristics of the concept of trustworthiness formation are defined.",,
Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims,"Ten mechanisms can provide evidence about the safety, security, fairness, and privacy protection of AI systems.",Search,2020,90,"Miles  Brundage, Shahar  Avin, Jasmine  Wang, Haydn  Belfield, Gretchen  Krueger, Gillian  Hadfield, Heidy  Khlaaf, Jingying  Yang, Helen  Toner, Ruth  Fong, Tegan  Maharaj, Pang Wei Koh, Sara  Hooker, Jade  Leung, Andrew  Trask, Emma  Bluemke, Jonathan  Lebensbold, Cullen  O'Keefe, Mark  Koren, Th'eo  Ryffel, JB  Rubinovitz, Tamay  Besiroglu, Federica  Carugati, Jack  Clark, Peter  Eckersley, Sarah de Haas, Maritza  Johnson, Ben  Laurie, Alex  Ingerman, Igor  Krawczuk, Amanda  Askell, Rosario  Cammarota, Andrew  Lohn, David  Krueger, Charlotte  Stix, Peter  Henderson, Logan  Graham, Carina  Prunkl, Bianca  Martin, Elizabeth  Seger, Noa  Zilberman, Se'an 'O h'Eigeartaigh, Frens  Kroeger, Girish  Sastry, Rebecca  Kagan, Adrian  Weller, Brian  Tse, Elizabeth  Barnes, Allan  Dafoe, Paul  Scharre, Ariel  Herbert-Voss, Martijn  Rasser, Shagun  Sodhani, Carrick  Flynn, Thomas Krendl Gilbert, Lisa  Dyer, Saif  Khan, Yoshua  Bengio, Markus  Anderljung",ArXiv,,,,https://semanticscholar.org/paper/62c3142956d54db158d190ce691e3c13e7897412,,"With the recent wave of progress in artificial intelligence (AI) has come a growing awareness of the large-scale impacts of AI systems, and recognition that existing regulations and norms in industry and academia are insufficient to ensure responsible AI development. In order for AI developers to earn trust from system users, customers, civil society, governments, and other stakeholders that they are building AI responsibly, they will need to make verifiable claims to which they can be held accountable. Those outside of a given organization also need effective means of scrutinizing such claims. This report suggests various steps that different stakeholders can take to improve the verifiability of claims made about AI systems and their associated development processes, with a focus on providing evidence about the safety, security, fairness, and privacy protection of AI systems. We analyze ten mechanisms for this purpose--spanning institutions, software, and hardware--and make recommendations aimed at implementing, exploring, or improving those mechanisms.",,
The challenges and opportunities of artificial intelligence in implementing trustworthy robotics and autonomous systems,"Artificial intelligence can improve the trustworthiness of RAS by addressing challenges in health, safety, and security.",Search,2020,3,"Hongmei  He, J.  Gray, Angelo  Cangelosi, Q.  Meng, T. M. McGinnity, J.  Mehnen",,,,,https://semanticscholar.org/paper/3e130750bc9d95e12b4194b67137d89da0f87a07,,"Effective Robots and Autonomous Systems (RAS) must be trustworthy. Trust is essential in designing autonomous and semi-autonomous technologies, because “No trust, no use”. RAS should provide high quality of services, with the four key properties that make it trust, i.e. they must be (i) robust for any health issues, (ii) safe for any matters in their surrounding environments, (iii) secure for any threats from cyber spaces, and (iv) trusted for human-machine interaction. We have thoroughly analysed the challenges in implementing the trustworthy RAS in respects of the four properties, and addressed the power of AI in improving the trustworthiness of RAS. While we put our eyes on the beneﬁts that AI brings to human, we should realise the potential risks that could be caused by AI. The new concept of human-centred AI will be the core in implementing the trustworthy RAS. This review could provide a brief reference for the research on AI for trustworthy RAS.",,Review