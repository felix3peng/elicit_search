Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
An agile framework for trustworthy AI,The AI High Level Expert Group (AI-HLEG) ethics guidelines present a list of requirements that trustworthy AI systems should meet.,Search,2020,2,"Stefan  Leijnen, Huib  Aldewereld, Rudy van Belkom, Roland  Bijvank, Roelant  Ossewaarde",NeHuAI@ECAI,,,,https://semanticscholar.org/paper/880049a16c8fea47dcfe07450668f5507db5e96d,,"From the article: The ethics guidelines put forward by the AI High Level Expert Group (AI-HLEG) present a list of seven key requirements that Human-centered, trustworthy AI systems should meet. These guidelines are useful for the evaluation of AI systems, but can be complemented by applied methods and tools for the development of trustworthy AI systems in practice. In this position paper we propose a framework for translating the AI-HLEG ethics guidelines into the specific context within which an AI system operates. This approach aligns well with a set of Agile principles commonly employed in software engineering. http://ceur-ws.org/Vol-2659/",,
TAII Framework for Trustworthy AI Systems,The Trustworthy Artificial Intelligence Implementation (TAII) Framework identifies ethical dependencies within companies.,Search,2021,,Josef  Baker-Brunnbauer,,,,,https://semanticscholar.org/paper/c0b7aba59db8da49ca2109b4e90244a7fbb2153c,,"Organizations and companies need practical tools and guidelines to kick-off the implementation of Trustworthy Artificial Intelligence (TAI) systems. AI development companies are still in the beginning of this process or have not even started yet. The findings of this article address to decrease the entry level barrier for AI ethics implementation by introducing the Trustworthy Artificial Intelligence Implementation (TAII) Framework. The outcome is comparatively unique given that it considers a meta perspective of implementing TAI within organizations. As such, this research aims to fill a literature gap for management guidance to tackle trustworthy AI implementation while considering ethical dependencies within the company. The TAII Framework takes a holistic approach to identify the systemic relationships of ethics for the company ecosystem and considers corporate values, business models, and common good aspects like the Sustainable Development Goals and the Universal Declaration of Human Rights. The TAII Framework creates guidance to initiate the implementation of AI ethics in organizations without requiring a deep background in philosophy and considers the social impacts outside of a software and data engineering setting. Depending on the legal regulation or area of application, the TAII Framework can be adapted and used with different regulations and ethical principles.",,
Designing Trustworthy AI: A User Experience (UX) Framework at RSA Conference 2020,AI can be safe and in control by having a user experience framework.,Search,2020,,Carol  Smith,,,10.1184/R1/12198321.V1,https://doi.org/10.1184/R1/12198321.V1,https://semanticscholar.org/paper/a2a2e1d11f3738113b182d5d4e6366a033d96fab,,"Artificial intelligence (AI) holds great promise to empower us with knowledge and scaled effectiveness. To harness the power of AI systems, we can—and must—ensure that we keep humans safe and in control. This session will introduce a new user experience (UX) framework to guide the creation of AI systems that are accountable, de-risked, respectful, secure, honest and usable.",,
"Information Theoretic Evaluation of Privacy-Leakage, Interpretability, and Transferability for a Novel Trustworthy AI Framework",A novel trustworthy AI framework takes into account ethical AI principles during the development of machine learning and deep learning models.,Search,2021,,"Mohit  Kumar, Bernhard A. Moser, Lukas  Fischer, Bernhard  Freudenthaler",ArXiv,,,,https://semanticscholar.org/paper/4deb5a713cba1b041092bcb923719b22bf8fcc56,,"Guidelines and principles of trustworthy AI should be adhered to in practice during the development of AI systems. This work suggests a novel information theoretic trustworthy AI framework based on the hypothesis that information theory enables taking into account the ethical AI principles during the development of machine learning and deep learning models via providing a way to study and optimize the inherent tradeoffs between trustworthy AI principles. Under the proposed framework, a unified approach to “privacy-preserving interpretable and transferable learning” is considered to introduce the information theoretic measures for privacy-leakage, interpretability, and transferability. A technique based on variational optimization, employing conditionally deep autoencoders, is developed for practically calculating the defined information theoretic measures for privacy-leakage, interpretability, and transferability.",,
Trustworthy AI Implementation (TAII) Framework for AI Systems,The Trustworthy AI Implementation (TAII) framework combines AI ethics research with previous research findings to create the Trustworthy AI Implementation (TAII).,Search,2021,1,Josef  Baker-Brunnbauer,,,10.2139/SSRN.3796799,https://doi.org/10.2139/SSRN.3796799,https://semanticscholar.org/paper/3337ff3dd257ae6cb5d276e34aa06f190ab06265,,"Companies and their stakeholder need practical tools and implementation guidelines besides abstract frameworks to kick off the realization of Artificial Intelligence (AI) ethics. Based on my previous research outcome AI development companies are still in the beginning of this process or have not even started yet. How is it possible to decrease the entry level barrier to kickoff AI ethics implementation? I tackle this question by combining AI ethics research with previous research findings to create the Trustworthy AI Implementation (TAII) framework. A literature review was conducted and that specifies the research and implementation status for each process step. The aim is to kickoff AI ethics and to transfer research and abstract guidelines from academia to business. The TAII process generates a meta perspective on the systemic dependencies of ethics for the company ecosystem. It generates orienteering for the AI ethics kickoff without requiring a deep background in philosophy and considers perspectives of social impact outside the software and data engineering setting. Depending on the legal regulation or area of application, the TAII process can be adapted and used with different regulations and ethical principles.",,Review
Trustworthy AI: From Principles to Practices,"A systematic approach that considers the entire lifecycle of AI systems, ranging from data acquisition to model development, to development and deployment, can improve AI trustworthiness.",Search,2021,1,"Bo  Li, Peng  Qi, Bo  Liu, Shuai  Di, Jingen  Liu, Jiquan  Pei, Jinfeng  Yi, Bowen  Zhou",ArXiv,,,,https://semanticscholar.org/paper/c3689493757f90267908e776aeada9194fce55c7,,"Fast developing artificial intelligence (AI) technology has enabled various applied systems deployed in the real world, impacting people’s everyday lives. However, many current AI systems were found vulnerable to imperceptible attacks, biased against underrepresented groups, lacking in user privacy protection, etc., which not only degrades user experience but erodes the society’s trust in all AI systems. In this review, we strive to provide AI practitioners a comprehensive guide towards building trustworthy AI systems. We first introduce the theoretical framework of important aspects of AI trustworthiness, including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, alignment with human values, and accountability. We then survey leading approaches in these aspects in the industry. To unify the current fragmented approaches towards trustworthy AI, we propose a systematic approach that considers the entire lifecycle of AI systems, ranging from data acquisition to model development, to development and deployment, finally to continuous monitoring and governance. In this framework, we offer concrete action items to practitioners and societal stakeholders (e.g., researchers and regulators) to improve AI trustworthiness. Finally, we identify key opportunities and challenges in the future development of trustworthy AI systems, where we identify the need for paradigm shift towards comprehensive trustworthy AI systems.",,Review
Designing Trustworthy AI: A Human-Machine Teaming Framework to Guide Development,"A Human-Machine Teaming Framework for Designing Ethical AI Experiences will guide AI development teams to create AI systems that are accountable, de-risked, respectful, secure, honest, and usable.",Search,2019,4,Carol J. Smith,ArXiv,,10.1184/R1/12119847.V1,https://doi.org/10.1184/R1/12119847.V1,https://semanticscholar.org/paper/e4213c10a8894e9a767633ed12a605fd65beb95b,,"Artificial intelligence (AI) holds great promise to empower us with knowledge and augment our effectiveness. We can -- and must -- ensure that we keep humans safe and in control, particularly with regard to government and public sector applications that affect broad populations. How can AI development teams harness the power of AI systems and design them to be valuable to humans? Diverse teams are needed to build trustworthy artificial intelligent systems, and those teams need to coalesce around a shared set of ethics. There are many discussions in the AI field about ethics and trust, but there are few frameworks available for people to use as guidance when creating these systems. The Human-Machine Teaming (HMT) Framework for Designing Ethical AI Experiences described in this paper, when used with a set of technical ethics, will guide AI development teams to create AI systems that are accountable, de-risked, respectful, secure, honest, and usable. To support the team's efforts, activities to understand people's needs and concerns will be introduced along with the themes to support the team's efforts. For example, usability testing can help determine if the audience understands how the AI system works and complies with the HMT Framework. The HMT Framework is based on reviews of existing ethical codes and best practices in human-computer interaction and software development. Human-machine teams are strongest when human users can trust AI systems to behave as expected, safely, securely, and understandably. Using the HMT Framework to design trustworthy AI systems will provide support to teams in identifying potential issues ahead of time and making great experiences for humans.",,Review
Towards trustworthy AI: safe-visor architecture for uncertified controllers in stochastic cyber-physical systems,A history-based supervisor and a safety advisor can provide safety guarantees for an AI-based controller.,Search,2021,,"Abolfazl  Lavaei, Bingzhuo  Zhong, Marco  Caccamo, Majid  Zamani",CAADCPS@CPSIoTWeek,,10.1145/3457335.3461705,https://doi.org/10.1145/3457335.3461705,https://semanticscholar.org/paper/8d4b027951bd4bde6933e457bc89323cf8d9ea43,,"Artificial intelligence-based (a.k.a. AI-based) controllers have received significant attentions in the past few years due to their broad applications in cyber-physical systems (CPSs) to accomplish complex control missions. However, guaranteeing safety and reliability of CPSs equipped with this kind of (uncertified) controllers is currently very challenging, which is of vital importance in many real-life safety-critical applications. To cope with this difficulty, we propose a Safe-visor architecture for sandboxing AI-based controllers in stochastic CPSs. The proposed framework contains (i) a history-based supervisor which checks inputs from the AI-based controller and makes compromise between functionality and safety of the system, and (ii) a safety advisor that provides fallback when the AI-based controller endangers the safety of the system. By employing this architecture, we provide formal probabilistic guarantees on the satisfaction of those classes of safety specifications which can be represented by the accepting languages of deterministic finite automata (DFA), while AI-based controllers can still be employed in the control loop even though they are not reliable.",,
Trustworthy artificial intelligence,A data-driven research framework for Trustworthy AI can facilitate research on the distributed ledger technology-based realization of Trustworthy AI.,Search,2021,21,"Scott  Thiebes, Sebastian  Lins, Ali  Sunyaev",Electron. Mark.,,10.1007/S12525-020-00441-4,https://doi.org/10.1007/S12525-020-00441-4,https://semanticscholar.org/paper/9da092d7c7674e96830f8d6713a9a4f8101f984c,https://link.springer.com/content/pdf/10.1007/s12525-020-00441-4.pdf,"Artificial intelligence (AI) brings forth many opportunities to contribute to the wellbeing of individuals and the advancement of economies and societies, but also a variety of novel ethical, legal, social, and technological challenges. Trustworthy AI (TAI) bases on the idea that trust builds the foundation of societies, economies, and sustainable development, and that individuals, organizations, and societies will therefore only ever be able to realize the full potential of AI, if trust can be established in its development, deployment, and use. With this article we aim to introduce the concept of TAI and its five foundational principles (1) beneficence, (2) non-maleficence, (3) autonomy, (4) justice, and (5) explicability. We further draw on these five principles to develop a data-driven research framework for TAI and demonstrate its utility by delineating fruitful avenues for future research, particularly with regard to the distributed ledger technology-based realization of TAI.",,
A Trustworthy Framework of Artificial Intelligence for Power Grid Dispatching Systems,The HGAT-Explainer model can provide more favorable support for trustworthy-AI systems.,Search,2021,,"Ke  Zhang, Peidong  Xu, Tianlu  Gao, Jun  ZHANG",2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI),,10.1109/DTPI52967.2021.9540198,https://doi.org/10.1109/DTPI52967.2021.9540198,https://semanticscholar.org/paper/b48289ecaf70a5ef5de7f28f1590107581c4348d,,"With the widespread application of artificial intelligence (AI) technologies in power systems, the properties of lack of reliability and transparency for AI technologies have revealed gradually. Here, how to build a trustworthy-AI framework based on the power system is the focus. Due to the multidimensional and heterogeneous information of power grid data, the heterogeneous graph attention network (HGAT) model of power grid dispatching is established, and the corresponding explainer (HGAT-Explainer) for the model of power equipment faults is proposed to provide more favorable support for the trustworthy-AI systems.",,
The EU Approach to Ethics Guidelines for Trustworthy Artificial Intelligence,The EU Commission established an independent High-Level Expert Group on Artificial Intelligence (AI HLEG).,Search,2019,56,Nathalie A. Smuha,Computer Law Review International,,10.9785/cri-2019-200402,https://doi.org/10.9785/cri-2019-200402,https://semanticscholar.org/paper/a00ee7ae4642b986b622e0f48c845e79707b707b,https://lirias.kuleuven.be/bitstream/123456789/640572/2/EU%20Approach%20for%20Trustworthy%20AI%20-%20a%20continuous%20journey.pdf,"As part of its European strategy for Artificial Intelligence (AI), and as a response to the increasing ethical questions raised by this technology, the European Commission established an independent High-Level Expert Group on Artificial Intelligence (AI HLEG) in June 2018. The group was tasked to draft two deliverables: AI Ethics Guidelines and Policy and Investment Recommendations. Nine months later, its first deliverable was published, putting forward a comprehensive framework to achieve “Trustworthy AI” by offering ethical guidance to AI practitioners. This paper dives into the work carried out by the group, focusing in particular on its AI Ethics Guidelines. First, this paper clarifies the context that led to the creation of the AI HLEG and its mandate (I.). Subsequently, it elaborates on the Guidelines’ aim and purpose (II.), and analyses the Guidelines’ drafting process (III.). Particular focus is given to the questions surrounding the respective role played by ethics and law in the AI governance landscape (IV.), as well as some of the challenges that had to be overcome throughout the process (V.). Finally, this paper places the Guidelines in an international context, and sets out the next steps (VI.) ahead on the journey towards an appropriate governance framework for AI (VII.).",,
The relationship between trust in AI and trustworthy machine learning technologies,Trust can be impacted throughout the life cycle of AI-based systems.,Search,2020,50,"Ehsan  Toreini, Mhairi  Aitken, Kovila  Coopamootoo, Karen  Elliott, Carlos Gonzalez Zelaya, Aad van Moorsel",FAT*,,10.1145/3351095.3372834,https://doi.org/10.1145/3351095.3372834,https://semanticscholar.org/paper/bd4cf5a6987ef0f39b7e4e88d59b3a3365abcc70,http://arxiv.org/pdf/1912.00782,"To design and develop AI-based systems that users and the larger public can justifiably trust, one needs to understand how machine learning technologies impact trust. To guide the design and implementation of trusted AI-based systems, this paper provides a systematic approach to relate considerations about trust from the social sciences to trustworthiness technologies proposed for AI-based services and products. We start from the ABI+ (Ability, Benevolence, Integrity, Predictability) framework augmented with a recently proposed mapping of ABI+ on qualities of technologies that support trust. We consider four categories of trustworthiness technologies for machine learning, namely these for Fairness, Explainability, Auditability and Safety (FEAS) and discuss if and how these support the required qualities. Moreover, trust can be impacted throughout the life cycle of AI-based systems, and we therefore introduce the concept of Chain of Trust to discuss trustworthiness technologies in all stages of the life cycle. In so doing we establish the ways in which machine learning technologies support trusted AI-based systems. Finally, FEAS has obvious relations with known frameworks and therefore we relate FEAS to a variety of international 'principled AI' policy and technology frameworks that have emerged in recent years.",,
Formal Model of Trustworthy Artificial Intelligence Based on Standardization,The regulatory framework for AI is built on a human-centric basis and requires the development of standards.,Search,2021,1,"Eduard  Manziuk, Olexander  Barmak, Iurii  Krak, Olexander  Mazurets, Tetiana  Skrypnyk",IntelITSIS,,,,https://semanticscholar.org/paper/746cf930349beb3557ccd171fd4249347755ca10,,"The widespread and rapid distribution and application of artificial intelligence (AI) systems requires the development of formalized approaches and the construction of basic principles for the functioning of domain areas of AI use. This need is embodied in the development of recommendations and standards to obtain maximum benefits from the use of AI and minimize possible risks. The regulatory framework is being built on a human-centric basis. Accordingly, the developed standards should form the basis for further activities aimed at the use of AI and be applicable at all stages of creating practical solutions. Therefore, an important stage is the formalization of requirements, principles and provisions of legal and ethical norms in the form of practical template approaches for practical application. With this method, models and ontology of standardized concept of AI credibility are developed within the research. This made it possible to identify the main concepts that allow forming a position of trust, are a meaningful part of the concept of trustworthy AI, determine the need for its existence and pose a threat to it. On the basis of ontology of the domain area, models were developed and further decomposition of structural substantive concepts was carried out. In the future, the characteristics of the concept of trustworthiness formation are defined.",,
Trustworthy AI Development Guidelines for Human System Interaction,AI development guidelines can improve the user trust in AI systems to enhance human-AI interactions.,Search,2020,3,"Chathurika S. Wickramasinghe, Daniel L. Marino, Javier  Grandio, Milos  Manic",2020 13th International Conference on Human System Interaction (HSI),,10.1109/HSI49210.2020.9142644,https://doi.org/10.1109/HSI49210.2020.9142644,https://semanticscholar.org/paper/238fa66062114f39e404c40d0b1abc03b86e54bd,,"Artificial Intelligence (AI) is influencing almost all areas of human life. Even though these AI-based systems frequently provide state-of-the-art performance, humans still hesitate to develop, deploy, and use AI systems. The main reason for this is the lack of trust in AI systems caused by the deficiency of transparency of existing AI systems. As a solution, “Trustworthy AI” research area merged with the goal of defining guidelines and frameworks for improving user trust in AI systems, allowing humans to use them without fear. While trust in AI is an active area of research, very little work exists where the focus is to build human trust to improve the interactions between human and AI systems. In this paper, we provide a concise survey on concepts of trustworthy AI. Further, we present trustworthy AI development guidelines for improving the user trust to enhance the interactions between AI systems and humans, that happen during the AI system life cycle.",,
Establishing the rules for building trustworthy AI,The European Commission’s report ‘Ethics guidelines for trustworthy AI’ facilitates international support for AI solutions that are good for humanity and the environment.,Search,2019,67,Luciano  Floridi,Nature Machine Intelligence,,10.1038/S42256-019-0055-Y,https://doi.org/10.1038/S42256-019-0055-Y,https://semanticscholar.org/paper/dc44e2be0f85b6225f05390c570885337a99ef83,https://philpapers.org/archive/FLOETR.pdf,"The European Commission’s report ‘Ethics guidelines for trustworthy AI’ provides a clear benchmark to evaluate the responsible development of AI systems, and facilitates international support for AI solutions that are good for humanity and the environment, says Luciano Floridi.",,
Trustworthy AI,The pursuit of responsible AI raises the ante on both the trustworthy computing and formal methods communities.,Search,2021,7,Jeannette M. Wing,Commun. ACM,,10.1145/3448248,https://doi.org/10.1145/3448248,https://semanticscholar.org/paper/33cf9b4d6c76f988380b1adff2c06c30010f93d3,https://dl.acm.org/doi/pdf/10.1145/3448248,The pursuit of responsible AI raises the ante on both the trustworthy computing and formal methods communities.,,