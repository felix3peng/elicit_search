Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Enhanced well-being assessment as basis for the practical implementation of ethical and rights-based normative principles for AI,A well-being impact assessment framework could enable a human-centered AI impact assessment.,Search,2020,3,"Marek  Havrda, Bogdana  Rakova","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",,10.1109/SMC42975.2020.9283137,https://doi.org/10.1109/SMC42975.2020.9283137,https://semanticscholar.org/paper/867ba0f0e4843b889ec1d96ae52bd7f3c49f7603,http://arxiv.org/pdf/2007.14826,"Artificial Intelligence (AI) has an increasing impact on all areas of people’s livelihoods. A detailed look at existing interdisciplinary and transdisciplinary metrics frameworks could bring new insights and enable practitioners to navigate the challenge of understanding and assessing the impact of Autonomous and Intelligent Systems (A/IS). There has been emerging consensus on fundamental ethical and rights-based AI principles proposed by scholars, governments, civil rights organizations, and technology companies. In order to move from principles to real-world implementation, we adopt a lens motivated by regulatory impact assessments and the well-being movement in public policy. Similar to public policy interventions, outcomes of AI systems implementation may have far-reaching complex impacts. In public policy, indicators are only part of a broader toolbox, as metrics inherently lead to gaming and dissolution of incentives and objectives. Similarly, in the case of A/IS, there’s a need for a larger toolbox that allows for the iterative assessment of identified impacts, inclusion of new impacts in the analysis, and identification of emerging trade-offs. In this paper, we propose the practical application of an enhanced well-being impact assessment framework for A/IS that could be employed to address ethical and rights-based normative principles in AI. This process could enable a human-centered algorithmically-supported approach to the understanding of the impacts of AI systems. Finally, we propose a new testing infrastructure which would allow for governments, civil rights organizations, and others, to engage in cooperating with A/IS developers towards implementation of enhanced well-being impact assessments.",,
A Unified Framework of Five Principles for AI in Society,"A new principle, explicability, is needed in addition to the core principles of ethical AI.",Search,2019,152,"Luciano  Floridi, Josh  Cowls",Issue 1,,10.1162/99608F92.8CD550D1,https://doi.org/10.1162/99608F92.8CD550D1,https://semanticscholar.org/paper/8499e44d42b12518495069a54ae4400baccb7546,https://assets.pubpub.org/ukqte8ry/c8d3cba5-8f10-4a00-894c-3a3b886ad844.pdf,"Artificial Intelligence (AI) is already having a major impact on society. As a result, many organizations have launched a wide range of initiatives to establish ethical principles for the adoption of socially beneficial AI. Unfortunately, the sheer volume of proposed principles threatens to overwhelm and confuse. How might this problem of ‘principle proliferation’ be solved? In this paper, we report the results of a fine-grained analysis of several of the highest-profile sets of ethical principles for AI. We assess whether these principles converge upon a set of agreed-upon principles, or diverge, with significant disagreement over what constitutes ‘ethical AI.’ Our analysis finds a high degree of overlap among the sets of principles we analyze. We then identify an overarching framework consisting of five core principles for ethical AI. Four of them are core principles commonly used in bioethics: beneficence, non-maleficence, autonomy, and justice. On the basis of our comparative analysis, we argue that a new principle is needed in addition: explicability, understood as incorporating both the epistemological sense of intelligibility (as an answer to the question ‘how does it work?’) and in the ethical sense of accountability (as an answer to the question: ‘who is responsible for the way it works?’). In the ensuing discussion, we note the limitations and assess the implications of this ethical framework for future efforts to create laws, rules, technical standards, and best practices for ethical AI in a wide range of contexts.KeywordsAccountability; Autonomy; Artificial Intelligence; Beneficence; Ethics; Explicability; Fairness; Intelligibility; Justice; Non-maleficence.",,
Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI,There is a growing consensus around eight key thematic trends in AI principles documents.,Search,2020,137,"Jessica  Fjeld, Nele  Achten, Hannah  Hilligoss, Adam  Nagy, Madhulika  Srikumar",SSRN Electronic Journal,,10.2139/ssrn.3518482,https://doi.org/10.2139/ssrn.3518482,https://semanticscholar.org/paper/58bb24b72fea6d0ce172bdaf9c2f16c2bd7649e9,https://dash.harvard.edu/bitstream/1/42160420/1/HLS%20White%20Paper%20Final_v3.pdf,"The rapid spread of artificial intelligence (AI) systems has precipitated a rise in ethical and human rights-based frameworks intended to guide the development and use of these technologies. Despite the proliferation of these ""AI principles,"" there has been little scholarly focus on understanding these efforts either individually or as contextualized within an expanding universe of principles with discernible trends.

To that end, this white paper and its associated data visualization compare the contents of thirty-six prominent AI principles documents side-by-side. This effort uncovered a growing consensus around eight key thematic trends: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. Underlying this “normative core,” our analysis examined the forty-seven individual principles that make up the themes, detailing notable similarities and differences in interpretation found across the documents. In sharing these observations, it is our hope that policymakers, advocates, scholars, and others working to maximize the benefits and minimize the harms of AI will be better positioned to build on existing efforts and to push the fractured, global conversation on the future of AI toward consensus.",,
Actionable Principles for Artificial Intelligence Policy: Three Pathways,AI Ethics Principles are often unactionable in governmental policy.,Search,2021,9,Charlotte  Stix,Sci. Eng. Ethics,,10.1007/s11948-020-00277-3,https://doi.org/10.1007/s11948-020-00277-3,https://semanticscholar.org/paper/16dc267a80a87e81e6a8ec4ed8c5a020657dd7da,https://link.springer.com/content/pdf/10.1007/s11948-020-00277-3.pdf,"In the development of governmental policy for artificial intelligence (AI) that is informed by ethics, one avenue currently pursued is that of drawing on “AI Ethics Principles”. However, these AI Ethics Principles often fail to be actioned in governmental policy. This paper proposes a novel framework for the development of ‘Actionable Principles for AI’. The approach acknowledges the relevance of AI Ethics Principles and homes in on methodological elements to increase their practical implementability in policy processes. As a case study, elements are extracted from the development process of the Ethics Guidelines for Trustworthy AI of the European Commission’s “High Level Expert Group on AI”. Subsequently, these elements are expanded on and evaluated in light of their ability to contribute to a prototype framework for the development of 'Actionable Principles for AI'. The paper proposes the following three propositions for the formation of such a prototype framework: (1) preliminary landscape assessments; (2) multi-stakeholder participation and cross-sectoral feedback; and, (3) mechanisms to support implementation and operationalizability.",,
Principles Alone Cannot Guarantee Ethical AI,AI ethics initiatives have seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics.,Search,2019,63,Brent  Mittelstadt,,,10.2139/ssrn.3391293,https://doi.org/10.2139/ssrn.3391293,https://semanticscholar.org/paper/ddc2d6d51b2f00a70320e293473035b993192949,,"Artificial intelligence (AI) ethics is now a global topic of discussion in academic and policy circles. At least 84 public–private initiatives have produced statements describing high-level principles, values and other tenets to guide the ethical development, deployment and governance of AI. According to recent meta-analyses, AI ethics has seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics. Despite the initial credibility granted to a principled approach to AI ethics by the connection to principles in medical ethics, there are reasons to be concerned about its future impact on AI development and governance. Significant differences exist between medicine and AI development that suggest a principled approach for the latter may not enjoy success comparable to the former. Compared to medicine, AI development lacks (1) common aims and fiduciary duties, (2) professional history and norms, (3) proven methods to translate principles into practice, and (4) robust legal and professional accountability mechanisms. These differences suggest we should not yet celebrate consensus around high-level principles that hide deep political and normative disagreement. AI ethics initiatives have seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics. Despite this, Brent Mittelstadt highlights important differences between medical practice and AI development that suggest a principled approach may not work in the case of AI.",,
Principles alone cannot guarantee ethical AI,"AI development lacks common aims, fiduciary duties, professional history and norms, proven methods to translate principles into practice, and robust legal and professional accountability mechanisms.",Search,2019,162,Brent  Mittelstadt,Nat. Mach. Intell.,,10.1038/s42256-019-0114-4,https://doi.org/10.1038/s42256-019-0114-4,https://semanticscholar.org/paper/2014d6036276b470d010060c86cedd4c92e0958c,http://arxiv.org/pdf/1906.06668,"Artificial intelligence (AI) ethics is now a global topic of discussion in academic and policy circles. At least 84 public–private initiatives have produced statements describing high-level principles, values and other tenets to guide the ethical development, deployment and governance of AI. According to recent meta-analyses, AI ethics has seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics. Despite the initial credibility granted to a principled approach to AI ethics by the connection to principles in medical ethics, there are reasons to be concerned about its future impact on AI development and governance. Significant differences exist between medicine and AI development that suggest a principled approach for the latter may not enjoy success comparable to the former. Compared to medicine, AI development lacks (1) common aims and fiduciary duties, (2) professional history and norms, (3) proven methods to translate principles into practice, and (4) robust legal and professional accountability mechanisms. These differences suggest we should not yet celebrate consensus around high-level principles that hide deep political and normative disagreement.AI ethics initiatives have seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics. Despite this, Brent Mittelstadt highlights important differences between medical practice and AI development that suggest a principled approach may not work in the case of AI.",,
"AI Evaluation: past, present and future",AI systems are becoming more complex and unpredictable due to the traditional task-oriented evaluation approach.,Search,2014,24,José  Hernández-Orallo,ArXiv,,,,https://semanticscholar.org/paper/8f2d78fb9293eac038a6a431d23ca5a18df7bfb4,,"Artificial intelligence develops techniques and systems whose performance must be evaluated on a regular basis in order to certify and foster progress in the discipline. We will describe and critically assess the different ways AI systems are evaluated. We first focus on the traditional task-oriented evaluation approach. We see that black-box (behavioural evaluation) is becoming more and more common, as AI systems are becoming more complex and unpredictable. We identify three kinds of evaluation: Human discrimination, problem benchmarks and peer confrontation. We describe the limitations of the many evaluation settings and competitions in these three categories and propose several ideas for a more systematic and robust evaluation. We then focus on a less customary (and challenging) ability-oriented evaluation approach, where a system is characterised by its (cognitive) abilities, rather than by the tasks it is designed to solve. We discuss several possibilities: the adaptation of cognitive tests used for humans and animals, the development of tests derived from algorithmic information theory or more general approaches under the perspective of universal psychometrics.",,
Requirements for AI Assessment,"The development of AI systems represents a significant investment and to realize the promise of that investment, performance assessment is necessary.",Search,2021,,"Gary Klein Mohammad Jalaeian Macrocognition, Robert R. Hoffman",,,,,https://semanticscholar.org/paper/5cfa64c13d88cf571a2a395862664b4cd7948207,,"The development of AI systems represents a significant investment. But to realize the promise of that investment, performance assessment is necessary. Empirical evaluation of Human-AI work systems must adduce convincing empirical evidence that the work method and its AI technology are learnable, usable, and useful. The theme to this Report is the notion that AI assessment must be effective but must also be efficient. Bench testing of a prototype of an AI system cannot require extensive series of experiments with complex designs. Thus, the empirical requirements that are presented in this Report involve escaping some of the constraints that are imposed in traditional laboratory research. Also, there is a recognition of new constraints that are unique to AI evaluation contexts. Empirical requirements are presented covering study design, research methods, statistical analyses, and online experimentation. The 15 requirements presented in this Report should be applicable to all research intended to evaluate the effectivity of AI systems.",,
A Survey on Ethical Principles of AI and Implementations,Ethical principles are required in every stage of the AI lifecycle to ensure that AI systems are ethical.,Search,2020,2,"Jianlong  Zhou, Fang  Chen, Adam  Berry, Mike  Reed, Shujia  Zhang, Siobhan  Savage",2020 IEEE Symposium Series on Computational Intelligence (SSCI),,10.1109/SSCI47803.2020.9308437,https://doi.org/10.1109/SSCI47803.2020.9308437,https://semanticscholar.org/paper/66a07e8609b74a0967828bb179e84444c2d312a8,https://opus.lib.uts.edu.au/bitstream/10453/146673/2/IEEE_ETHAI2020_ethicalAI_Survey.pdf,"AI has powerful capabilities in prediction, automation, planning, targeting, and personalisation. Generally, it is assumed that AI can enable machines to exhibit human-like intelligence, and is claimed to benefit to different areas of our lives. Since AI is fueled by data and is a distinct form of autonomous and self-learning agency, we are seeing increasing ethical concerns related to AI uses. In order to mitigate various ethical concerns, national and international organisations including governmental organisations, private sectors as well as research institutes have made extensive efforts by drafting ethical principles of AI, and having active discussions on ethics of AI within and beyond the AI community. This paper investigates these efforts with a focus on the identification of fundamental ethical principles of AI and their implementations. The review found that there is a convergence around limited principles and the most prevalent principles are transparency, justice and fairness, responsibility, non-maleficence, and privacy. The investigation suggests that ethical principles need to be combined with every stages of the AI lifecycle in the implementation to ensure that the AI system is designed, implemented and deployed in an ethical manner. Similar to ethical framework used in biomedical and clinical research, this paper suggests checklist-style questionnaires as benchmarks for the implementation of ethical principles of AI.",,Review
Multisource AI Scorecard Table for System Evaluation,,Search,2021,6,"Erik  Blasch, James  Sung, Tao  Nguyen",ArXiv,,,,https://semanticscholar.org/paper/a45c902c144113708cb050edb67fca0dee303e3e,,"The paper describes a Multisource AI Scorecard Table (MAST) that provides the developer and user of an artificial intelligence (AI)/machine learning (ML) system with a standard checklist focused on the principles of good analysis adopted by the intelligence community (IC) to help promote the development of more understandable systems and engender trust in AI outputs. Such a scorecard enables a transparent, consistent, and meaningful understanding of AI tools applied for commercial and government use. A standard is built on compliance and agreement through policy, which requires buy-in from the stakeholders. While consistency for testing might only exist across a standard data set, the community requires discussion on verification and validation approaches which can lead to interpretability, explainability, and proper use. The paper explores how the analytic tradecraft standards outlined in Intelligence Community Directive (ICD) 203 can provide a framework for assessing the performance of an AI system supporting various operational needs. These include sourcing, uncertainty, consistency, accuracy, and visualization. Three use cases are presented as notional examples that support security for comparative analysis.",,
AI Assurance Processes,,Search,2020,4,"Emre  Kazim, Adriano  Koshiyama",SSRN Electronic Journal,,10.2139/ssrn.3685087,https://doi.org/10.2139/ssrn.3685087,https://semanticscholar.org/paper/46d129ded58b32e597935f6b5c733c2e8c36b1c7,,"The ethics of Artificial Intelligence (AI Ethics) can be thought of as undergoing three broad phases, with the first two being principles and processes, to the current phase which we read in terms of assurance. In this article we anticipate and expand upon themes in the AI assurance space: namely; i. general and sector specific assurance, ii. governance via technical and impact assessments, iii. the use of ‘traffic-light’ user friendly monitoring interfaces, iv. risk assessments and ‘red teaming’ in order to mitigate unknown risks, v. certification, and vi. insurance of AI systems. The article concludes by noting that the manner in which AI assurance matures is likely to be as a result of the extent and reach of any regulatory intervention.",,
Unifying Principles and Metrics for Safe and Assistive AI,AI safety focuses on designing AI systems that allow humans to safely instruct and control AI systems.,Search,2021,4,Siddharth  Srivastava,AAAI,,,,https://semanticscholar.org/paper/967cba5849f93869655af8d3d8fda9b0a3304a1d,,"The prevalence and success of AI applications have been tempered by concerns about the controllability of AI systems about AI’s impact on the future of work. These concerns reflect two aspects of a central question: how would humans work with AI systems? While research on AI safety focuses on designing AI systems that allow humans to safely instruct and control AI systems, research on AI and the future of work focuses on the impact of AI on humans who may be unable to do so. This Blue Sky Ideas paper proposes a unifying set of declarative principles that enable a more uniform evaluation of arbitrary AI systems along multiple dimensions of the extent to which they are suitable for use by specific classes of human operators. It leverages recent AI research and the unique strengths of the field to develop human-centric principles for AI systems that address the concerns noted above.",,
Evaluation in artificial intelligence: from task-oriented to ability-oriented measurement,Traditional AI evaluation schemes and competitions have many limitations.,Search,2016,80,José  Hernández-Orallo,Artificial Intelligence Review,,10.1007/s10462-016-9505-7,https://doi.org/10.1007/s10462-016-9505-7,https://semanticscholar.org/paper/1a48604fbc09f88a89e551ed70dda07bdb6f01e5,https://riunet.upv.es/bitstream/10251/83598/3/AIRE-Evaluation-of-AI.pdf,"The evaluation of artificial intelligence systems and components is crucial for the progress of the discipline. In this paper we describe and critically assess the different ways AI systems are evaluated, and the role of components and techniques in these systems. We first focus on the traditional task-oriented evaluation approach. We identify three kinds of evaluation: human discrimination, problem benchmarks and peer confrontation. We describe some of the limitations of the many evaluation schemes and competitions in these three categories, and follow the progression of some of these tests. We then focus on a less customary (and challenging) ability-oriented evaluation approach, where a system is characterised by its (cognitive) abilities, rather than by the tasks it is designed to solve. We discuss several possibilities: the adaptation of cognitive tests used for humans and animals, the development of tests derived from algorithmic information theory or more integrated approaches under the perspective of universal psychometrics. We analyse some evaluation tests from AI that are better positioned for an ability-oriented evaluation and discuss how their problems and limitations can possibly be addressed with some of the tools and ideas that appear within the paper. Finally, we enumerate a series of lessons learnt and generic guidelines to be used when an AI evaluation scheme is under consideration.",,
The Role and Limits of Principles in AI Ethics: Towards a Focus on Tensions,,Search,2019,72,"Jess  Whittlestone, Rune  Nyrup, Anna  Alexandrova, Stephen  Cave",AIES,,10.1145/3306618.3314289,https://doi.org/10.1145/3306618.3314289,https://semanticscholar.org/paper/304f2d1cf97ac8fb071b5357e97691d64f4e8f6a,https://dl.acm.org/doi/pdf/10.1145/3306618.3314289,"The last few years have seen a proliferation of principles for AI ethics. There is substantial overlap between different sets of principles, with widespread agreement that AI should be used for the common good, should not be used to harm people or undermine their rights, and should respect widely held values such as fairness, privacy, and autonomy. While articulating and agreeing on principles is important, it is only a starting point. Drawing on comparisons with the field of bioethics, we highlight some of the limitations of principles: in particular, they are often too broad and high-level to guide ethics in practice. We suggest that an important next step for the field of AI ethics is to focus on exploring the tensions that inevitably arise as we try to implement principles in practice. By explicitly recognising these tensions we can begin to make decisions about how they should be resolved in specific cases, and develop frameworks and guidelines for AI ethics that are rigorous and practically relevant. We discuss some different specific ways that tensions arise in AI ethics, and what processes might be needed to resolve them.",,
Requirements for the Empirical Assessment of Human-AI Work Systems: A Contribution to AI Measurement Science,,Search,2021,,"Gary  Klein, Robert  Hoffman, Shane T. Mueller, William  Clancey",,,10.31234/osf.io/j8t3c,https://doi.org/10.31234/osf.io/j8t3c,https://semanticscholar.org/paper/e30bde5f5e543771f085ab0cfb06b54ee0f5ebad,,"The development of AI systems represents a significant investment. But to realize the promise of that investment, performance assessment is necessary. Empirical evaluation of Human-AI work systems must adduce convincing empirical evidence that the work method and its AI technology are learnable, usable, and useful. The theme to this Report is the notion that AI assessment must be effective but must also be efficient. Bench testing of a prototype of an AI system cannot require extensive series of experiments with complex designs. Thus, the empirical requirements that are presented in this Report involve escaping some of the constraints that are imposed in traditional laboratory research. Also, there is a recognition of new constraints that are unique to AI evaluation contexts. Empirical requirements are presented covering study design, research methods, statistical analyses, and online experimentation. The 15 requirements presented in this Report should be applicable to all research intended to evaluate the effectivity of AI systems.",,
A Review of AI and AI Intelligence Assessment,AI research is limited and quantitative methods lack to assess intelligence objectively and quantitatively.,Search,2020,,"Tianyun  Zhang, Tianlu  Gao, Peidong  Xu, Jun  Zhang",2020 IEEE 4th Conference on Energy Internet and Energy System Integration (EI2),,10.1109/EI250167.2020.9347303,https://doi.org/10.1109/EI250167.2020.9347303,https://semanticscholar.org/paper/bfa4c82684d72c399b7d2c0fc2e340eb80e80487,,"The design and application of AI systems have witnessed rapid development in various fields over a period of three scores, accompanied by researcher’s increasing interest in developing a more intelligent and humanoid AI system. Naturally, it becomes more essential to assess the intelligence of AI objectively and quantitatively, as related researches are still limited and the quantitative methods lack. In this paper, we first comprehensively review the current studies on AI systems, and conclude that these studies could be classified into two groups, i.e. the design as well as development of AI systems and the intelligence assessment of AI. Reviews finds the need and urgency for the quantitative intelligence assessment methods for AI. We also believe that a more efficient assessment method is to establish an index system to estimate and score the intelligence level of AI quantitatively.",,Review