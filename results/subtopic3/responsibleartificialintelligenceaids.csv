Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Responsible Artificial Intelligence (AI) for Value Formation and Market Performance in Healthcare: the Mediating Role of Patient’s Cognitive Engagement,The healthcare sector has been at the forefront of the adoption of artificial intelligence technologies.,Search,2021,11,"Pradeep  Kumar, Yogesh K. Dwivedi, Ambuj  Anand",Information systems frontiers : a journal of research and innovation,,10.1007/s10796-021-10136-6,https://doi.org/10.1007/s10796-021-10136-6,https://semanticscholar.org/paper/8eaeda4885475764277a056c37e034be2e46ccd2,https://link.springer.com/content/pdf/10.1007/s10796-021-10136-6.pdf,"The Healthcare sector has been at the forefront of the adoption of artificial intelligence (AI) technologies. Owing to the nature of the services and the vulnerability of a large section of end-users, the topic of responsible AI has become the subject of widespread study and discussion. We conduct a mixed-method study to identify the constituents of responsible AI in the healthcare sector and investigate its role in value formation and market performance. The study context is India, where AI technologies are in the developing phase. The results from 12 in-depth interviews enrich the more nuanced understanding of how different facets of responsible AI guide healthcare firms in evidence-based medicine and improved patient centered care. PLS-SEM analysis of 290 survey responses validates the theoretical framework and establishes responsible AI as a third-order factor. The 174 dyadic data findings also confirm the mediation mechanism of the patient’s cognitive engagement with responsible AI-solutions and perceived value, which leads to market performance.",,
Towards Responsible Artificial Intelligence in Long-term Care: A Scoping Review on Practical Approaches.,There is limited empirical evidence detailing how responsible AI innovation is addressed in context.,Search,2021,,"Dirk R M Lukkien, Henk Herman Nap, Hendrik P Buimer, Alexander  Peine, Wouter P C Boon, Johannes C F Ket, Mirella M N Minkman, Ellen H M Moors",The Gerontologist,,10.1093/geront/gnab180,https://doi.org/10.1093/geront/gnab180,https://semanticscholar.org/paper/a2adc42d39d81e6cdb5b32c45451c42fd3aa3427,https://academic.oup.com/gerontologist/advance-article-pdf/doi/10.1093/geront/gnab180/42216937/gnab180.pdf,"BACKGROUND AND OBJECTIVES

Artificial intelligence (AI) is widely positioned to become a key element of intelligent technologies used in the long-term care (LTC) for older adults. The increasing relevance and adoption of AI has encouraged debate over the societal and ethical implications of introducing and scaling AI. This scoping review investigates how the design and implementation of AI technologies in LTC is addressed responsibly: so called responsible innovation (RI).

RESEARCH DESIGN AND METHODS

We conducted a systematic literature search in five electronic databases using concepts related to LTC, AI and RI. We then performed a descriptive and thematic analysis to map the key concepts, types of evidence and gaps in the literature.

RESULTS

After reviewing 3,339 papers, 25 papers were identified that met our inclusion criteria. From this literature, we extracted three overarching themes: user-oriented AI innovation; framing AI as a solution to RI issues; and context-sensitivity. Our results provide an overview of measures taken and recommendations provided to address responsible AI innovation in LTC.

DISCUSSION AND IMPLICATIONS

The review underlines the importance of the context of use when addressing responsible AI innovation in LTC. However, limited empirical evidence actually details how responsible AI innovation is addressed in context. Therefore, we recommend expanding empirical studies on RI at the level of specific AI technologies and their local contexts of use. Also, we call for more specific frameworks for responsible AI innovation in LTC to flexibly guide researchers and innovators. Future frameworks should clearly distinguish between RI processes and outcomes.",,Review
Promoting Responsible Artificial Intelligence in Insurance,Artificial intelligence in insurance can yield economic and societal benefits for beyond insurers and their customers.,Search,2020,2,Benno  Keller,,,,,https://semanticscholar.org/paper/0c98d0b3b1df7eb5cc4cf31b95d7ce7238f5491d,,"The use of artificial intelligence in insurance has the potential to yield economic and societal benefits that go beyond insurers and their customers by improving risk pooling and enhancing risk reduction, mitigation and prevention. In order to foster the adoption of AI systems and realise these benefits, insurers need to earn the trust of customers by using new technologies responsibly. In order to promote key principles for responsible AI such as transparency and explainability, fairness, safety, accountability and privacy, insurers should establish internal guidelines and policies, adopt an appropriate governance structure to address related risks, and develop and roll out comprehensive training programmes for employees and agents.",,
RESPONSIBLE ARTIFICIAL INTELLIGENCE: DESIGNING AI FOR HUMAN VALUES AND SOCIETY,Artificial intelligence is increasingly affecting our lives in smaller or greater ways.,Search,2019,,Nandhini Shree J P et. al,,,,,https://semanticscholar.org/paper/b6659e6b491337169814b1c31086fdbec2e2b0b9,,"Artificial intelligence (AI) is increasingly affecting our lives in smaller or greater ways.Inordertoensurethatsystemswillupholdhumanvalues,designmethodsareneededthatincorporateethicalprinciplesand address societal concerns.

In this paper, we explore the impact of AI in the case of the expected effects on the Europeanlabormarket,andproposetheaccountability,responsibilityandtransparency(ART)designprinciples for the development of AI systems that are sensitive to humanvalues.",,
How to achieve trustworthy artificial intelligence for health,"The EU's guidance leaves room for local, contextualized discretion in the global health sector.",Search,2020,15,"Kristine  Bærøe, Ainar  Miyata-Sturm, Edmund  Henden",Bulletin of the World Health Organization,,10.2471/BLT.19.237289,https://doi.org/10.2471/BLT.19.237289,https://semanticscholar.org/paper/0a3c92d6c4fa4670743fb13758916067e772a143,https://europepmc.org/articles/pmc7133476?pdf=render,"Abstract Artificial intelligence holds great promise in terms of beneficial, accurate and effective preventive and curative interventions. At the same time, there is also awareness of potential risks and harm that may be caused by unregulated developments of artificial intelligence. Guiding principles are being developed around the world to foster trustworthy development and application of artificial intelligence systems. These guidelines can support developers and governing authorities when making decisions about the use of artificial intelligence. The High-Level Expert Group on Artificial Intelligence set up by the European Commission launched the report Ethical guidelines for trustworthy artificial intelligence in2019. The report aims to contribute to reflections and the discussion on the ethics of artificial intelligence technologies also beyond the countries of the European Union (EU). In this paper, we use the global health sector as a case and argue that the EU’s guidance leaves too much room for local, contextualized discretion for it to foster trustworthy artificial intelligence globally. We point to the urgency of shared globalized efforts to safeguard against the potential harms of artificial intelligence technologies in health care.",,
Research on Social Responsibility of Artificial Intelligence Based on ISO 26000,Artificial intelligence should pay attention to the performance of social responsibility.,Search,2018,3,Wei-wei  Zhao,Advances in Intelligent Systems and Computing,,10.1007/978-3-030-00214-5_17,https://doi.org/10.1007/978-3-030-00214-5_17,https://semanticscholar.org/paper/8b937f4ce6c5cb109e6f9460f2135f618f3e79ce,,"Due to the limitations of artificial intelligence (AI) technology, the policies and regulations are lagged, the social responsibility of artificial intelligence has a series of problems, such as human rights, environmental problems. Based on ISO 26000, which is the seven core issues of social responsibility: organizational governance, human rights, labor, environment, fair operating practice, consumer issues, community participation and development. We describe the problems of artificial intelligence in these seven aspects in this paper. Then we analyzed and corresponding countermeasures which are discussed. Finally, we can draw a conclusion that artificial intelligence should pay attention to the performance of social responsibility.",,
Making Responsible AI the Norm rather than the Exception,The National Security Commission on Artificial Intelligence (NSCAI) prepared a document on Responsible AI recommendations.,Search,2021,,Abhishek  Gupta,ArXiv,,,,https://semanticscholar.org/paper/75299097114e0eca55790c8f37e4acca6a92cdaa,,"This report prepared by the Montreal AI Ethics Institute provides recommendations in response to the National Security Commission on Artificial Intelligence (NSCAI) Key Considerations for Responsible Development and Fielding of Artificial Intelligence document. The report centres on the idea that Responsible AI should be made the Norm rather than an Exception. It does so by utilizing the guiding principles of: (1) alleviating friction in existing workflows, (2) empowering stakeholders to get buy-in, and (3) conducting an effective translation of abstract standards into actionable engineering practices. After providing some overarching comments on the document from the NSCAI, the report dives into the primary contribution of an actionable framework to help operationalize the ideas presented in the document from the NSCAI. The framework consists of: (1) a learning, knowledge, and information exchange (LKIE), (2) the Three Ways of Responsible AI, (3) an empirically-driven risk-prioritization matrix, and (4) achieving the right level of complexity. All components reinforce each other to move from principles to practice in service of making Responsible AI the norm rather than the exception.",,
Responsible AI,AI can be used to improve the lives of people with disabilities.,Search,2021,1,Ben  Shneiderman,Commun. ACM,,10.1145/3445973,https://doi.org/10.1145/3445973,https://semanticscholar.org/paper/dd8216b7c6329d7931ed5ad842263e960d15397d,,Recommendations for increasing the benefits of artificial intelligence technologies.,,
"Artificial intelligence in health care: laying the Foundation for Responsible, sustainable, and inclusive innovation in low- and middle-income countries",,Search,2020,19,"Hassane  Alami, Lysanne  Rivard, Pascale  Lehoux, Steven J. Hoffman, Stéphanie Bernadette Mafalda Cadeddu, Mathilde  Savoldelli, Mamane Abdoulaye Samri, Mohamed Ali Ag Ahmed, Richard  Fleet, Jean-Paul  Fortin",Globalization and Health,,10.1186/s12992-020-00584-1,https://doi.org/10.1186/s12992-020-00584-1,https://semanticscholar.org/paper/b460805f7717925953bc5c17554f736c3c6d58aa,https://globalizationandhealth.biomedcentral.com/track/pdf/10.1186/s12992-020-00584-1,"The World Health Organization and other institutions are considering Artificial Intelligence (AI) as a technology that can potentially address some health system gaps, especially the reduction of global health inequalities in low- and middle-income countries (LMICs). However, because most AI-based health applications are developed and implemented in high-income countries, their use in LMICs contexts is recent and there is a lack of robust local evaluations to guide decision-making in low-resource settings. After discussing the potential benefits as well as the risks and challenges raised by AI-based health care, we propose five building blocks to guide the development and implementation of more responsible, sustainable, and inclusive AI health care technologies in LMICs.",,
Artificial intelligence in health care: accountability and safety,,Search,2020,27,"Ibrahim  Habli, Tom  Lawton, Zoe  Porter",Bulletin of the World Health Organization,,10.2471/BLT.19.237487,https://doi.org/10.2471/BLT.19.237487,https://semanticscholar.org/paper/a132e66655f9d4f8edba54df053c6656c4c617be,https://europepmc.org/articles/pmc7133468?pdf=render,"Abstract The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.",,
Improving Social Responsibility of Artificial Intelligence by Using ISO 26000,The social responsibility of artificial intelligence has become a hot topic in academic circles.,Search,2018,7,Wei-Wei  Zhao,IOP Conference Series: Materials Science and Engineering,,10.1088/1757-899X/428/1/012049,https://doi.org/10.1088/1757-899X/428/1/012049,https://semanticscholar.org/paper/93e0e234ec5b14fe5b5d79483edffd9b4ec01e88,https://iopscience.iop.org/article/10.1088/1757-899X/428/1/012049/pdf,"The vigorous development of artificial intelligence has had a profound and long-term impact on human production and life. It is a double-edged sword. While letting people enjoy the good life created by new technology, it also allows people to feel its negative effects, such as infringing on human privacy, and bringing new inequalities to human beings. Discussing the social responsibility of artificial intelligence has become a hot topic in academic circles in the past two years. This article starts with adopting the research framework of ISO 26000, comprehensively analyzing the problems of artificial intelligence social responsibility in theory and practice, and putting forward their own thinking. It is concluded that in the age of artificial intelligence, we will proceed from the seven themes of this standard to enhance the social responsibility of artificial intelligence, and ultimately achieve the sustainable development of artificial intelligence by adopting the social responsibility international standard ISO 26000,.",,
Role of Artificial Intelligence in Health Care,Artificial intelligence can assist in the diagnosis of various diseases to help save lives.,Search,2017,7,"Mishra  Sg, Takke  Ak, Auti  St, Suryavanshi  Sv, Oza  Mj",,,,,https://semanticscholar.org/paper/30b8392139c9b73096870f4811e14516a9d8dfc9,,"The purpose of Artificial Intelligence is to make computers more useful in solving problematic healthcare challenges and by using computers we can interpret data which is obtained by diagnosis of various chronic diseases like Alzheimer, Diabetes, Cardiovascular diseases and various types of cancers like breast cancer, colon cancer etc. It helps in early detection of various chronic diseases which reduces economic burden and severity of disease. Various automated systems and tools like Brain-computer interfaces (BCIs), arterial spin labeling (ASL) imaging, ASL-MRI, biomarkers, iT bra, Natural language processing (NLP)and various algorithms helps to minimize errors and control disease progression. The computer assisted diagnosis, decision support systems, expert systems and implementation of software may assist physicians to minimize the intra and inter-observer variability. To streamline the process of diagnosis artificial intelligence methods specifically artificial neural networks (ANN), Fuzzy approach can be implemented to handle diverse type of medical data. ANN technique discovers the hidden patterns and correlation in medical data and effective in designing support system in clinical field. The application of AI facilitates interpretation of results with high accuracy and speed. This review will explore how artificial intelligence and machine learning can save lives by helping individual patients beat the odds. Some examples of artificial intelligence assisted diagnosis of various diseases are given below.",,Review
Building Safer AGI by introducing Artificial Stupidity,Artificial Stupidity can make an Artificial General Intelligence (AGI) safer by limiting its computing power and memory.,Search,2018,18,"Michaël  Trazzi, Roman V. Yampolskiy",ArXiv,,,,https://semanticscholar.org/paper/feef1ddc618a406e4b125b51ad7de0505516c8e6,,"Artificial Intelligence (AI) achieved super-human performance in a broad variety of domains. We say that an AI is made Artificially Stupid on a task when some limitations are deliberately introduced to match a human's ability to do the task. An Artificial General Intelligence (AGI) can be made safer by limiting its computing power and memory, or by introducing Artificial Stupidity on certain tasks. We survey human intellectual limits and give recommendations for which limits to implement in order to build a safe AGI.",,
Beneficial AI: the next battlefield,"AI-based systems may be prone to be misused and require “accountability, responsibility and transparency”.",Search,2018,4,Eugénio  Oliveira,,,10.24840/2183-0606_005.004_0002,https://doi.org/10.24840/2183-0606_005.004_0002,https://semanticscholar.org/paper/8057c0ff9771c321f51e09d0d351776f00e60387,https://journalsojs3.fe.up.pt/index.php/jim/article/download/2183-0606_005.004_0002/293,"When planting our human print in a new technology-driven world we should ask, remembering Neil Armstrong in 1969, “after many small steps for AI researchers, will it result in a giant leap in the unknown for mankind?” An “Artificial Intelligence-first” world is being preached all over the media by many responsible players in economic and scientific communities. This letter states our belief in AI potentialities, including its major and decisive role in computer science and engineering, while warning against the current hyping of its near future. Although quite excited by several recent interesting revelations about the future of AI, we here argue in favor of a more cautious interpretation of the current and future AI-based systems potential outreach. We also include some personal perspectives on simple remedies to preventing recognized possible dangers. We advocate a set of practices and principles that may prevent the development of AI-based systems prone to be misused. Accountable “Data curators”, appropriate Software Engineering specification methods, the inclusion, when needed, of the “human in the loop”, software agents with emotion-like states might be important factors leading to more secure AI-based systems. Moreover, to inseminate ART in Artificial Intelligence, ART standing for Accountability, Responsibility and Transparency, becomes also mandatory for trustworthy AI-based systems. This letter is an abbreviation of a more substantial article to be published in IJCA journal.",,
Artificial intelligence in a crisis needs ethics with urgency,Artificial intelligence can be used in the COVID-19 response to save lives with new ethical approaches.,Search,2020,14,"Asaf  Tzachor, Jess  Whittlestone, Lalitha S Sundaram, Seán Ó hÉigeartaigh",Nat. Mach. Intell.,,10.1038/s42256-020-0195-0,https://doi.org/10.1038/s42256-020-0195-0,https://semanticscholar.org/paper/cda4b91f54ee9ecb0be363c58735caa5b0d85d35,https://www.nature.com/articles/s42256-020-0195-0.pdf,"Artificial intelligence tools can help save lives in a pandemic. However, the need to implement technological solutions rapidly raises challenging ethical issues. We need new approaches for ethics with urgency, to ensure AI can be safely and beneficially used in the COVID-19 response and beyond.",,
Safe and sound - artificial intelligence in hazardous applications,Computer science and artificial intelligence are increasingly used in the hazardous and uncertain realms of medical decision making.,Search,2000,272,"John  Fox, Subrata Kumar Das",,,,,https://semanticscholar.org/paper/f62d215d4c40d299929d2e7fa105d54623a9e1bf,,"Computer science and artificial intelligence are increasingly used in the hazardous and uncertain realms of medical decision making, where small faults or errors can spell human catastrophe. This book describes, from both practical and theoretical perspectives, an AI technology for supporting sound clinical decision making and safe patient management. The technology combines techniques from conventional software engineering with a systematic method for building intelligent agents. Although the focus is on medicine, many of the ideas can be applied to AI systems in other hazardous settings. The book also covers a number of general AI problems, including knowledge representation and expertise modeling, reasoning and decision making under uncertainty, planning and scheduling, and the design and implementation of intelligent agents.The book, written in an informal style, begins with the medical background and motivations, technical challenges, and proposed solutions. It then turns to a wide-ranging discussion of intelligent and autonomous agents, with particular reference to safety and hazard management. The final section provides a detailed discussion of the knowledge representation and other aspects of the agent model developed in the book, along with a formal logical semantics for the language.",,