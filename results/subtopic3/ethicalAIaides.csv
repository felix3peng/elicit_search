Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Toward an Ethics of AI Assistants: an Initial Framework,Personal AI assistants are now nearly ubiquitous and pose several ethical concerns.,Search,2018,28,John  Danaher,Philosophy & Technology,,10.1007/S13347-018-0317-3,https://doi.org/10.1007/S13347-018-0317-3,https://semanticscholar.org/paper/0eec7dad1f60c6802b88ba7637ab84c567e97c8d,,"Personal AI assistants are now nearly ubiquitous. Every leading smartphone operating system comes with a personal AI assistant that promises to help you with basic cognitive tasks: searching, planning, messaging, scheduling and so on. Usage of such devices is effectively a form of algorithmic outsourcing: getting a smart algorithm to do something on your behalf. Many have expressed concerns about this algorithmic outsourcing. They claim that it is dehumanising, leads to cognitive degeneration, and robs us of our freedom and autonomy. Some people have a more subtle view, arguing that it is problematic in those cases where its use may degrade important interpersonal virtues. In this article, I assess these objections to the use of AI assistants. I will argue that the ethics of their use is complex. There are no quick fixes or knockdown objections to the practice, but there are some legitimate concerns. By carefully analysing and evaluating the objections that have been lodged to date, we can begin to articulate an ethics of personal AI use that navigates those concerns. In the process, we can locate some paradoxes in our thinking about outsourcing and technological dependence, and we can think more clearly about what it means to live a good life in the age of smart machines.",,
AI assisted ethics,"AI programs need oversight programs to monitor, audit, and hold operational AI programs accountable.",Search,2016,52,"Amitai  Etzioni, Oren  Etzioni",Ethics and Information Technology,,10.1007/s10676-016-9400-6,https://doi.org/10.1007/s10676-016-9400-6,https://semanticscholar.org/paper/cb90d3732a50bce46165e75b2260e0c71a70ba33,,"The growing number of ‘smart’ instruments, those equipped with AI, has raised concerns because these instruments make autonomous decisions; that is, they act beyond the guidelines provided them by programmers. Hence, the question the makers and users of smart instrument (e.g., driver-less cars) face is how to ensure that these instruments will not engage in unethical conduct (not to be conflated with illegal conduct). The article suggests that to proceed we need a new kind of AI program—oversight programs—that will monitor, audit, and hold operational AI programs accountable.",,
Ethical Artificial Intelligence - An Open Question,"Artificial Intelligence is an effective science that employs strong enough approaches, methods, and techniques to solve unsolvable real world based problems.",Search,2017,12,"Alice  Pavaloiu, Utku  Kose",ArXiv,,,,https://semanticscholar.org/paper/b952eaffb220ed192728d2ce7436235827132057,,"Artificial Intelligence (AI) is an effective science which employs strong enough approaches, methods, and techniques to solve unsolvable real world based problems. Because of its unstoppable rise towards the future, there are also some discussions about its ethics and safety. Shaping an AI friendly environment for people and a people friendly environment for AI can be a possible answer for finding a shared context of values for both humans and robots. In this context, objective of this paper is to address the ethical issues of AI and explore the moral dilemmas that arise from ethical algorithms, from pre set or acquired values. In addition, the paper will also focus on the subject of AI safety. As general, the paper will briefly analyze the concerns and potential solutions to solving the ethical issues presented and increase readers awareness on AI safety as another related research interest.",,
Ethical Artificial Intelligence for Digital Health Organizations,A US-based Digital Health company developed an ethical code for emotional AI services for mental health support.,Search,2020,9,"Angela  Joerin, Michiel  Rauws, Russell  Fulmer, Valerie  Black",Cureus,,10.7759/cureus.7202,https://doi.org/10.7759/cureus.7202,https://semanticscholar.org/paper/a8f262b28aa4a35196814b447346f99173c4795a,https://www.cureus.com/articles/25462-ethical-artificial-intelligence-for-digital-health-organizations.pdf,"This technical report describes the methods undertaken by a US-based Digital Health company (X2AI or X2 for short) to develop an ethical code for startup environments and other organizations delivering emotional artificial intelligence (AI) services, especially for mental health support. With a growing demand worldwide for scalable, affordable, and accessible health care solutions, the use of AI offers tremendous potential to improve emotional well-being. To realize this potential, it is imperative that AI service providers prioritize clear and consistent ethical guidelines that align with global considerations regarding user safety and privacy. This report offers a template for an ethical code that can be implemented by other emotional AI services and their affiliates. It includes practical guidelines for integrating support from clients, collaborators, and research partners. It also shows how existing ethical systems can inform the development of AI ethics.",,
Ethics Sheets for AI Tasks,Ethics Sheets for AI Tasks document the ethical considerations of a given AI task before building systems.,Search,2021,1,Saif M. Mohammad,ArXiv,,,,https://semanticscholar.org/paper/ee800c9afd3e61e428a79550d642ffbdaacfa068,,"Recent innovations such as Datasheets for Datasets and Model Cards for Model Reporting have made useful contributions to furthering ethical research. Yet, several highprofile events, such as the mass testing of emotion recognition systems on vulnerable sub-populations, have highlighted how technology will often lead to more adverse outcomes for those that are already marginalized. In this paper, I will make a case for thinking about ethical considerations not just at the level of individual models and datasets, but also at the level of AI tasks. I will present a new form of such an effort, Ethics Sheets for AI Tasks, dedicated to fleshing out the assumptions and ethical considerations hidden in how a task is commonly framed and in the choices we make regarding the data, method, and evaluation. Finally, I will provide an example ethics sheet for automatic emotion recognition. Ethics sheets are a mechanism to document ethical considerations before building datasets and systems. Such pre-production activities (e.g., ethics analyses) and associated artifacts (e.g., accessible documentation) are crucial for responsible AI: for communicating risks to all stakeholders, to help decision and policy making, and for developing more effective post-production documents such as Data Sheets and Model Cards. The Case: Importance of Ethics Considerations at the Level of AI Tasks Good design helps everyone. It is well established, for example, that designing for accessibility helps society at large.1 As Artificial Intelligence (AI), Machine Learning (ML), and Natural language Processing (NLP) systems become more ubiquitous, their broad societal impacts are receiving more scrutiny than ever before. However, several high-profile instances such as the use of recidivism prediction biased against people from black neighborhoods2, face-recognition systems that perform poorly for people with dark skin tones (Buolamwini and Gebru 2018), machine translation systems that are biased against some genders (Prates, Avelar, and Lamb 2019), and mass testing of emotion recognition systems on certain sub-populations (ARTICLE19 2021; Wakefield 2021), have highlighted how technology is often at https://blog.ai-media.tv/blog/why-designing-for-accessibilityhelps-everyone https://www.propublica.org/article/machine-bias-riskassessments-in-criminal-sentencing odds with the very people it is meant to help, and how it will often lead to more adverse outcomes for those that are already marginalized. This raises uncomfortable questions for us AI researchers and developers: What role do we (researchers/engineers) play in the eventual harms perpetrated by technology? What are the hidden assumptions in our research? What are the unsaid implications of our choices? Are we striking at the barriers to opportunity or are we amplifying societal inequities? The answers are often complex and multifaceted. While many AI systems have clear benefits, we are increasingly seeing examples such as those discussed above where realworld AI systems are causing harm. Academic research (which often feeds into real-world systems), is also seeing growing amounts of criticisms: criticisms of physiognomy, racism, bias, discrimination, perpetuating stereotypes, ignoring indigenous world views, and more. See Arcas, Mitchell, and Todorov (2017) and Ongweso (2020) for recent examples. There have also been criticisms of thoughtlessness in machine learning (e.g., is automating this task, this way, really going to help people?) and a seemingly callous disregard for the variability and complexity of human behavior (McQuillan 2018; Fletcher-Watson et al. 2018; Birhane 2021). In the sub-sections below, I describe recent efforts by the AI community to encourage responsible research, the limitations of those efforts, and the need for thinking about ethical considerations at the level of AI tasks. The next section presents a new proposal to that end: to create ethics sheets for AI tasks. This is followed by an example ethics sheet for automatic emotion recognition. Recent Innovations for Responsible Research So how are we addressing these new challenges in AI/ML/NLP research? For individual datasets, it is recommended to create datasheets or data statements (Gebru et al. 2018; Bender and Friedman 2018) (list key details of the datasets such as composition and intended uses; meant to encourage appropriate use of the data). For individual systems, it is recommended to create model cards (Mitchell et al. 2019) (list key details of the models such as performance in various contexts and intended use scenarios; meant ar X iv :2 10 7. 01 18 3v 3 [ cs .A I] 1 7 Se p 20 21 to encourage appropriate use of the systems.) For individual papers, we write ethics/impact statements. Conferences have started to institute ethics policies and ethics reviews.3 Limitations: Datasheets and model cards are pivotal inventions that will serve our community well. However, they are not without limitations and the specificity of their scope on individual pieces of work places additional constraints: • Authors are in a position of conflict of interest; there are strong incentives to present their work in positive light (for paper acceptance, community buy-in, etc.) • There can be a tendency to produce boiler-plate text without a meaningful and critical engagement with the relevant ethical issues. • While there is important benefit in creating postproduction documents that describe societal impact, it is arguably more important to engage with ethical considerations (and create an ethics focused document) before building AI systems (and possibly even choosing to not build a system for a particular deployment context based on the analysis). • Lastly, ethics considerations apply at levels other than individual projects, for example, at the level of AI tasks. A comprehensive engagement with the relevant ethical issues requires a wide literature review, and the resulting analysis to be presented in a dedicated document (and not in add-on sections for individual system papers). Ethics at the Level of AI Tasks I am defining AI task to simply mean some task we may want to automate using AI techniques. An AI system is a particular AI model built for the task. Individual systems have their own unique sets of ethical considerations (depending on the choices that were made when building the systems). However, several ethical considerations apply not at the level of individual systems, but at the level of the task. For example, consider the task of detecting personality traits from one’s utterances. Even before we consider a system for the task, we ought to consider questions such as: • What are the societal implications of automating personality trait detection? • How can such a system be used/misused? • Is there enough credible scientific basis for personality trait identification that we should attempt to do this? • Which theory of personality traits should such automation rely on? What are the implications of that choice? And so on. In addition, for a given task, there exist ethical considerations latent in the choices commonly made in dataset creation, model development, and evaluation. Poor choices lead to more harm. Consider these outcomes reported in the popular press: • Text Generation: ‘Dangerous’ AI writes fake news, BBC.4 https://medium.com/@GovAI/a-guide-to-writing-the-neuripsimpact-statement-4293b723f832 www.bbc.com/news/technology-49446729 • Image Generation: ‘Deepfakes’ a political problem already hitting EU, EU Observer.5 • Automatic Emotion Recognition from Faces: Emotional Entanglement: China’s emotion recognition market and its implications for human rights, Article19 6. • Machine Translation: Female historians and male nurses do not exist, Google Translate tells its European users, Algorithm Watch.7 • Information Extraction: Kannada: Google apologises for ‘ugliest Indian language’ search result, BBC.8 Numerous other such examples have surfaced in just the past few years for a variety of AI tasks. Reading relevant literature, engaging with various stakeholders of the task, and developing some AI systems helps one to start identifying relevant ethical considerations for various NLP, ML, and AI tasks; but that takes time. Meanwhile, tens of thousands of new researchers are joining our ranks. Pressures to graduate and find good jobs force them to build systems and publish papers in a matter of months. Even experienced researchers can find it difficult to keep track of various ethical considerations discussed in a wide assortment of conferences and journals. The Proposal: Ethics Sheets for AI Tasks If one wants to do work on an AI Task, then right at the beginning it is useful to have access to: a carefully compiled document that substantively engages with the ethical issues relevant to that task; going beyond individual systems and datasets, drawing on knowledge from a body of relevant past work. Similarly, if one conceptualizes a new AI Task, then it is useful to simultaneously create such a source of information. Therefore, I propose that we researchers and developers write such articles, which I will refer to as Ethics Sheets for AI Tasks. In some ways, ethics sheets are similar to survey articles for areas of research, except here the focus is on ethical considerations for an AI task. Simply put: an ethics sheet for an AI task is a semi-standardized article that aggregates and organizes a wide variety of ethical considerations relevant for that task. It: • Fleshes out assumptions hidden in how the task is framed, and in the choices often made regarding the data, method, and evaluation. • Presents ethical considerations unique or especially relevant to the task. • Presents how common ethical considerations manifest in the task. • Presents relevant dimensions and choice points; along with tradeoffs for various stakeholders. • Lists common harm mitigation strategies. https://euobserver.com/opinion/151935 www.article19.",,Review
Beyond the promise: implementing ethical AI,"Businesses require strong, mandated governance controls to ensure responsible AI use in enterprises.",Search,2021,19,Ray  Eitel-Porter,AI Ethics,,10.1007/s43681-020-00011-6,https://doi.org/10.1007/s43681-020-00011-6,https://semanticscholar.org/paper/0a7109502e7fe91f4decc3dd3515e1fecbc02da7,https://link.springer.com/content/pdf/10.1007/s43681-020-00011-6.pdf,"Artificial Intelligence (AI) applications can and do have unintended negative consequences for businesses if not implemented with care. Specifically, faulty or biased AI applications risk compliance and governance breaches and damage to the corporate brand. These issues commonly arise from a number of pitfalls associated with AI development, which include rushed development, a lack of technical understanding, and improper quality assurance, among other factors. To mitigate these risks, a growing number of organisations are working on ethical AI principles and frameworks. However, ethical AI principles alone are not sufficient for ensuring responsible AI use in enterprises. Businesses also require strong, mandated governance controls including tools for managing processes and creating associated audit trails to enforce their principles. Businesses that implement strong governance frameworks, overseen by an ethics board and strengthened with appropriate training, will reduce the risks associated with AI. When applied to AI modelling, the governance will also make it easier for businesses to bring their AI deployments to scale.",,
Recommendations for the ethical use and design of artificial intelligent care providers,Artificial intelligent care providers present new ethical issues that will have significant ramifications for the mental health care and other helping professions.,Search,2014,63,David D. Luxton,Artif. Intell. Medicine,,10.1016/j.artmed.2014.06.004,https://doi.org/10.1016/j.artmed.2014.06.004,https://semanticscholar.org/paper/c3fc33be2a7ed7912b23653576e04f7588e77698,,"OBJECTIVE

This paper identifies and reviews ethical issues associated with artificial intelligent care providers (AICPs) in mental health care and other helping professions. Specific recommendations are made for the development of ethical codes, guidelines, and the design of AICPs.

METHODS

Current developments in the application of AICPs and associated technologies are reviewed and a foundational overview of applicable ethical principles in mental health care is provided. Emerging ethical issues regarding the use of AICPs are then reviewed in detail. Recommendations for ethical codes and guidelines as well as for the development of semi-autonomous and autonomous AICP systems are described. The benefits of AICPs and implications for the helping professions are discussed in order to weigh the pros and cons of their use.

RESULTS

Existing ethics codes and practice guidelines do not presently consider the current or the future use of interactive artificial intelligent agents to assist and to potentially replace mental health care professionals. AICPs present new ethical issues that will have significant ramifications for the mental health care and other helping professions. Primary issues involve the therapeutic relationship, competence, liability, trust, privacy, and patient safety. Many of the same ethical and philosophical considerations are applicable to use and design of AICPs in medicine, nursing, social work, education, and ministry.

CONCLUSION

The ethical and moral aspects regarding the use of AICP systems must be well thought-out today as this will help to guide the use and development of these systems in the future. Topics presented are relevant to end users, AI developers, and researchers, as well as policy makers and regulatory boards.",,Review
Artificial Intelligence (AI) Ethics: Ethics of AI and Ethical AI,AI ethics is still in the infancy stage.,Search,2020,26,"Keng  Siau, Weiyu  Wang",J. Database Manag.,,10.4018/jdm.2020040105,https://doi.org/10.4018/jdm.2020040105,https://semanticscholar.org/paper/39d1f020a585d3f28cb4b4c14497649e6a469ef1,,"Artificial intelligence (AI)-based technology has achieved many great things, such as facial recognition, medical diagnosis, and self-driving cars. AI promises enormous benefits for economic growth, social development, as well as human well-being and safety improvement. However, the low-level of explainability, data biases, data security, data privacy, and ethical problems of AI-based technology pose significant risks for users, developers, humanity, and societies. As AI advances, one critical issue is how to address the ethical and moral challenges associated with AI. Even though the concept of “machine ethics” was proposed around 2006, AI ethics is still in the infancy stage. AI ethics is the field related to the study of ethical issues in AI. To address AI ethics, one needs to consider the ethics of AI and how to build ethical AI. Ethics of AI studies the ethical principles, rules, guidelines, policies, and regulations that are related to AI. Ethical AI is an AI that performs and behaves ethically. One must recognize and understand the potential ethical and moral issues that may be caused by AI to formulate the necessary ethical principles, rules, guidelines, policies, and regulations for AI (i.e., Ethics of AI). With the appropriate ethics of AI, one can then build AI that exhibits ethical behavior (i.e., Ethical AI). This paper will discuss AI ethics by looking at the ethics of AI and ethical AI. What are the perceived ethical and moral issues with AI? What are the general and common ethical principles, rules, guidelines, policies, and regulations that can resolve or at least attenuate these ethical and moral issues with AI? What are some of the necessary features and characteristics of an ethical AI? How to adhere to the ethics of AI to build ethical AI?",,
An embedded ethics approach for AI development,AI developers can be practically assisted in identifying and addressing ethical issues.,Search,2020,26,"Stuart  McLennan, Amelia  Fiske, Leo Anthony Celi, Ruth  Müller, Jan  Harder, Konstantin  Ritt, Sami  Haddadin, Alena  Buyx",,,10.1038/s42256-020-0214-1,https://doi.org/10.1038/s42256-020-0214-1,https://semanticscholar.org/paper/a6c87b0515ce63b22967d12a96805db86f7c06a6,,"There is a need to consider how AI developers can be practically assisted in identifying and addressing ethical issues. In this Comment, a group of AI engineers, ethicists and social scientists suggest embedding ethicists into the development team as one way of improving the consideration of ethical issues during AI development.",,
An artificial neural network approach for creating an ethical artificial agent,An artificial neutral network was developed to determine if a behavior or action is ethically permissible.,Search,2009,21,"Ali Reza Honarvar, Nasser  Ghasem-Aghaee",2009 IEEE International Symposium on Computational Intelligence in Robotics and Automation - (CIRA),,10.1109/CIRA.2009.5423190,https://doi.org/10.1109/CIRA.2009.5423190,https://semanticscholar.org/paper/ccbba7f671c53c907843bd5d806669dd53982c37,,"Autonomous robotic systems and intelligent artificial agents' capability have advanced dramatically. Since the intelligent artificial agents have been developing more autonomous and human-like, the capability of them to make moral decisions becomes an important issue. In this work we developed an artificial neutral network which considered various effective factors for ethical assessment of an action to determine that if a behavior or an action is ethically permissible or not. We integrated this net to the BDI-Agent model as a part of its reasoning process to behave ethically in various environments.",,
Good Systems: Ethical AI for CSCW,Artificial intelligence can lead to increased productivity and efficiency but also potential ethical trade-offs.,Search,2019,3,"Kenneth R. Fleischmann, Sherri R. Greenberg, Danna  Gurari, Abigale  Stangl, Nitin  Verma, Jaxsen R. Day, Rachel N. Simons, Tom  Yeh",CSCW Companion,,10.1145/3311957.3359437,https://doi.org/10.1145/3311957.3359437,https://semanticscholar.org/paper/d4f75fafc5d911cefdaf95b92bfaa1d6d2fe82d6,,"Artificial intelligence is revolutionizing work, including what it means for cooperative work to be supported by computers. The increased use of AI in CSCW can lead to many advantages, including increased productivity and efficiency, but it can also include several potential ethical trade-offs, such as invasions of privacy, loss of autonomy, and job displacement. This workshop will explore the ethical dimensions of AI in CSCW, building on Good Systems, a UT Grand Challenge. Specifically, the first half of the workshop will focus on the need to design AI to work for all users and to avoid bias through the use of universal design as well as the need for AI and CSCW researchers to interact with policy and legal experts to work together to ensure that AI will be developed in an ethical manner with sufficient consideration of its societal implications, and also that AI will be regulated and legislated in ways that will maximize its benefits to all people.",,
Principles and business processes for responsible AI,AI risk assessment needs to be undertaken from the perspectives of other stakeholders.,Search,2019,25,Roger  Clarke,Comput. Law Secur. Rev.,,10.1016/J.CLSR.2019.04.007,https://doi.org/10.1016/J.CLSR.2019.04.007,https://semanticscholar.org/paper/9042677e67305726a4511ef3e9a7a00239af2a79,,"Abstract The first article in this series examined why the world wants controls over Artificial Intelligence (AI). This second article discusses how an organisation can manage AI responsibly, in order to protect its own interests, but also those of its stakeholders and society as a whole. A limited amount of guidance is provided by ethical analysis. A much more effective approach is to apply adapted forms of the established techniques of risk assessment and risk management. Critically, risk assessment needs to be undertaken not only with the organisation's own interests in focus, but also from the perspectives of other stakeholders. To underpin this new form of business process, a set of Principles for Responsible AI is presented, consolidating proposals put forward by a diverse collection of 30 organisations.",,
Ethical AI Implementation,Implementing ethics in business is not unique that just comes along with AI.,Search,2021,,Stefan H. Vieweg,AI for the Good,,10.1007/978-3-030-66913-3_11,https://doi.org/10.1007/978-3-030-66913-3_11,https://semanticscholar.org/paper/58e1ee159dc218fa4d18645a7ba12e7f36780894,,"Implementing ethics in business is not unique that just comes along with AI. Though, the implications in an AI setting are much more far-reaching than ever before. Given its disruptive nature, AI affects entire societies’ prosperity projections right down to every individual to earn a living; it has a massive impact on the environment as well. Illustration of key initiatives in the EU and the USA toward ethical AI is discussed such as applicable laws (e.g., GDPR and CCPA on data privacy) and ideas such as the RoboLaw on automation or the electronic person (e-person). Postulates from various commissions are summarized and selected organizations thriving for ethical AI are introduced.",,
The ethics of AI in health care: A mapping review.,"If action is not taken regarding ethical issues in AI for health care, a new ""AI winter"" may occur.",Search,2020,57,"Jessica  Morley, Caio C.V. Machado, Christopher  Burr, Josh  Cowls, Indra  Joshi, Mariarosaria  Taddeo, Luciano  Floridi",Social science & medicine,,10.1016/j.socscimed.2020.113172,https://doi.org/10.1016/j.socscimed.2020.113172,https://semanticscholar.org/paper/0a1da3d352f83f7c539e621ed0ec4d292d812a10,,"This article presents a mapping review of the literature concerning the ethics of artificial intelligence (AI) in health care. The goal of this review is to summarise current debates and identify open questions for future research. Five literature databases were searched to support the following research question: how can the primary ethical risks presented by AI-health be categorised, and what issues must policymakers, regulators and developers consider in order to be 'ethically mindful? A series of screening stages were carried out-for example, removing articles that focused on digital health in general (e.g. data sharing, data access, data privacy, surveillance/nudging, consent, ownership of health data, evidence of efficacy)-yielding a total of 156 papers that were included in the review. We find that ethical issues can be (a) epistemic, related to misguided, inconclusive or inscrutable evidence; (b) normative, related to unfair outcomes and transformative effectives; or (c) related to traceability. We further find that these ethical issues arise at six levels of abstraction: individual, interpersonal, group, institutional, and societal or sectoral. Finally, we outline a number of considerations for policymakers and regulators, mapping these to existing literature, and categorising each as epistemic, normative or traceability-related and at the relevant level of abstraction. Our goal is to inform policymakers, regulators and developers of what they must consider if they are to enable health and care systems to capitalise on the dual advantage of ethical AI; maximising the opportunities to cut costs, improve care, and improve the efficiency of health and care systems, whilst proactively avoiding the potential harms. We argue that if action is not swiftly taken in this regard, a new 'AI winter' could occur due to chilling effects related to a loss of public trust in the benefits of AI for health care.",,Review
Artificial Intelligence: the global landscape of ethics guidelines,There is a global convergence emerging around five ethical principles with substantive divergence regarding how these principles are interpreted.,Search,2019,228,"Anna  Jobin, Marcello  Ienca, Effy  Vayena",ArXiv,,10.1038/s42256-019-0088-2,https://doi.org/10.1038/s42256-019-0088-2,https://semanticscholar.org/paper/7bf47af1f989c1a999d7dab24d86d19f13e8ba55,http://arxiv.org/pdf/1906.11668,"In the last five years, private companies, research institutions as well as public sector organisations have issued principles and guidelines for ethical AI, yet there is debate about both what constitutes ""ethical AI"" and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analyzed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted; why they are deemed important; what issue, domain or actors they pertain to; and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies.",,
The ethical AI—paradox: why better technology needs more and not less human responsibility,AI has no ethics and bad decisions by algorithms are caused by human choices made at an earlier stage.,Search,2021,3,"David  De Cremer, Garry  Kasparov",AI and Ethics,,10.1007/s43681-021-00075-y,https://doi.org/10.1007/s43681-021-00075-y,https://semanticscholar.org/paper/1a1308f6013fc4403c89a46f818467e925275530,https://link.springer.com/content/pdf/10.1007/s43681-021-00075-y.pdf,"Because AI is gradually moving into the position of decision-maker in business and organizations, its influence is increasingly impacting the outcomes and interests of the human end-user. As a result, scholars and practitioners alike have become worried about the ethical implications of decisions made where AI is involved. In approaching the issue of AI ethics, it is becoming increasingly clear that society and the business world—under the influence of the big technology companies—are accepting the narrative that AI has its own ethical compass, or, in other words, that AI can decide itself to do bad or good. We argue that this is not the case. We discuss and demonstrate that AI in itself has no ethics and that good or bad decisions by algorithms are caused by human choices made at an earlier stage. For this reason, we argue that even though technology is quickly becoming better and more sophisticated a need exists to simultaneously train humans even better in shaping their ethical compass and awareness.",,