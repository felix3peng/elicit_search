Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Introduction to AI Fairness,"Today, AI is used in many high-stakes decision-making applications in which fairness is an important concern.",Search,2020,2,"Yunfeng  Zhang, Rachel K. E. Bellamy, Moninder  Singh, Q. Vera Liao",CHI Extended Abstracts,,10.1145/3334480.3375059,https://doi.org/10.1145/3334480.3375059,https://semanticscholar.org/paper/d49f8d57240cd04dd66d91bf53c639497139ab3a,,"Today, AI is used in many high-stakes decision-making applications in which fairness is an important concern. Already, there are many examples of AI being biased and making questionable and unfair decisions. Recently, the AI research community has proposed many methods to measure and mitigate unwanted biases, and developed open-source toolkits for developers to make fair AI. This course will cover the recent development in algorithmic fairness, including the many different definitions of fairness, their corresponding quantitative measurements, and ways to mitigate biases. This course is open to beginners and is designed for anyone interested in the topic of AI fairness.",,
Introduction to AI Fairness,"Today, AI is used in many high-stakes decision-making applications in which fairness is an important concern.",Search,2021,,"Yunfeng  Zhang, Rachel K. E. Bellamy, Q. Vera Liao, Moninder  Singh",CHI Extended Abstracts,,10.1145/3411763.3444998,https://doi.org/10.1145/3411763.3444998,https://semanticscholar.org/paper/e24d854f822bebd531926eee518d4b2e1455e5de,,"Today, AI is used in many high-stakes decision-making applications in which fairness is an important concern. Already, there are many examples of AI being biased and making questionable and unfair decisions. Recently, the AI research community has proposed many methods to measure and mitigate unwanted biases, and developed open-source toolkits for developers to make fair AI. This course will cover the recent development in algorithmic fairness, including the many different definitions of fairness, their corresponding quantitative measurements, and ways to mitigate biases. This course is open to beginners and is designed for anyone interested in the topic of AI fairness.",,
Towards Fairness Certification in Artificial Intelligence,Machine learning models incur the risk of amplifying prejudices and societal stereotypes by over associating protected attributes.,Search,2021,1,"Tatiana  Tommasi, Silvia  Bucci, Barbara  Caputo, Pietro  Asinari",ArXiv,,,,https://semanticscholar.org/paper/157246efaa0a667383cd78da0599231687368e0e,,"Thanks to the great progress of machine learning in the last years, several Artificial Intelligence (AI) techniques have been increasingly moving from the controlled research laboratory settings to our everyday life. The most simple examples are the spam filters that keep our email account in order, face detectors that help us when taking a portrait picture, online recommender systems that suggest which movie and clothing we might like, or interactive maps that navigate us towards our vacation home. Artificial intelligence is clearly supportive in many decision-making scenarios, but when it comes to sensitive areas such as health care, hiring policies, education, banking or justice, with major impact on individuals and society, it becomes crucial to establish guidelines on how to design, develop, deploy and monitor this technology. Indeed the decision rules elaborated by machine learning models are data-driven and there are multiple ways in which discriminatory biases can seep into data. Algorithms trained on those data incur the risk of amplifying prejudices and societal stereotypes by over associating protected attributes such as gender, ethnicity or disabilities with the prediction task.",,
Artificial Intelligence: A Guide to Intelligent Systems,The methods used in the book have been extensively tested through several courses given by the author.,Search,2001,2205,Michael  Negnevitsky,,,,,https://semanticscholar.org/paper/7c4a9643c701c0c91ea50fd587038f79187a0a5e,,"From the Publisher:

Virtually all the literature on artificial intelligence is expressed in the jargon of commuter science, crowded with complex matrix algebra and differential equations. Unlike many other books on computer intelligence, this one demonstrates that most ideas behind intelligent systems are simple and straightforward. The book has evolved from lectures given to students with little knowledge of calculus, and the reader needs no prerequisites associated with knowledge of any programming language. The methods used in the book have been extensively tested through several courses given by the author.

The book provides an introduction to the field of computer intelligence, covering

rule-based expert systems,

fuzzy expert systems,

frame-based expert systems,

artificail neural networks,

evolutionary computation,

hybrid intelligent systems,

knowledge engineering,

data mining.

In a university setting the book can be used as an introductory course within computer science, information systems or engineering departments. The book is also suitable as a self-study guide for non-computer science professionals, giving access to the state of the art in knowledge-based systems and computational intelligence. Everyone who faces challenging problems and cannot solve them using traditional approaches can benefit",,
Designing Algorithms to Increase Fairness in Artificial Intelligence,Artificial intelligence can be trained to preserve gender discrimination.,Search,2018,,"Anil  Aswani, Matt  Olfat",,,,,https://semanticscholar.org/paper/20a815559967e15848aecb02955126bf945e7724,,"The increasing role of artificial intelligence (AI) to automate decision-making sparks concern about potential AI-based discrimination. Such bias is undesirable in the quest to minimize inequality, and legal regulations require that AI not discriminate against protected classes on the basis of gender, race, age, and the like. Exclusion of data on protected classes when training AI is one strategy to minimize prejudice. However, this is not only a naive approach to fairness, but also insufficient because AI systems can learn to use information on protected classes via other data [2]; for example, race can often be inferred from a home address. Consequently, more sophisticated algorithmic and computational approaches are necessary to ensure that AI behaves impartially. Such concerns about AI fairness are not merely theoretical. Researchers have observed several instances of biased data and prejudiced AI. When discriminatory behavior influences the data that trains AI, the resulting AI output often perpetuates this bias. For instance, doctors frequently undertreat pain in women as compared to men [3]. AI systems for pain management trained using such biased data can algorithmically preserve this gender discrimination. Social media algorithms provide further examples; in one situation, LinkedIn disproportionately advertised high-paying jobs to men. In another, Facebook’s algorithms displayed considerable racial prejudice in censorship [1]. The first step towards developing fair AI is to quantify fairness, for which investigators have proposed several definitions for supervised learning to date. Put simply, these definitions require that an individual’s membership in a protected class (e.g., gender) will not impact AI’s outcome (e.g., approval or disapproval of a loan application). One can tailor this process for the purpose of classification, where the goal is to construct a function h p : { , }  → − + 1 1 (known as a classifier) that uses a vector of descriptive features x p Î  , characterizing each individual to predict a binary outcome y ∈ − + { , } 1 1 for him/ herself. When an individual’s protected class z ∈ − + { , } 1 1 is binary, the notion of demographic parity [4] at level D requires that | [ ( ) | ]  h x z = + = + − 1 1 [ ( ) | ]| . h x z =+ = − ≤ 1 1 ∆ Intuitively, the probability of receiving a positive outcome from the classifier is independent of the protected class’s value. Other definitions of fairness—such as equal opportunity—also exist [5]. While there are many approaches for constructing accurate classifiers from training data, researchers have only recently begun",,
How Fair AI Can Make Us Richer,"AI systems guide important parts of our lives if we get admitted to university, if we are hired, fired or promoted.",Search,2021,,Sandra  Wachter,European Data Protection Law Review,,10.21552/edpl/2021/3/5,https://doi.org/10.21552/edpl/2021/3/5,https://semanticscholar.org/paper/24aa2a3be2464b0f641207bd1f2886c180cb1dc1,https://edpl.lexxion.eu/data/article/17685/pdf/edpl_2021_03-006.pdf,"Sandra Wachter* We are all aware that artificial intelligence (AI) has now become an integral part of our lives. AI systems are behind mundane tasks such as displaying search results on Safari, preparing travel routs on Google and suggesting new music on Spotify. But algorithms also steer important parts of our lives: if we get admitted to university, if we are hired, fired or promoted, if we get insurance, social benefits or a loan, or even if we have to go to prison. Algorithms can touch almost every aspect of our lives.",,
Explaining how your AI system is fair,Sharing reasons and principles for AI fairness decisions with the broader audience is key to maintaining confidence in AI systems.,Search,2021,,"Boris  Ruf, Marcin  Detyniecki",ArXiv,,,,https://semanticscholar.org/paper/1271e86aad602cfa09727dc98bae31c19ce77cc6,,"Copyright held by the owner/author(s). CHI’21,, May 8–13, 2021, Online Virtual Conference (originally Yokohama, Japan) ACM 978-1-4503-6819-3/20/04. https://doi.org/10.1145/3334480.XXXXXXX Abstract To implement fair machine learning in a sustainable way, choosing the right fairness objective is key. Since fairness is a concept of justice which comes in various, sometimes conflicting definitions, this is not a trivial task though. The most appropriate fairness definition for an artificial intelligence (AI) system is a matter of ethical standards and legal requirements, and the right choice depends on the particular use case and its context. In this position paper, we propose to use a decision tree as means to explain and justify the implemented kind of fairness to the end users. Such a structure would first of all support AI practitioners in mapping ethical principles to fairness definitions for a concrete application and therefore make the selection a straightforward and transparent process. However, this approach would also help document the reasoning behind the decision making. Due to the general complexity of the topic of fairness in AI, we argue that specifying ""fairness"" for a given use case is the best way forward to maintain confidence in AI systems. In this case, this could be achieved by sharing the reasons and principles expressed during the decision making process with the broader audience.",,
"Fairness, Accountability and Transparency in Artificial Intelligence: A Case Study of Logical Predictive Models",The interpretability of logical machine learning models can be restored by explaining them with class-contrastive counterfactual statements.,Search,2019,4,Kacper  Sokol,AIES,,10.1145/3306618.3314316,https://doi.org/10.1145/3306618.3314316,https://semanticscholar.org/paper/f031fe645728d6fd36a9a36232cf19a846e9db73,,"Machine learning -- the part of artificial intelligence aimed at eliciting knowledge from data and automated decision making without explicit instructions -- is making great strides, with new algorithms being invented every day. These algorithms find myriads of applications, but their ubiquity often comes at the expense of limited interpretability, hidden biases and unexpected vulnerabilities. Whenever one of these factors is a priority, the learning algorithm of choice is often a method considered to be inherently interpretable, e.g. logical models such as decision trees. In my research I challenge this assumption and highlight (quite common) cases when the assumed interpretability fails to deliver. To restore interpretability of logical machine learning models (decision trees and their ensembles in particular) I propose to explain them with class-contrastive counterfactual statements, which are a very common type of explanation in human interactions, well-grounded in social science research. To evaluate transparency of such models I collate explainability desiderata that can be used to systematically assess and compare such methods as an addition to user studies. Given contrastive explanations, I investigate their influence on the model's security, in particular gaming and stealing the model. Finally, I evaluate model fairness, where I am interested in choosing the most fair model among all the models with equal performance.",,
From Aware to Fair: Tackling Bias in A.I,It's important to maintain accuracy in fair artificial intelligence systems.,Search,2021,,"Anthony J. Kupecz, Zachary  Ives",,,,,https://semanticscholar.org/paper/c3977673e4799153fdc73a01e7e3499a732283ba,,"Within the past decade, there has been tremendous advancements in the field of Artificial Intelligence (AI). From recommendation systems and facial recognition, to social services and recruiting tools, AI algorithms dominate our life and are with us nearly 24/7. Despite the tremendous boon these technologies have been for the majority, they have the potential to be nightmares with long lasting consequences for the minority. As designers of these widespread algorithms, it has become increasingly important that we are aware of the biases and potential for discrimination in these technologies. At the same time, it is important to maintain accuracy within these systems. This paper will explore the nascent topic of algorithmic fairness by looking at the problem through the lens of classification tasks. We will foray into the concept of “fairness” and the different proposed definitions, and then compare and contrast proposed solutions. We will end on a discussion of the limitations surrounding this topic and offer recommendations for the future of this space.",,
Think Your Artificial Intelligence Software Is Fair? Think Again,"Machine-learning software is also biased, sometimes in similar ways to humans, often in different ways.",Search,2019,14,"Rachel K.E. Bellamy, Kuntal  Dey, Michael  Hind, Samuel C. Hoffman, Stephanie  Houde, Kalapriya  Kannan, Pranay  Lohia, Sameep  Mehta, Aleksandra  Mojsilovic, Seema  Nagar, Karthikeyan Natesan Ramamurthy, John  Richards, Diptikalyan  Saha, Prasanna  Sattigeri, Moninder  Singh, Kush R. Varshney, Yunfeng  Zhang",IEEE Software,,10.1109/MS.2019.2908514,https://doi.org/10.1109/MS.2019.2908514,https://semanticscholar.org/paper/4d60f78b44f34a67a5ce6316d1c45c90a912db44,,"Today, machine-learning software is used to help make decisions that affect people's lives. Some people believe that the application of such software results in fairer decisions because, unlike humans, machine-learning software generates models that are not biased. Think again. Machine-learning software is also biased, sometimes in similar ways to humans, often in different ways. While fair model- assisted decision making involves more than the application of unbiased models-consideration of application context, specifics of the decisions being made, resolution of conflicting stakeholder viewpoints, and so forth-mitigating bias from machine-learning software is important and possible but difficult and too often ignored.",,
Fairway: SE Principles for Building Fairer Software,A routine part of the machine learning software development life cycle should test for bias and mitigate bias in AI software.,Search,2020,1,"Joymallya  Chakraborty, Suvodeep  Majumder, Zhe  Wu, Tim  Menzies",ArXiv,,,,https://semanticscholar.org/paper/21e8e6da482cf1aeb18e8a449d84b1c6da8770b6,,"Machine learning software is increasingly being used to make decisions that affect people’s lives. But sometimes, the core part of this software (the learned model), behaves in a biased manner that gives undue advantages to a specific group of people (where those groups are determined by sex, race, etc.). This “algorithmic discrimination” in the AI software systems has become a matter of serious concern in the machine learning and software engineering community. There have been works done to find “algorithmic bias” or “ethical bias” in software system. Once the bias is detected in the AI software system, mitigation of bias is extremely important. In this work, we a) explain how ground truth bias in training data affects machine learning model fairness and how to find that bias in AI software, b) propose a method Fairway which combines preprocessing and in-processing approach to remove ethical bias from training data and trained model. Our results show that we can find bias and mitigate bias in a learned model, without much damaging the predictive performance of that model. We propose that (1) testing for bias and (2) bias mitigation should be a routine part of the machine learning software development life cycle. Fairway offers much support for these two purposes.",,
"Artificial intelligence, Digital Single Market and the proposal of a right to fair and reasonable inferences: a legal issue between ethics and techniques",The European Union Law is still under construction when it comes to providing effective protection to its citizens against automated inferences.,Search,2019,,"Alexandre  Veronese, Alessandra  Silveira, Amanda Nunes Lopes Espiñeira Lemos",UNIO – EU Law Journal,,10.21814/unio.5.2.2294,https://doi.org/10.21814/unio.5.2.2294,https://semanticscholar.org/paper/a2263f0e5e3ec03bd74d71a503db647076543fb2,https://revistas.uminho.pt/index.php/unio/article/download/2294/2409,"The article discusses the ethical and technical consequences of Artificial intelligence (hereinafter, A.I) applications and their usage of the European Union data protection legal framework to enable citizens to defend themselves against them. This goal is under the larger European Union Digital Single Market policy, which has concerns about how this subject correlates with personal data protection. The article has four sections. The first one introduces the main issue by describing the importance of AI applications in the contemporary world scenario. The second one describes some fundamental concepts about AI. The third section has an analysis of the ongoing policies for AI in the European Union and the Council of Europe proposal about ethics applicable to AI in the judicial systems. The fourth section is the conclusion, which debates the current legal mechanisms for citizens protection against fully automated decisions, based on European Union Law and in particular the General Data Protection Regulation. The conclusion will be that European Union Law is still under construction when it comes to providing effective protection to its citizens against automated inferences that are unfair or unreasonable.",,
Guide to some computerized artificial intelligence methods,"Artificial intelligence is not a new concept, because since the late 1940s exciting developments have been taking place in making computers act in a way that one would consider intelligent.",Search,1996,23,Saul B. Saila,,,10.1007/978-94-015-8598-9_2,https://doi.org/10.1007/978-94-015-8598-9_2,https://semanticscholar.org/paper/e9d0ed59c9ec4f0f907f71f7bdbeb1a49537f873,,"Artificial intelligence is not a new concept, because since the late 1940s exciting developments have been taking place in making computers act in a way that one would consider intelligent. Artificial intelligence (AI) has been defined as a subfield of computer science which deals with machines and software that appear to think and solve problems. The overall goal of much of the work in artificial intelligence is to develop systems that perform like human beings. Whether or not these systems are really ‘intelligent’ is a philosophical question. For our purposes, the fact that these systems mimic human intelligence to some extent at least is sufficient. AI programs are programs that exhibit behavior normally identified with human intelligence, and until recently, not with computers. In particular, AI programs seem to grasp ideas and concepts. For example, some can understand natural languages, some can see or perform difficult assembly tasks, and others can infer new information from facts provided to the system. However, software that makes computers seem intelligent is not that different from any other kind of software.",,
Fairway: a way to build fair ML software,Fairway proposes a method to remove ethical bias from training data and trained models.,Search,2020,25,"Joymallya  Chakraborty, Suvodeep  Majumder, Zhe  Yu, Tim  Menzies",ESEC/SIGSOFT FSE,,10.1145/3368089.3409697,https://doi.org/10.1145/3368089.3409697,https://semanticscholar.org/paper/cafef47bdd70002ba9c599b5ab28ed056940a35e,http://arxiv.org/pdf/2003.10354,"Machine learning software is increasingly being used to make decisions that affect people's lives. But sometimes, the core part of this software (the learned model), behaves in a biased manner that gives undue advantages to a specific group of people (where those groups are determined by sex, race, etc.). This ""algorithmic discrimination"" in the AI software systems has become a matter of serious concern in the machine learning and software engineering community. There have been works done to find ""algorithmic bias"" or ""ethical bias"" in the software system. Once the bias is detected in the AI software system, the mitigation of bias is extremely important. In this work, we a)explain how ground-truth bias in training data affects machine learning model fairness and how to find that bias in AI software,b)propose a method Fairway which combines pre-processing and in-processing approach to remove ethical bias from training data and trained model. Our results show that we can find bias and mitigate bias in a learned model, without much damaging the predictive performance of that model. We propose that (1) testing for bias and (2) bias mitigation should be a routine part of the machine learning software development life cycle. Fairway offers much support for these two purposes.",,
Artificial intelligence - a modern approach: the intelligent agent book,"A Modern Approach"" has become a classic in the AI literature.",Search,1995,71,"Stuart J. Russell, Peter  Norvig",Prentice Hall series in artificial intelligence,,,,https://semanticscholar.org/paper/4182e91594e927da074663508d06e0200606c7bb,,"The first edition of Artificial Intelligence: A Modern Approach has become a classic in the AI literature. It has been adopted by over 600 universities in 60 countries, and has been praised as the definitive synthesis of the field. In the second edition, every chapter has been extensively rewritten. Significant new material has been introduced to cover areas such as constraint satisfaction, fast propositional inference, planning graphs, internet agents, exact probabilistic inference, Markov Chain Monte Carlo techniques, Kalman filters, ensemble learning methods, statistical learning, probabilistic natural language models, probabilistic robotics, and ethical aspects of AI. The book is supported by a suite of online resources including source code, figures, lecture slides, a directory of over 800 links to ""AI on the Web,"" and an online discussion group. All of this is available at: aima.cs.berkeley.edu.",,
Rough sets and some problems of artificial intelligence,Rough sets and some problems of artificial intelligence.,Search,1985,6,Zdzisław  Pawlak,,,10.1016/0167-9236(86)90045-x,https://doi.org/10.1016/0167-9236(86)90045-x,https://semanticscholar.org/paper/a426ff3705fd88582c96ff9a9fc0162b3f709796,http://bcpw.bg.pw.edu.pl/Content/1997,"W: ICS PAS Reports 565/85, pages 1-55. Institute of Computer Science Polish Academy of Sciences (ICS PAS), Warsaw, Poland, 1985",,