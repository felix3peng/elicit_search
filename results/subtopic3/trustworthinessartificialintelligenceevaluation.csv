Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Opening the software engineering toolbox for the assessment of trustworthy AI,Software engineering and testing practices can be used for the assessment of trustworthy AI.,Search,2020,2,"Mohit Kumar Ahuja, Mohamed-Bachir  Belaid, Pierre  Bernab'e, Mathieu  Collet, Arnaud  Gotlieb, Chhagan  Lal, Dusica  Marijan, Sagar  Sen, Aizaz  Sharif, Helge  Spieker",NeHuAI@ECAI,,,,https://semanticscholar.org/paper/3b0ff6bd000e9c615d024614343f2c1cf12bf124,,"Trustworthiness is a central requirement for the acceptance and success of human-centered artificial intelligence (AI). To deem an AI system as trustworthy, it is crucial to assess its behaviour and characteristics against a gold standard of Trustworthy AI, consisting of guidelines, requirements, or only expectations. While AI systems are highly complex, their implementations are still based on software. The software engineering community has a long-established toolbox for the assessment of software systems, especially in the context of software testing. In this paper, we argue for the application of software engineering and testing practices for the assessment of trustworthy AI. We make the connection between the seven key requirements as defined by the European Commission's AI high-level expert group and established procedures from software engineering and raise questions for future work.",,
Trustworthy Acceptance: A New Metric for Trustworthy Artificial Intelligence Used in Decision Making in Food-Energy-Water Sectors,A trustworthy acceptance metric and its measurement methodology can be used to evaluate the trustworthiness of AI systems.,Search,2021,1,"Suleyman  Uslu, Davinder  Kaur, Samuel J. Rivera, Arjan  Durresi, Mimoza  Durresi, Meghna  Babbar-Sebens",AINA,,10.1007/978-3-030-75100-5_19,https://doi.org/10.1007/978-3-030-75100-5_19,https://semanticscholar.org/paper/5d6a347ac08ff55ee9ac0234c36d9f41b0d7088c,,"We propose, for the first time, a trustworthy acceptance metric and its measurement methodology to evaluate the trustworthiness of AI-based systems used in decision making in Food Energy Water (FEW) management. The proposed metric is a significant step forward in the standardization process of AI systems. It is essential to standardize the AI systems’ trustworthiness, but until now, the standardization efforts remain at the level of high-level principles. The measurement methodology of the proposed includes human experts in the loop, and it is based on our trust management system. Our metric captures and quantifies the system’s transparent evaluation by field experts on as many control points as desirable by the users. We illustrate the trustworthy acceptance metric and its measurement methodology using AI in decision-making scenarios of Food-Energy-Water sectors. However, the proposed metric and its methodology can be easily adapted to other fields of AI applications. We show that our metric successfully captures the aggregated acceptance of any number of experts, can be used to do multiple measurements on various points of the system, and provides confidence values for the measured acceptance. Suleyman Uslu Indiana University-Purdue University Indianapolis, Indianapolis, IN, USA e-mail: suslu@iu.edu Davinder Kaur Indiana University-Purdue University Indianapolis, Indianapolis, IN, USA e-mail: davikaur@iu.edu Samuel J Rivera Oregon State University, Corvallis, OR, USA e-mail: sammy.rivera@oregonstate.edu Arjan Durresi Indiana University-Purdue University Indianapolis, Indianapolis, IN, USA e-mail: adurresi@iupui.edu Mimoza Durresi European University of Tirana e-mail: mimoza.durresi@uet.edu.al Meghna Babbar-Sebens Oregon State University, Corvallis, OR, USA e-mail: meghna@oregonstate.edu",,
Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence,An automatic online assessment method for the reliability of CPS was proposed in this article.,Search,2021,81,"Zhihan  Lv, Yang  Han, Amit Kumar Singh, Gunasekaran  Manogaran, Haibin  Lv",IEEE Transactions on Industrial Informatics,,10.1109/TII.2020.2994747,https://doi.org/10.1109/TII.2020.2994747,https://semanticscholar.org/paper/79086f67c5d7413a05305478b1b38781588ed19d,,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.",,
Trustworthiness of Artificial Intelligence,A AI has a lot of benefits but any mistake in either the development or in the working phase of the AI system can be disastrous.,Search,2020,4,"Sonali  Jain, Manan  Luthra, Shagun  Sharma, Mehtab  Fatima",2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS),,10.1109/ICACCS48705.2020.9074237,https://doi.org/10.1109/ICACCS48705.2020.9074237,https://semanticscholar.org/paper/2efae53ba8d84c6f11d3f7151f23b9e22ca806e4,,"This paper discusses the need for a trustworthy AI, along with the ethics which are required to keep that trust intact. AI has a lot of benefits when it comes to societal, individual or cultural development. But any mistake in either the development or in the working phase of the AI system can be disastrous, especially when human lives are involved. The main goal of this paper is to understand what really makes an Artificial Intelligence system trustworthy.",,
Trustworthy AI Inference Systems: An Industry Research View,Private AI inference systems require security protection mechanisms and appropriate data privacy protection.,Search,2020,2,"Rosario  Cammarota, Matthias  Schunter, Anand  Rajan, Fabian  Boemer, 'Agnes  Kiss, Amos  Treiber, Christian  Weinert, Thomas  Schneider, Emmanuel  Stapf, Ahmad-Reza  Sadeghi, Daniel  Demmler, Huili  Chen, Siam Umar Hussain, Sadegh  Riazi, Farinaz  Koushanfar, Saransh  Gupta, Tajan Simunic Rosing, Kamalika  Chaudhuri, Hamid  Nejatollahi, Nikil  Dutt, Mohsen  Imani, Kim  Laine, Anuj  Dubey, Aydin  Aysu, Fateme Sadat Hosseini, Chengmo  Yang, Eric  Wallace, Pamela  Norton",ArXiv,,,,https://semanticscholar.org/paper/828947e3e9e06c506e6a30e3eb7e176c0b8b953d,,"In this work, we provide an industry research view for approaching the design, deployment, and operation of trustworthy Artificial Intelligence (AI) inference systems. Such systems provide customers with timely, informed, and customized inferences to aid their decision, while at the same time utilizing appropriate security protection mechanisms for AI models. Additionally, such systems should also use Privacy-Enhancing Technologies (PETs) to protect customers' data at any time.

To approach the subject, we start by introducing trends in AI inference systems. We continue by elaborating on the relationship between Intellectual Property (IP) and private data protection in such systems. Regarding the protection mechanisms, we survey the security and privacy building blocks instrumental in designing, building, deploying, and operating private AI inference systems. For example, we highlight opportunities and challenges in AI systems using trusted execution environments combined with more recent advances in cryptographic techniques to protect data in use. Finally, we outline areas of further development that require the global collective attention of industry, academia, and government researchers to sustain the operation of trustworthy AI inference systems.",,
Trustworthy AI,The pursuit of responsible AI raises the ante on both the trustworthy computing and formal methods communities.,Search,2021,7,Jeannette M. Wing,Commun. ACM,,10.1145/3448248,https://doi.org/10.1145/3448248,https://semanticscholar.org/paper/33cf9b4d6c76f988380b1adff2c06c30010f93d3,https://dl.acm.org/doi/pdf/10.1145/3448248,The pursuit of responsible AI raises the ante on both the trustworthy computing and formal methods communities.,,
Requirements for Trustworthy Artificial Intelligence - A Review,"The field of algorithmic decision-making, particularly Artificial Intelligence (AI), has been drastically changing.",Search,2020,8,"Davinder  Kaur, Suleyman  Uslu, Arjan  Durresi",NBiS,,10.1007/978-3-030-57811-4_11,https://doi.org/10.1007/978-3-030-57811-4_11,https://semanticscholar.org/paper/ab7f6628cbbafae1ce994929af2482efbd092d61,https://scholarworks.iupui.edu/bitstream/1805/28055/1/Kaur2020Requirements-AAM.pdf,"The field of algorithmic decision-making, particularly Artificial Intelligence (AI), has been drastically changing. With the availability of a massive amount of data and an increase in the processing power, AI systems have been used in a vast number of high-stake applications. So, it becomes vital to make these systems reliable and trustworthy. Different approaches have been proposed to make theses systems trustworthy. In this paper, we have reviewed these approaches and summarized them based on the principles proposed by the European Union for trustworthy AI. This review provides an overview of different principles that are important to make AI trustworthy.",,Review
Trustworthy artificial intelligence,"Trustworthy AI bases on the idea that trust builds the foundation of societies, economies, and sustainable development.",Search,2021,21,"Scott  Thiebes, Sebastian  Lins, Ali  Sunyaev",Electron. Mark.,,10.1007/S12525-020-00441-4,https://doi.org/10.1007/S12525-020-00441-4,https://semanticscholar.org/paper/9da092d7c7674e96830f8d6713a9a4f8101f984c,https://link.springer.com/content/pdf/10.1007/s12525-020-00441-4.pdf,"Artificial intelligence (AI) brings forth many opportunities to contribute to the wellbeing of individuals and the advancement of economies and societies, but also a variety of novel ethical, legal, social, and technological challenges. Trustworthy AI (TAI) bases on the idea that trust builds the foundation of societies, economies, and sustainable development, and that individuals, organizations, and societies will therefore only ever be able to realize the full potential of AI, if trust can be established in its development, deployment, and use. With this article we aim to introduce the concept of TAI and its five foundational principles (1) beneficence, (2) non-maleficence, (3) autonomy, (4) justice, and (5) explicability. We further draw on these five principles to develop a data-driven research framework for TAI and demonstrate its utility by delineating fruitful avenues for future research, particularly with regard to the distributed ledger technology-based realization of TAI.",,
Trust in AI Agent: A Systematic Review of Facial Anthropomorphic Trustworthiness for Social Robot Design,"Static facial features, dynamic features, their combinations, and related emotional expressions can improve the facial anthropomorphic trustworthiness for social robots.",Search,2020,11,"Yao  Song, Yan  Luximon",Sensors,,10.3390/s20185087,https://doi.org/10.3390/s20185087,https://semanticscholar.org/paper/f4b26e8f1500c95328e5487fa67c5abba1ba1bba,https://www.mdpi.com/1424-8220/20/18/5087/pdf,"As an emerging artificial intelligence system, social robot could socially communicate and interact with human beings. Although this area is attracting more and more attention, limited research has tried to systematically summarize potential features that could improve facial anthropomorphic trustworthiness for social robot. Based on the literature from human facial perception, product, and robot face evaluation, this paper systematically reviews, evaluates, and summarizes static facial features, dynamic features, their combinations, and related emotional expressions, shedding light on further exploration of facial anthropomorphic trustworthiness for social robot design.",,Systematic Review
Service Trustworthiness Evaluation Using Neural Network and Fuzzy Logic,A proposed trustworthiness evaluation framework utilizes neural network and fuzzy logic to handle inaccuracy and subjectivity.,Search,2016,2,"Zhengping  Wu, Yu  Zhou",2016 IEEE International Conference on Services Computing (SCC),,10.1109/SCC.2016.80,https://doi.org/10.1109/SCC.2016.80,https://semanticscholar.org/paper/54847735d9bd23fb41db16d3e86430fdf834818e,,"Trustworthiness has become a critical factor for users to choose the most suitable computing services for business or personal use. However, no standard exists for evaluation and comparison of service trustworthiness. So we try to propose a trustworthiness evaluation framework that can make standard or customized selection decisions based on common sense or user-defined specific trustworthiness criteria. This framework utilizes neural network and fuzzy logic to handle inaccuracy and subjectivity in trustworthiness evaluation. A feedback mechanism is also incorporated to make the entire framework be adaptive to users' preferences on different trust factors. A prototype is implemented to evaluate and compare different types of computing services. Experiments on today's popular email services and cloud-based online storage services prove the effectiveness and accuracy of the proposed framework.",,
Enhancing trustworthiness evaluation in internetware with similarity and non-negative constraints,Trustworthiness evaluation mechanisms can help reduce uncertainty and boost collaborations.,Search,2013,2,"Guo  Yan, Feng  Xu, Yuan  Yao, Jian  Lu",Internetware,,10.1145/2532443.2532459,https://doi.org/10.1145/2532443.2532459,https://semanticscholar.org/paper/93395325980fb3b911ed8695fec908b18b4f368f,,"Internetware is envisioned as a new software paradigm where software developers usually need to interact with unknown partners as well as the software entities developed by them. To reduce uncertainty and boost collaborations in such setting, it is important to provide trustworthiness evaluation mechanisms so that trustworthy partners/entities can be easily found. In this work, we propose a novel trustworthiness evaluation mechanism by enhancing existing mechanisms with similarity and non-negative constraints. To be specific, we first extend an existing multi-aspect trust inference model by incorporating the non-negative constraint. One of the advantages of such constraint is its strong interpretability. Second, we incorporate similarity into two neighborhood models borrowed from recommender systems. When computing similarity, we make use of the intermediate results from the first step. Finally, these models are combined under a machine learning framework. To show the effectiveness of our method, we conduct experiments on a real data-set. The results show that: both our non-negativity extension and similarity computation improve the evaluation accuracy of the original methods, and the combined method outperforms several state-of-the-art methods.",,
Trustworthy AI in the Age of Pervasive Computing and Big Data,The requirements of trustworthy AI systems are specifically focused on the aspects that can be integrated into the design and development of AI systems.,Search,2020,15,"Abhishek  Kumar, Tristan  Braud, Sasu  Tarkoma, Pan  Hui",2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops),,10.1109/percomworkshops48775.2020.9156127,https://doi.org/10.1109/percomworkshops48775.2020.9156127,https://semanticscholar.org/paper/f92cedfdf08f7c92ddefebd06fa763d7a8359c1f,http://repository.ust.hk/ir/bitstream/1783.1-101388/1/neutral-ai.pdf,"The era of pervasive computing has resulted in countless devices that continuously monitor users and their environment, generating an abundance of user behavioural data. Such data may support improving the quality of service, but may also lead to adverse usages such as surveillance and advertisement. In parallel, Artificial Intelligence (AI) systems are being applied to sensitive fields such as healthcare, justice, or human resources, raising multiple concerns on the trustworthiness of such systems. Trust in AI systems is thus intrinsically linked to ethics, including the ethics of algorithms, the ethics of data, or the ethics of practice. In this paper, we formalise the requirements of trustworthy AI systems through an ethics perspective. We specifically focus on the aspects that can be integrated into the design and development of AI systems. After discussing the state of research and the remaining challenges, we show how a concrete use-case in smart cities can benefit from these methods.",,
How to achieve trustworthy artificial intelligence for health,"The EU's guidance leaves room for local, contextualized discretion in the global health sector.",Search,2020,15,"Kristine  Bærøe, Ainar  Miyata-Sturm, Edmund  Henden",Bulletin of the World Health Organization,,10.2471/BLT.19.237289,https://doi.org/10.2471/BLT.19.237289,https://semanticscholar.org/paper/0a3c92d6c4fa4670743fb13758916067e772a143,https://europepmc.org/articles/pmc7133476?pdf=render,"Abstract Artificial intelligence holds great promise in terms of beneficial, accurate and effective preventive and curative interventions. At the same time, there is also awareness of potential risks and harm that may be caused by unregulated developments of artificial intelligence. Guiding principles are being developed around the world to foster trustworthy development and application of artificial intelligence systems. These guidelines can support developers and governing authorities when making decisions about the use of artificial intelligence. The High-Level Expert Group on Artificial Intelligence set up by the European Commission launched the report Ethical guidelines for trustworthy artificial intelligence in2019. The report aims to contribute to reflections and the discussion on the ethics of artificial intelligence technologies also beyond the countries of the European Union (EU). In this paper, we use the global health sector as a case and argue that the EU’s guidance leaves too much room for local, contextualized discretion for it to foster trustworthy artificial intelligence globally. We point to the urgency of shared globalized efforts to safeguard against the potential harms of artificial intelligence technologies in health care.",,
Achieving Trustworthy Artificial Intelligence: Multi-Source Trust Transfer in Artificial In- telligence-capable Technology,Trust transfer occurs from known technologies and providers to AI-capable technologies and their providers.,Search,2021,,Maximilian  Renner,,,,,https://semanticscholar.org/paper/3d9e767f8c7395b275db8f4d02f053997233024b,,"Contemporary research focuses on examining trustworthy AI but neglects to consider trust transfer processes, proposing that users’ established trust in a familiar source (e.g., a technology or person) may transfer to a novel target. We argue that such trust transfer processes also occur in the case of novel AI-capable technologies, as they are the result of the convergence of AI with one or more base technologies. We develop a model with a focus on multi-source trust transfer while including the theoretical framework of trustduality (i.e., trust in providers and trust in technologies) to advance our understanding about trust transfer. A survey among 432 participants confirms that users transfer their trust from known technologies and providers (i.e., vehicle and AI technology) to AI-capable technologies and their providers. The study contributes by providing a novel theoretical perspective on establishing trustworthy AI by validating the importance of the duality of trust.",,
Trustworthy AI Development Guidelines for Human System Interaction,"Trust in AI is an active area of research, but little work exists where the focus is to build human trust to improve human-AI interactions.",Search,2020,3,"Chathurika S. Wickramasinghe, Daniel L. Marino, Javier  Grandio, Milos  Manic",2020 13th International Conference on Human System Interaction (HSI),,10.1109/HSI49210.2020.9142644,https://doi.org/10.1109/HSI49210.2020.9142644,https://semanticscholar.org/paper/238fa66062114f39e404c40d0b1abc03b86e54bd,,"Artificial Intelligence (AI) is influencing almost all areas of human life. Even though these AI-based systems frequently provide state-of-the-art performance, humans still hesitate to develop, deploy, and use AI systems. The main reason for this is the lack of trust in AI systems caused by the deficiency of transparency of existing AI systems. As a solution, “Trustworthy AI” research area merged with the goal of defining guidelines and frameworks for improving user trust in AI systems, allowing humans to use them without fear. While trust in AI is an active area of research, very little work exists where the focus is to build human trust to improve the interactions between human and AI systems. In this paper, we provide a concise survey on concepts of trustworthy AI. Further, we present trustworthy AI development guidelines for improving the user trust to enhance the interactions between AI systems and humans, that happen during the AI system life cycle.",,
Formal Model of Trustworthy Artificial Intelligence Based on Standardization,The widespread and rapid distribution and application of artificial intelligence requires the development of formalized approaches and the construction of basic principles.,Search,2021,1,"Eduard  Manziuk, Olexander  Barmak, Iurii  Krak, Olexander  Mazurets, Tetiana  Skrypnyk",IntelITSIS,,,,https://semanticscholar.org/paper/746cf930349beb3557ccd171fd4249347755ca10,,"The widespread and rapid distribution and application of artificial intelligence (AI) systems requires the development of formalized approaches and the construction of basic principles for the functioning of domain areas of AI use. This need is embodied in the development of recommendations and standards to obtain maximum benefits from the use of AI and minimize possible risks. The regulatory framework is being built on a human-centric basis. Accordingly, the developed standards should form the basis for further activities aimed at the use of AI and be applicable at all stages of creating practical solutions. Therefore, an important stage is the formalization of requirements, principles and provisions of legal and ethical norms in the form of practical template approaches for practical application. With this method, models and ontology of standardized concept of AI credibility are developed within the research. This made it possible to identify the main concepts that allow forming a position of trust, are a meaningful part of the concept of trustworthy AI, determine the need for its existence and pose a threat to it. On the basis of ontology of the domain area, models were developed and further decomposition of structural substantive concepts was carried out. In the future, the characteristics of the concept of trustworthiness formation are defined.",,