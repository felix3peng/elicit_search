Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
"Tutorial: Human-Centered AI: Reliable, Safe and Trustworthy",Artificial Intelligence (AI) algorithms are combined with human-centered thinking to make Human-Centered AI (HCAI).,Search,2021,,Ben  Shneiderman,IUI Companion,,10.1145/3397482.3453994,https://doi.org/10.1145/3397482.3453994,https://semanticscholar.org/paper/77891ecacb567308c7ee8f117b8ffd5634d61e0f,,"This 3-hour tutorial proposes a new synthesis, in which Artificial Intelligence (AI) algorithms are combined with human-centered thinking to make Human-Centered AI (HCAI). This approach combines research on AI algorithms with user experience design methods to shape technologies that amplify, augment, empower, and enhance human performance. Researchers and developers for HCAI systems value meaningful human control, putting people first by serving human needs, values, and goals.",,
Human-Centered Artificial Intelligence and Machine Learning,AI systems must be designed with awareness that they are part of a larger system consisting of humans.,Search,2019,67,Mark O. Riedl,Human Behavior and Emerging Technologies,,10.1002/HBE2.117,https://doi.org/10.1002/HBE2.117,https://semanticscholar.org/paper/1fccba11583dc9e1030713d61bd65e9e9990e39f,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/hbe2.117,"Humans are increasingly coming into contact with artificial intelligence and machine learning systems. Human-centered artificial intelligence is a perspective on AI and ML that algorithms must be designed with awareness that they are part of a larger system consisting of humans. We lay forth an argument that human-centered artificial intelligence can be broken down into two aspects: (1) AI systems that understand humans from a sociocultural perspective, and (2) AI systems that help humans understand them. We further argue that issues of social responsibility such as fairness, accountability, interpretability, and transparency.",,
Human-Centered AI,"AI systems require the primary users to gain appropriate levels of trust, transparency regarding limitations, and reflective oversight.",Search,2021,4,"Hollen  Barmer, Rachel  Dzombak, Matthew  Gaston, Vijaykumar  Palat, Frank  Redner, Carol  Smith, Tanisha  Smith",,,10.1184/R1/16560183.V1,https://doi.org/10.1184/R1/16560183.V1,https://semanticscholar.org/paper/264b9b136889da3b4d7e50ef58c77678b35dc3e0,,"We identify three specific areas of focus to advance human-centered AI:• Designers and systems must understand the context of use and sense changes over time: Successful AI Engineering depends on the team’s ability to identify and articulate the desired system outcome and understand human and contextual factors affecting the outcome. The system itself must be able to learn when shifts in context have occurred. What are the best ways to maintain clarity around operational intent and mechanisms for adapting and evolving systems based on dynamic contexts and user needs? • Development of tools, processes, and practices to scope and facilitate human-machine teaming: Implementation of AI systems entails high levels of interdependence between human and machine. Adoption of AI systems requires the primary users to interact with and understand systems, gaining appropriate levels of trust. Every AI system needs to be designed to recognize boundaries and unfamiliar scenarios, and to provide transparency regarding its limitations. • Methods, mechanisms, and mindsets to engage in critical oversight: AI systems learn through data and observations, rather than being explicitly programmed for a deterministic outcome. Critical and reflective oversight by organizations, teams, and individuals that create and use AI systems is needed to uphold ethical principles and proactively consider the risks of bias, misuse, abuse, and unintended consequences through design, development, and ongoing deployment.For each area, we identify ongoing work as well and challenges and opportunities in developing and deploying AI systems with confidence.",,
"Human-Centered Artificial Intelligence: Trusted, Reliable & Safe.","The new goal of Human-Centered Artificial Intelligence is more likely to produce designs that are Trusted, Reliable & Safe.",Search,2020,2,Ben  Shneiderman,,,,,https://semanticscholar.org/paper/e0b2bfdfcc251747538004be479f3914d0932316,,"Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The new goal of HCAI is more likely to produce designs that are Trusted, Reliable & Safe (TRS). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.",,
Explainable Artificial Intelligence: Human-centered Perspective,AI can be explained to users because they have different goals and levels of expertise.,Search,2021,,Hana  Kopecká,,,,,https://semanticscholar.org/paper/21d01ada95b6fdafe31f8ad340e934e77a323b35,,"Users prefer different explanations because they have different goals and levels of expertise. Users prefer different explanations because they have different goals and levels of expertise and because they are embedded in different socio-cultural structures that affect their cognitive style. AI Explainable Artificial Intelligence: Human-centered Perspective Hana Kopecká hana.kopecka@kcl.ac.uk King’s College London, United Kingdom",,
"Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy","The methods of Human-Centered Artificial Intelligence are more likely to produce designs that are Reliable, Safe & Trustworthy.",Search,2020,105,Ben  Shneiderman,Int. J. Hum. Comput. Interact.,,10.1080/10447318.2020.1741118,https://doi.org/10.1080/10447318.2020.1741118,https://semanticscholar.org/paper/e49f67fa5c946ad24afcf59699a9cacf1ca53924,http://arxiv.org/pdf/2002.04087,"ABSTRACT Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The methods of HCAI are more likely to produce designs that are Reliable, Safe & Trustworthy (RST). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.",,
Human-centered AI: The role of Human-centered Design Research in the development of AI,Artificial Intelligence has the tremendous potential to produce progress and innovation in society.,Search,2020,12,Jan  Auernhammer,,,10.21606/drs.2020.282,https://doi.org/10.21606/drs.2020.282,https://semanticscholar.org/paper/647e53dbfa26c84eb4908ed67855b167da79398f,https://dl.designresearchsociety.org/cgi/viewcontent.cgi?article=1178&context=drs-conference-papers,"Artificial Intelligence has the tremendous potential to produce progress and innovation in society. Designing AI for people has been expressed as essential for societal well-being and the common good. However, human-centered is often used generically without any commitment to a philosophy or overarching approach. This paper outlines different philosophical perspectives and several Human-centered Design approaches and discusses their contribution to the development of Artificial Intelligence. The paper argues that humanistic design research should play a vital role in the pan-disciplinary collaboration with technologists and policymakers to mitigate the impact of AI. Ultimately, Human-centered Artificial Intelligence incorporates involving people and designing Artificial Intelligence systems for people through a genuine human-centered philosophy and approach.",,
Human-centered artificial intelligence in education: Seeing the invisible through the visible,The misuse of AI due to algorithm bias and a lack of governance could inhibit human rights.,Search,2021,14,"Stephen J.H. Yang, Hiroaki  Ogata, Tatsunori  Matsui, Nian-Shing  Chen",Comput. Educ. Artif. Intell.,,10.1016/J.CAEAI.2021.100008,https://doi.org/10.1016/J.CAEAI.2021.100008,https://semanticscholar.org/paper/8a90ab1c8336d99048e16d5ce3e0148da7cf1371,https://repository.kulib.kyoto-u.ac.jp/dspace/bitstream/2433/261148/1/j.caeai.2021.100008.pdf,"Abstract The inevitable rise and development of artificial intelligence (AI) was not a sudden occurrence. The greater the effect that AI has on humans, the more pressing the need is for us to understand it. This paper addresses research on the use of AI to evaluate new design methods and tools that can be leveraged to advance AI research, education, policy, and practice to improve the human condition. AI has the potential to educate, train, and improve the performance of humans, making them better at their tasks and activities. The use of AI can enhance human welfare in numerous respects, such as through improving the productivity of food, health, water, education, and energy services. However, the misuse of AI due to algorithm bias and a lack of governance could inhibit human rights and result in employment, gender, and racial inequality. We envision that AI can evolve into human-centered AI (HAI), which refers to approaching AI from a human perspective by considering human conditions and contexts. Most current discussions on AI technology focus on how AI can enable human performance. However, we explore AI can also inhibit the human condition and advocate for an in-depth dialog between technology- and humanity-based researchers to improve understanding of HAI from various perspectives.",,
Human-centred artificial intelligence: a contextual morality perspective,The emergence of big data combined with the technical developments in Artificial Intelligence has enabled novel opportunities for autonomous and continuous decision support.,Search,2020,3,"Niels  van Berkel, Benjamin  Tag, Jorge  Goncalves, Simo  Hosio",,,10.1080/0144929x.2020.1818828,https://doi.org/10.1080/0144929x.2020.1818828,https://semanticscholar.org/paper/f3f8340f6139bea15b2ac533d6a9133694654959,http://jultika.oulu.fi/files/nbnfi-fe202201031079.pdf,The emergence of big data combined with the technical developments in Artificial Intelligence has enabled novel opportunities for autonomous and continuous decision support. While initial work has ...,,
Human-centered Artificial Intelligence: A Multidimensional Approach towards Real World Evidence,An iterative methodology using hermeneutics outlines the need for a forward-thinking approach to deal with Real World Evidence.,Search,2019,3,"Bettina  Schneider, Petra Maria Asprion, Frank  Grimberg",ICEIS,,10.5220/0007715503810390,https://doi.org/10.5220/0007715503810390,https://semanticscholar.org/paper/f831bf2857fe27c3211f602f2839dec59222f251,http://pdfs.semanticscholar.org/603b/6573fa4f30d51652c687e3a6ace0bf6d3c01.pdf,"This study indicates the significance of a human-centered perspective in the analysis and interpretation of Real World Data. As an exemplary use-case, the construct of perceived ‘Health-related Quality of Life’ is chosen to show, firstly, the significance of Real World Data and, secondly, the associated ‘Real World Evidence’. We settled on an iterative methodology and used hermeneutics for a detailed literature analysis to outline the relevance and the need for a forward-thinking approach to deal with Real World Evidence in the life science and health care industry. The novelty of the study is its focus on a human-centered artificial intelligence, which can be achieved by using ‘System Dynamics’ modelling techniques. The outcome – a human-centered ‘Indicator Set’ can be combined with results from data-driven, AI-based analytics. With this multidimensional approach, human intelligence and artificial intelligence can be intertwined towards an enriched Real World Evidence. The developed approach considers three perspectives – the elementary, the algorithmic and – as novelty – the human-centered evidence. As conclusion, we claim that Real World Data are more valuable and applicable to achieve patient-centricity and personalization if the human-centered perspective is considered ‘by design’.",,
Computational Narrative Intelligence: A Human-Centered Goal for Artificial Intelligence,Instilling artificial intelligences with computational narrative intelligence is beneficial to humans.,Search,2016,28,Mark O. Riedl,ArXiv,,,,https://semanticscholar.org/paper/703276a118627f99c832a83c7d9386fd96eb37cc,,"Narrative intelligence is the ability to craft, tell, understand, and respond affectively to stories. We argue that instilling artificial intelligences with computational narrative intelligence affords a number of applications beneficial to humans. We lay out some of the machine learning challenges necessary to solve to achieve computational narrative intelligence. Finally, we argue that computational narrative is a practical step towards machine enculturation, the teaching of sociocultural values to machines.",,
Towards Human Centered Ambient Intelligence,A dynamic and active user model creates a virtual doppelganger of the user on software level.,Search,2008,4,"Thomas  Plötz, Christian  Kleine-Cosack, Gernot A. Fink",AmI,,10.1007/978-3-540-89617-3_3,https://doi.org/10.1007/978-3-540-89617-3_3,https://semanticscholar.org/paper/9fca45ef14d33b4c4736740f07cdfce1904e5133,,"In this paper we present a novel approach to the integration of humans into AmI environments. The key aspect of the concept which we call human centered Ami is a dynamic and active user model which creates a virtual doppelganger of the user on software level. This agent not only complies to the specific characteristics of humans but directly affects and triggers environmental activities. In fact the user's persona and behavior is mapped to system level. Utilizing this doppelganger we introduce the integration of the users' capabilities and skills into the functionality of the environment. Human services enrich intelligent environments and allow to overcome the ""all-or-nothing"" dilemma which we identified in conventional approaches. The concept of human centered AmI is put into effect within the perception-oriented intelligent environment FINCA. Results of a Wizard-of-Oz experiment with real users show the benefits of the presented approach.",,
Human-Centered AI using Ethical Causality and Learning Representation for Multi-Agent Deep Reinforcement Learning,,Search,2021,,"Joshua  Ho, Chien-Min  Wang",2021 IEEE 2nd International Conference on Human-Machine Systems (ICHMS),,10.1109/ICHMS53169.2021.9582667,https://doi.org/10.1109/ICHMS53169.2021.9582667,https://semanticscholar.org/paper/bb14cf7061118e09f258338533544c0a4f68ed9c,,"Human-Centered Computing and AI are two fields devoted to several cross-intersecting interests in the modern AI design. They consider human factors and the machine learning algorithms to enhance compatibility and reliability for human-robot interaction and cooperation. In this work, we propose a novel design concept for the challenging issues that have raised ethical dilemmas; an augmented ethical causality with successor representation for policy gradient models Human-Centered AI with environments. The proposed system leverages Human-Centered AI for using explainable knowledge to construct the ethical causality, and shows it significantly outperformed the statistical approach and baselines alone by further considering meta parametric Human-Centered ethical priorities, when compared to other approaches in the simulated game theory Deep Reinforcement Learning environments. The experimental results aim to efficiently and effectively access the cause, effect and impact of causal inference and multi-agent heterogeneity in the DRL environments for natural, general and significant causal learning representations.",,
Interactive Human Centered Artificial Intelligence: A Definition and Research Challenges,AI will allow the automation of mental routine tasks and that it will extend our ability to perceive the world and foresee events.,Search,2020,7,Albrecht  Schmidt,AVI,,10.1145/3399715.3400873,https://doi.org/10.1145/3399715.3400873,https://semanticscholar.org/paper/5267f3927eeaf45ed6c8340f07c34ff986474c84,,"Artificial Intelligence (AI) has become the buzzword of the last decade. Advances so far have been largely technical with a focus on machine learning (ML). Only recently have we begun seeing a shift towards focusing on the human aspects of artificial intelligence, centered on the narrow view of making AI interactive and explainable. In this paper I suggest a definition for ""Interactive Human Centered Artificial Intelligence and outline the required properties. Staying in control is essential for humans to feel safe and have self-determination. Hence, we need to find ways for humans to understand AI based systems and means to allow human control and oversight. In our work, we argue that levels of abstractions and granularity of control are a general solution to this. Furthermore, it is essential that we make explicit why we want AI and what are the goals of AI research and development. We need to state the properties that we expect of future intelligent systems and who will benefit from a system or service. For me, AI and ML are very much comparable to raw materials (like stone, iron, or bronze). Historical periods are named after these materials as they fundamentally changed what humans can build and what tools humans can engineer. Hence, I argue that in the AI age we need to shift the focus from the material (e.g. the AI algorithms, as there will be plenty of material) towards the tools and infrastructures that are enabled which are beneficial to humans. It is apparent that AI will allow the automation of mental routine tasks and that it will extend our ability to perceive the world and foresee events. For me, the central question is how to create these tools for amplifying the human mind without compromising human values.",,
Reinvigorating the Discourse on Human-Centered Artificial Intelligence in Educational Technologies,"The development and implementation of AI-driven approaches in education involve several privacies, ethics, and morality challenges.",Search,2021,1,"André  Renz, Gergana  Vladova",Technology Innovation Management Review,,10.22215/TIMREVIEW/1438,https://doi.org/10.22215/TIMREVIEW/1438,https://semanticscholar.org/paper/920ff37009ca389fae86d2165b6f5975d81f227a,https://timreview.ca/sites/default/files/article_PDF/TIMReview_2021_May%20-%201_1.pdf,"The increasing relevance of artificial intelligence (AI) applications in various domains has led to high expectations of benefits, ranging from precision, efficiency, and optimization to the completion of routine or time-consuming tasks. Particularly in the field of education, AI applications promise immense innovation potential. A central focus in this field is on analyzing and evaluating learner characteristics to derive learning profiles and create individualized learning environments. The development and implementation of such AI-driven approaches are related to learners' data, and thus involves several privacies, ethics, and morality challenges. In this paper, we introduce the concept of human-centered AI, and consider how an AI system can be developed in line with human values without posing risks to humanity. Because the education market is in the early stages of incorporating AI into educational tools, we believe that this is the right time to raise awareness about the use of principles that foster human-centered values and help in building responsible, ethical, and value-oriented AI.",,
Towards Human-Centered AI: Psychological concepts as foundation for empirical XAI research,End-users with no experience in machine learning may perceive XAI techniques to shed light on AI systems differently.,Search,2021,,Katharina  Weitz,it - Information Technology,,10.1515/itit-2021-0047,https://doi.org/10.1515/itit-2021-0047,https://semanticscholar.org/paper/1b11c9fc8c6bce9dd50504282fcd7eaef06ebeb7,,"Abstract Human-Centered AI is a widely requested goal for AI applications. To reach this is explainable AI promises to help humans to understand the inner workings and decisions of AI systems. While different XAI techniques have been developed to shed light on AI systems, it is still unclear how end-users with no experience in machine learning perceive these. Psychological concepts like trust, mental models, and self-efficacy can serve as instruments to evaluate XAI approaches in empirical studies with end-users. First results in applications for education, healthcare, and industry suggest that one XAI does not fit all. Instead, the design of XAI has to consider user needs, personal background, and the specific task of the AI system.",,