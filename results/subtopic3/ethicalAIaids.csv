Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Ethical Artificial Intelligence for Digital Health Organizations,A US-based Digital Health company developed an ethical code for emotional AI services for mental health support.,Search,2020,9,"Angela  Joerin, Michiel  Rauws, Russell  Fulmer, Valerie  Black",Cureus,,10.7759/cureus.7202,https://doi.org/10.7759/cureus.7202,https://semanticscholar.org/paper/a8f262b28aa4a35196814b447346f99173c4795a,https://www.cureus.com/articles/25462-ethical-artificial-intelligence-for-digital-health-organizations.pdf,"This technical report describes the methods undertaken by a US-based Digital Health company (X2AI or X2 for short) to develop an ethical code for startup environments and other organizations delivering emotional artificial intelligence (AI) services, especially for mental health support. With a growing demand worldwide for scalable, affordable, and accessible health care solutions, the use of AI offers tremendous potential to improve emotional well-being. To realize this potential, it is imperative that AI service providers prioritize clear and consistent ethical guidelines that align with global considerations regarding user safety and privacy. This report offers a template for an ethical code that can be implemented by other emotional AI services and their affiliates. It includes practical guidelines for integrating support from clients, collaborators, and research partners. It also shows how existing ethical systems can inform the development of AI ethics.",,
Ethical Artificial Intelligence - An Open Question,"Artificial Intelligence is an effective science that employs strong enough approaches, methods, and techniques to solve unsolvable real world based problems.",Search,2017,12,"Alice  Pavaloiu, Utku  Kose",ArXiv,,,,https://semanticscholar.org/paper/b952eaffb220ed192728d2ce7436235827132057,,"Artificial Intelligence (AI) is an effective science which employs strong enough approaches, methods, and techniques to solve unsolvable real world based problems. Because of its unstoppable rise towards the future, there are also some discussions about its ethics and safety. Shaping an AI friendly environment for people and a people friendly environment for AI can be a possible answer for finding a shared context of values for both humans and robots. In this context, objective of this paper is to address the ethical issues of AI and explore the moral dilemmas that arise from ethical algorithms, from pre set or acquired values. In addition, the paper will also focus on the subject of AI safety. As general, the paper will briefly analyze the concerns and potential solutions to solving the ethical issues presented and increase readers awareness on AI safety as another related research interest.",,
Artificial intelligence in a crisis needs ethics with urgency,Artificial intelligence can be used in the COVID-19 response to save lives on a pandemic scale.,Search,2020,14,"Asaf  Tzachor, Jess  Whittlestone, Lalitha S Sundaram, Seán Ó hÉigeartaigh",Nat. Mach. Intell.,,10.1038/s42256-020-0195-0,https://doi.org/10.1038/s42256-020-0195-0,https://semanticscholar.org/paper/cda4b91f54ee9ecb0be363c58735caa5b0d85d35,https://www.nature.com/articles/s42256-020-0195-0.pdf,"Artificial intelligence tools can help save lives in a pandemic. However, the need to implement technological solutions rapidly raises challenging ethical issues. We need new approaches for ethics with urgency, to ensure AI can be safely and beneficially used in the COVID-19 response and beyond.",,
AI for humanitarian action: Human rights and ethics,"AI will increasingly shape the global response to the world's toughest problems, especially in the development and humanitarian sector.",Search,2020,2,"Michael  Pizzi, Mila  Romanoff, Tim  Engelhardt",International Review of the Red Cross,,10.1017/S1816383121000011,https://doi.org/10.1017/S1816383121000011,https://semanticscholar.org/paper/ec22353879fc43ba66fb1bc2447798efbae6a283,,"Abstract Artificial intelligence (AI)-supported systems have transformative applications in the humanitarian sector but they also pose unique risks for human rights, even when used with the best intentions. Drawing from research and expert consultations conducted across the globe in recent years, this paper identifies key points of consensus on how humanitarian practitioners can ensure that AI augments – rather than undermines – human interests while being rights-respecting. Specifically, these consultations emphasized the necessity of an anchoring framework based on international human rights law as an essential baseline for ensuring that human interests are embedded in AI systems. Ethics, in addition, can play a complementary role in filling gaps and elevating standards above the minimum requirements of international human rights law. This paper summarizes the advantages of this framework, while also identifying specific tools and best practices that either already exist and can be adapted to the AI context, or that need to be created, in order to operationalize this human rights framework. As the COVID crisis has laid bare, AI will increasingly shape the global response to the world's toughest problems, especially in the development and humanitarian sector. To ensure that AI tools enable human progress and contribute to achieving the Sustainable Development Goals, humanitarian actors need to be proactive and inclusive in developing tools, policies and accountability mechanisms that protect human rights.",,
How AI can be a force for good,Ethics plays a key role in ensuring that regulations of AI harness its potential while mitigating its risks.,Search,2018,179,"Mariarosaria  Taddeo, Luciano  Floridi",Science,,10.1126/science.aat5991,https://doi.org/10.1126/science.aat5991,https://semanticscholar.org/paper/540e19cca64b2d9a13b6caac81124c5f097517fa,,"An ethical framework will help to harness the potential of AI while keeping humans in control Artificial intelligence (AI) is not just a new technology that requires regulation. It is a powerful force that is reshaping daily practices, personal and professional interactions, and environments. For the well-being of humanity it is crucial that this power is used as a force of good. Ethics plays a key role in this process by ensuring that regulations of AI harness its potential while mitigating its risks.",,
An ethically mindful approach to AI for health care,"The risks of AI in health care include inconclusive, inscrutable, or misguided evidence, unfair outcomes, and transformative effects.",Search,2020,12,"Jessica  Morley, Luciano  Floridi",The Lancet,,10.1016/S0140-6736(19)32975-7,https://doi.org/10.1016/S0140-6736(19)32975-7,https://semanticscholar.org/paper/b9bc01ba06e37bc1f514099af5418e0bfbbafbf1,,"254 www.thelancet.com Vol 395 January 25, 2020 Health-care systems worldwide face increasing demand, a rise in chronic disease, and resource constraints. At the same time, the use of digital health technologies in all care settings has led to an expansion of data. These data, if harnessed appropriately, could enable health-care providers to target the causes of ill-health and monitor the effectiveness of preventions and interventions. For this reason, policy makers, politicians, clinical entrepreneurs, and computer and data scientists argue that a key part of health-care solutions will be artificial Intelligence (AI), particularly machine learning. AI forms a key part of the National Health Service (NHS) Long-Term Plan (2019) in England, the US National Institutes of Health Strategic Plan for Data Science (2018), and China’s Healthy China 2030 strategy (2016). The willingness to embrace the potential future of medical care, expressed in these national strategies, is a positive development. Health-care providers should, however, be mindful of the risks that arise from AI’s ability to change the intrinsic nature of how health care is delivered. Such potential AI transformations raise ethical risks that are normative, epistemic, or overarching. Such risks relate to inconclusive, inscrutable, or misguided evidence; unfair outcomes or transformative effects; or traceability. Examples of these risks are described in the table. To mitigate these risks, a bold and systematic approach is needed to the implementation of AI solutions in health care that recognises the challenges and addresses them directly. Crucially, this approach must not rely solely on hard governance measures, such as new statutory obligations, that are designed in response to calls for the development of a robust regulatory system. These measures are necessary but insufficient. Regulations provide only the necessary rules of the game, not the best strategy to win it. What is needed is an ethical focus on the end user, and their expectations, demands, needs, and rights. The challenge is the insufficiently consistent approach to this kind of analysis. To date, responses to the ethical risks, such as the NHS Code of Conduct for Data-Driven Health and Care Technology and other non-sector specific ethical codes, centre on protecting the individual. This approach is understandable because this is the An ethically mindful approach to AI for health care",,
Artificial intelligence for good health: a scoping review of the ethics literature,"The ethics of AI in health, particularly carer robots, diagnostics, and precision medicine, are largely unknown.",Search,2021,10,"Kathleen  Murphy, Erica  Di Ruggiero, Ross  Upshur, Donald J. Willison, Neha  Malhotra, Jia Ce Cai, Nakul  Malhotra, Vincci  Lui, Jennifer  Gibson",BMC medical ethics,,10.1186/s12910-021-00577-8,https://doi.org/10.1186/s12910-021-00577-8,https://semanticscholar.org/paper/803879148f1586908bf1a4177843ef05e73a0ad5,https://bmcmedethics.biomedcentral.com/track/pdf/10.1186/s12910-021-00577-8,"Background Artificial intelligence (AI) has been described as the “fourth industrial revolution” with transformative and global implications, including in healthcare, public health, and global health. AI approaches hold promise for improving health systems worldwide, as well as individual and population health outcomes. While AI may have potential for advancing health equity within and between countries, we must consider the ethical implications of its deployment in order to mitigate its potential harms, particularly for the most vulnerable. This scoping review addresses the following question: What ethical issues have been identified in relation to AI in the field of health, including from a global health perspective? Methods Eight electronic databases were searched for peer reviewed and grey literature published before April 2018 using the concepts of health, ethics, and AI, and their related terms. Records were independently screened by two reviewers and were included if they reported on AI in relation to health and ethics and were written in the English language. Data was charted on a piloted data charting form, and a descriptive and thematic analysis was performed. Results Upon reviewing 12,722 articles, 103 met the predetermined inclusion criteria. The literature was primarily focused on the ethics of AI in health care, particularly on carer robots, diagnostics, and precision medicine, but was largely silent on ethics of AI in public and population health. The literature highlighted a number of common ethical concerns related to privacy, trust, accountability and responsibility, and bias. Largely missing from the literature was the ethics of AI in global health, particularly in the context of low- and middle-income countries (LMICs). Conclusions The ethical issues surrounding AI in the field of health are both vast and complex. While AI holds the potential to improve health and health systems, our analysis suggests that its introduction should be approached with cautious optimism. The dearth of literature on the ethics of AI within LMICs, as well as in public health, also points to a critical need for further research into the ethical implications of AI within both global and public health, to ensure that its development and implementation is ethical for everyone, everywhere.",,Review
Beyond the promise: implementing ethical AI,"Businesses require strong, mandated governance controls to ensure responsible AI use in enterprises.",Search,2021,19,Ray  Eitel-Porter,AI Ethics,,10.1007/s43681-020-00011-6,https://doi.org/10.1007/s43681-020-00011-6,https://semanticscholar.org/paper/0a7109502e7fe91f4decc3dd3515e1fecbc02da7,https://link.springer.com/content/pdf/10.1007/s43681-020-00011-6.pdf,"Artificial Intelligence (AI) applications can and do have unintended negative consequences for businesses if not implemented with care. Specifically, faulty or biased AI applications risk compliance and governance breaches and damage to the corporate brand. These issues commonly arise from a number of pitfalls associated with AI development, which include rushed development, a lack of technical understanding, and improper quality assurance, among other factors. To mitigate these risks, a growing number of organisations are working on ethical AI principles and frameworks. However, ethical AI principles alone are not sufficient for ensuring responsible AI use in enterprises. Businesses also require strong, mandated governance controls including tools for managing processes and creating associated audit trails to enforce their principles. Businesses that implement strong governance frameworks, overseen by an ethics board and strengthened with appropriate training, will reduce the risks associated with AI. When applied to AI modelling, the governance will also make it easier for businesses to bring their AI deployments to scale.",,
Ethical AI Implementation,Implementing ethics in business is not unique that just comes along with AI.,Search,2021,,Stefan H. Vieweg,AI for the Good,,10.1007/978-3-030-66913-3_11,https://doi.org/10.1007/978-3-030-66913-3_11,https://semanticscholar.org/paper/58e1ee159dc218fa4d18645a7ba12e7f36780894,,"Implementing ethics in business is not unique that just comes along with AI. Though, the implications in an AI setting are much more far-reaching than ever before. Given its disruptive nature, AI affects entire societies’ prosperity projections right down to every individual to earn a living; it has a massive impact on the environment as well. Illustration of key initiatives in the EU and the USA toward ethical AI is discussed such as applicable laws (e.g., GDPR and CCPA on data privacy) and ideas such as the RoboLaw on automation or the electronic person (e-person). Postulates from various commissions are summarized and selected organizations thriving for ethical AI are introduced.",,
Medical ethics considerations on artificial intelligence,It is crucial that measures be taken to monitor technological developments to ensure preventative and precautionary safeguards are in place to safeguard the rights of those involved against direct or indirect coercion.,Search,2019,41,Kadircan H. Keskinbora,Journal of Clinical Neuroscience,,10.1016/j.jocn.2019.03.001,https://doi.org/10.1016/j.jocn.2019.03.001,https://semanticscholar.org/paper/bc6519025efcd4db20267691e0b6eabfe44dac95,,"Artificial intelligence (AI) is currently one of the mostly controversial matters of the world. This article discusses AI in terms of the medical ethics issues involved, both existing and potential. Once artificial intelligence is fully developed within electronic systems, it will afford many useful applications in many sectors ranging from banking, agriculture, medical procedures to military operations, especially by decreasing the involvement of humans in critically dangerous activities. Robots as well as computers themselves are embodiments of values inasmuch as they entail actions and choices, but their practical applications are modelled or programmed by the engineers building the systems. AI will need algorithmic procedures to ensure safety in the implementation of such systems. The AI algorithms written could naturally contain errors that may result in unforeseen consequences and unfair outcomes along economic and racial class lines. It is crucial that measures be taken to monitor technological developments ensuring preventative and precautionary safeguards are in place to safeguard the rights of those involved against direct or indirect coercion. While it is the responsibility of AI researchers to ensure that the future impact is more positive than negative, ethicists and philosophers need to be deeply involved in the development of such technologies from the beginning.",,
The ethics of AI in health care: A mapping review.,Artificial intelligence can have a chilling effect on public trust in health care if action is not taken.,Search,2020,57,"Jessica  Morley, Caio C.V. Machado, Christopher  Burr, Josh  Cowls, Indra  Joshi, Mariarosaria  Taddeo, Luciano  Floridi",Social science & medicine,,10.1016/j.socscimed.2020.113172,https://doi.org/10.1016/j.socscimed.2020.113172,https://semanticscholar.org/paper/0a1da3d352f83f7c539e621ed0ec4d292d812a10,,"This article presents a mapping review of the literature concerning the ethics of artificial intelligence (AI) in health care. The goal of this review is to summarise current debates and identify open questions for future research. Five literature databases were searched to support the following research question: how can the primary ethical risks presented by AI-health be categorised, and what issues must policymakers, regulators and developers consider in order to be 'ethically mindful? A series of screening stages were carried out-for example, removing articles that focused on digital health in general (e.g. data sharing, data access, data privacy, surveillance/nudging, consent, ownership of health data, evidence of efficacy)-yielding a total of 156 papers that were included in the review. We find that ethical issues can be (a) epistemic, related to misguided, inconclusive or inscrutable evidence; (b) normative, related to unfair outcomes and transformative effectives; or (c) related to traceability. We further find that these ethical issues arise at six levels of abstraction: individual, interpersonal, group, institutional, and societal or sectoral. Finally, we outline a number of considerations for policymakers and regulators, mapping these to existing literature, and categorising each as epistemic, normative or traceability-related and at the relevant level of abstraction. Our goal is to inform policymakers, regulators and developers of what they must consider if they are to enable health and care systems to capitalise on the dual advantage of ethical AI; maximising the opportunities to cut costs, improve care, and improve the efficiency of health and care systems, whilst proactively avoiding the potential harms. We argue that if action is not swiftly taken in this regard, a new 'AI winter' could occur due to chilling effects related to a loss of public trust in the benefits of AI for health care.",,Review
Ethical AI for Social Good,The ethical aspects that are critical for future AI4SG efforts are new to AI.,Search,2021,,"Ramya  Akula, Ivan  Garibay",HCI,,10.1007/978-3-030-90963-5_28,https://doi.org/10.1007/978-3-030-90963-5_28,https://semanticscholar.org/paper/1b89902b044eddae06bd302ff82b0548108e0ccf,,"The concept of AI for Social Good(AI4SG) is gaining momentum in both information societies and the AI community. Through all the advancement of AI-based solutions, it can solve societal issues effectively. To date, however, there is only a rudimentary grasp of what constitutes AI socially beneficial in principle, what constitutes AI4SG in reality, and what are the policies and regulations needed to ensure it. This paper fills the vacuum by addressing the ethical aspects that are critical for future AI4SG efforts. Some of these characteristics are new to AI, while others have greater importance due to its usage.",,
Artificial Intelligence (AI) Ethics: Ethics of AI and Ethical AI,AI ethics is still in the infancy stage.,Search,2020,26,"Keng  Siau, Weiyu  Wang",J. Database Manag.,,10.4018/jdm.2020040105,https://doi.org/10.4018/jdm.2020040105,https://semanticscholar.org/paper/39d1f020a585d3f28cb4b4c14497649e6a469ef1,,"Artificial intelligence (AI)-based technology has achieved many great things, such as facial recognition, medical diagnosis, and self-driving cars. AI promises enormous benefits for economic growth, social development, as well as human well-being and safety improvement. However, the low-level of explainability, data biases, data security, data privacy, and ethical problems of AI-based technology pose significant risks for users, developers, humanity, and societies. As AI advances, one critical issue is how to address the ethical and moral challenges associated with AI. Even though the concept of “machine ethics” was proposed around 2006, AI ethics is still in the infancy stage. AI ethics is the field related to the study of ethical issues in AI. To address AI ethics, one needs to consider the ethics of AI and how to build ethical AI. Ethics of AI studies the ethical principles, rules, guidelines, policies, and regulations that are related to AI. Ethical AI is an AI that performs and behaves ethically. One must recognize and understand the potential ethical and moral issues that may be caused by AI to formulate the necessary ethical principles, rules, guidelines, policies, and regulations for AI (i.e., Ethics of AI). With the appropriate ethics of AI, one can then build AI that exhibits ethical behavior (i.e., Ethical AI). This paper will discuss AI ethics by looking at the ethics of AI and ethical AI. What are the perceived ethical and moral issues with AI? What are the general and common ethical principles, rules, guidelines, policies, and regulations that can resolve or at least attenuate these ethical and moral issues with AI? What are some of the necessary features and characteristics of an ethical AI? How to adhere to the ethics of AI to build ethical AI?",,
‘Ethical’ artificial intelligence in the welfare state: Discourse and discrepancy in Australian social services,"In Australia, the discourse around ethical AI does not correspond with the reality of AI deployment in the public sector.",Search,2021,1,"Alexandra  James, Andrew  Whelan",Critical Social Policy,,10.1177/0261018320985463,https://doi.org/10.1177/0261018320985463,https://semanticscholar.org/paper/79472473bb90bba50e9018c6ae7b13a98b1ac9a9,,"In recent years, a discourse of ‘ethical artificial intelligence’ has emerged and gained international traction in response to widely publicised AI failures. In Australia, the discourse around ethical AI does not accord with the reality of AI deployment in the public sector. Drawing on institutional ethnographic approaches, this paper describes the misalignments between how technology is described in government documentation, and how it is deployed in social service delivery. We argue that the propagation of ethical principles legitimates established new public management strategies, and pre-empts questions regarding the efficacy of AI development; instead positioning implementation as inevitable and, provided an ethical framework is adopted, laudable. The ethical AI discourse acknowledges, and ostensibly seeks to move past, widely reported administrative failures involving new technologies. In actuality, this discourse works to make AI implementation a reality, ethical or not.",,
A Framework for Ethical AI at the United Nations,The UN needs a framework to mitigate the risks of AI and to ensure the use of AI aligns with ethical values.,Search,2021,2,Lambert  Hogenhout,ArXiv,,,,https://semanticscholar.org/paper/4212a75ac54080c4861f14616989ae3e30a49c28,,"This paper aims to provide an overview of the ethical concerns in artificial intelligence (AI) and the framework that is needed to mitigate those risks, and to suggest a practical path to ensure the development and use of AI at the United Nations (UN) aligns with our ethical values. The overview discusses how AI is an increasingly powerful tool with potential for good, albeit one with a high risk of negative side-effects that go against fundamental human rights and UN values. It explains the need for ethical principles for AI aligned with principles for data governance, as data and AI are tightly interwoven. It explores different ethical frameworks that exist and tools such as assessment lists. It recommends that the UN develop a framework consisting of ethical principles, architectural standards, assessment methods, tools and methodologies, and a policy to govern the implementation and adherence to this framework, accompanied by an education program for staff.",,Review
Ethics in artificial intelligence: introduction to the special issue,"The development of intelligent systems must incorporate moral, ethical, and legal considerations.",Search,2018,129,Virginia  Dignum,Ethics and Information Technology,,10.1007/s10676-018-9450-z,https://doi.org/10.1007/s10676-018-9450-z,https://semanticscholar.org/paper/6b77b4235bd455cf6df68cfa4fe4e2aa9401d06c,https://link.springer.com/content/pdf/10.1007%2Fs10676-018-9450-z.pdf,"Recent developments in Artificial Intelligence (AI) have generated a steep interest from media and general public. As AI systems (e.g. robots, chatbots, avatars and other intelligent agents) are moving from being perceived as a tool to being perceived as autonomous agents and team-mates, an important focus of research and development is understanding the ethical impact of these systems. What does it mean for an AI system to make a decision? What are the moral, societal and legal consequences of their actions and decisions? Can an AI system be held accountable for its actions? How can these systems be controlled once their learning capabilities bring them into states that are possibly only remotely linked to their initial, designed, setup? Should such autonomous innovation in commercial systems even be allowed, and how should use and development be regulated? These and many other related questions are currently the focus of much attention. The way society and our systems will be able to deal with these questions will for a large part determine our level of trust, and ultimately, the impact of AI in society, and the existence of AI. Contrary to the frightening images of a dystopic future in media and popular fiction, where AI systems dominate the world and is mostly concerned with warfare, AI is already changing our daily lives mostly in ways that improve human health, safety, and productivity (Stone et al. 2016). This is the case in domain such as transportation; service robots; health-care; education; public safety and security; and entertainment. Nevertheless, and in order to ensure that those dystopic futures do not become reality, these systems must be introduced in ways that build trust and understanding, and respect human and civil rights. The need for ethical considerations in the development of intelligent interactive systems is becoming one of the main influential areas of research in the last few years, and has led to several initiatives both from researchers as from practitioners, including the IEEE initiative on Ethics of Autonomous Systems1, the Foundation for Responsible Robotics2, and the Partnership on AI3 amongst several others. As the capabilities for autonomous decision making grow, perhaps the most important issue to consider is the need to rethink responsibility (Dignum 2017). Whatever their level of autonomy and social awareness and their ability to learn, AI systems are artefacts, constructed by people to fulfil some goals. Theories, methods, algorithms are needed to integrate societal, legal and moral values into technological developments in AI, at all stages of development (analysis, design, construction, deployment and evaluation). These frameworks must deal both with the autonomic reasoning of the machine about such issues that we consider to have ethical impact, but most importantly, we need frameworks to guide design choices, to regulate the reaches of AI systems, to ensure proper data stewardship, and to help individuals determine their own involvement. Values are dependent on the socio-cultural context (Turiel 2002), and are often only implicit in deliberation processes, which means that methodologies are needed to elicit the values held by all the stakeholders, and to make these explicit can lead to better understanding and trust on artificial autonomous systems. That is, AI reasoning should be able to take into account societal values, moral and ethical considerations; weigh the respective priorities of values held by different stakeholders in various multicultural contexts; explain its reasoning; and guarantee transparency. Responsible Artificial Intelligence is about human responsibility for the development of intelligent systems along fundamental human principles and values, to ensure human flourishing and wellbeing in a sustainable world. In fact, Responsible AI is more than the ticking of some ethical ‘boxes’ in a report, or the development of some add-on features, or switch-off buttons in AI systems. Rather, responsibility is fundamental",,