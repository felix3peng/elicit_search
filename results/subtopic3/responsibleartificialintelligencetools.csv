Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Tools and Practices for Responsible AI Engineering,Hydra-zen and rAI-toolbox are critical needs for responsible AI engineering.,Search,2022,,"Ryan  Soklaski, Justin  Goodwin, Olivia  Brown, Michael  Yee, Jason  Matterer",,,,,https://semanticscholar.org/paper/9a15c604696e672d2ccbcc07d36bf38ba3817bba,,"Responsible Artificial Intelligence (AI)—the practice of developing, evaluating, and maintaining accurate AI systems that also exhibit essential properties such as robustness and explainability—represents a multifaceted challenge that often stretches standard machine learning tooling, frameworks, and testing methods beyond their limits. In this paper, we present two new software libraries—hydra-zen and the rAI-toolbox—that address critical needs for responsible AI engineering. hydra-zen dramatically simplifies the process of making complex AI applications configurable, and their behaviors reproducible. The rAI-toolbox is designed to enable methods for evaluating and enhancing the robustness of AI-models in a way that is scalable and that composes naturally with other popular ML frameworks. We describe the design principles and methodologies that make these tools effective, including the use of property-based testing to bolster the reliability of the tools themselves. Finally, we demonstrate the composability and flexibility of the tools by showing how various use cases from adversarial robustness and explainable AI can be concisely implemented with familiar APIs.",,
Responsibility and Artificial Intelligence,Responsibility is necessary for the development of responsible artificial intelligence systems.,Search,2020,4,Virginia  Dignum,,,10.1093/oxfordhb/9780190067397.013.12,https://doi.org/10.1093/oxfordhb/9780190067397.013.12,https://semanticscholar.org/paper/faf748f8f38d48f2ef310e9e6f55ed277dcbebbf,,"This chapter explores the concept of responsibility in artificial intelligence (AI). Being fundamentally tools, AI systems are fully under the control and responsibility of their owners or users. However, their potential autonomy and capability to learn require that design considers accountability, responsibility, and transparency principles in an explicit and systematic manner. The main concern of Responsible AI is thus the identification of the relative responsibility of all actors involved in the design, development, deployment, and use of AI systems. Firstly, society must be prepared to take responsibility for AI impact. Secondly, Responsible AI implies the need for mechanisms that enable AI systems to act according to ethics and human values. Lastly, Responsible AI is about participation. It is necessary to understand how different people work with and live with AI technologies across cultures in order to develop frameworks for responsible AI.",,
Responsible AI Challenges in End-to-end Machine Learning,Responsible AI must be easy to deploy and actionable.,Search,2021,,"Steven Euijong Whang, Ki Hyun Tae, Yuji  Roh, Geon  Heo",ArXiv,,,,https://semanticscholar.org/paper/0233cd95dd0bc327dd72a14d60216c98021250ab,,"Responsible AI is becoming critical as AI is widely used in our everyday lives. Many companies that deploy AI publicly state that when training a model, we not only need to improve its accuracy, but also need to guarantee that the model does not discriminate against users (fairness), is resilient to noisy or poisoned data (robustness), is explainable, and more. In addition, these objectives are not only relevant to model training, but to all steps of end-to-end machine learning, which include data collection, data cleaning and validation, model training, model evaluation, and model management and serving. Finally, responsible AI is conceptually challenging, and supporting all the objectives must be as easy as possible. We thus propose three key research directions towards this vision – depth, breadth, and usability – to measure progress and introduce our ongoing research. First, responsible AI must be deeply supported where multiple objectives like fairness and robust must be handled together. To this end, we propose FR-Train, a holistic framework for fair and robust model training in the presence of data bias and poisoning. Second, responsible AI must be broadly supported, preferably in all steps of machine learning. Currently we focus on the data pre-processing steps and propose Slice Tuner, a selective data acquisition framework for training fair and accurate models, and MLClean, a data cleaning framework that also improves fairness and robustness. Finally, responsible AI must be usable where the techniques must be easy to deploy and actionable. We propose FairBatch, a batch selection approach for fairness that is effective and simple to use, and Slice Finder, a model evaluation tool that automatically finds problematic slices. We believe we scratched the surface of responsible AI for end-to-end machine learning and suggest research challenges moving forward.",,
Responsible AI Tutorial,A key aspect to making AI responsible is to have a development pipeline that can promote reproducibility of results and manage the lineage of data and ML models.,Search,2022,,"Dr Mukta Paliwal, Dattaraj  Rao, Amogh Kamat Tarcar",COMAD/CODS,,10.1145/3493700.3493769,https://doi.org/10.1145/3493700.3493769,https://semanticscholar.org/paper/04b7d3004cdf971ea05803fbe39c25de561afcc5,,"There is rapid technical progress and widespread adoption of Artificial Intelligence (AI) based products and workflows influencing many aspects of human and business activities like banking, healthcare, advertising and many more. Although accuracy of AI models is undoubtedly the most important factor considered while deploying AI based products, there is urgent need to understand how AI can be designed to operate responsibly. Responsible AI is a framework that each software developing organization needs to adapt to build customer trust in the transparency, accountability, fairness, and security of deployed AI solutions. At the same time a key aspect to making AI responsible is to have a development pipeline that can promote reproducibility of results and manage the lineage of data and ML models. This tutorial will throw light on these aspects of Responsible AI with a working example demonstrating the concept. The intent of the tutorial will be to equip the audience with enough knowledge of the concepts along with code to gain appreciation for the importance of building Responsible AI.",,
Software Engineering Methods for Responsible Artificial Intelligence,"By anticipating the consequences of the design choices, reflecting upon the problem being solved by engaging all stakeholders and taking appropriate actions to ensure openness and the system’s social, legal, and ethical acceptability, the ethical considerations can be addressed throughout the AI systems’ software development life-cycle.",Search,2021,,Zahoor Ul Islam,AAMAS,,10.5555/3463952.3464248,https://doi.org/10.5555/3463952.3464248,https://semanticscholar.org/paper/40a6c6adf5f8a0cffcf0c36e1963d6324add2705,,"In order to ensure responsible Artificial intelligence (AI) applications engineering, we need to make sure that the development of AI systems is mindful of the consequences for individuals and societies. By anticipating the consequences of the design choices, reflecting upon the problem being solved by engaging all stakeholders and taking appropriate actions to ensure openness and the system’s social, legal, and ethical acceptability. This research aims to develop an engineering process model by which ethical considerations can be addressed throughout the AI systems’ software development life-cycle. The design methodological framework engineered in this PhD research will support aligning system goals with key ethical values by providing explicit values analysis and interpretation mechanisms, formal representation of ethical values, mechanisms for stakeholders participation in handling ethical deliberation, and providing support for governance and compliance mechanisms.",,
Progressing Towards Responsible AI,"Progress in AI can be assessed with ethical, legal, social, economic, and cultural considerations.",Search,2020,2,"Teresa  Scantamburlo, Atia  Cort'es, Marie  Schacht",ArXiv,,,,https://semanticscholar.org/paper/f704ed8791dc7d0d8e7f7a9176d2fcee644161b9,,"The field of Artificial Intelligence (AI) and, in particular, the Machine Learning area, counts on a wide range of performance metrics and benchmark data sets to assess the problem-solving effectiveness of its solutions. However, the appearance of research centres, projects or institutions addressing AI solutions from a multidisciplinary and multi-stakeholder perspective suggests a new approach to assessment comprising ethical guidelines, reports or tools and frameworks to help both academia and business to move towards a responsible conceptualisation of AI. They all highlight the relevance of three key aspects: (i) enhancing cooperation among the different stakeholders involved in the design, deployment and use of AI; (ii) promoting multidisciplinary dialogue, including different domains of expertise in this process; and (iii) fostering public engagement to maximise a trusted relation with new technologies and practitioners. In this paper, we introduce the Observatory on Society and Artificial Intelligence (OSAI), an initiative grew out of the project AI4EU aimed at stimulating reflection on a broad spectrum of issues of AI (ethical, legal, social, economic and cultural). In particular, we describe our work in progress around OSAI and suggest how this and similar initiatives can promote a wider appraisal of progress in AI. This will give us the opportunity to present our vision and our modus operandi to enhance the implementation of these three fundamental dimensions.",,
Responsible AI: The Revolution in Governance Technology in China,The development of responsible artificial intelligence has been incorporated into the governance framework of the Chinese government.,Search,2021,,"Chaomin  Li, Lei  Yang",2021 2nd International Conference on Artificial Intelligence and Education (ICAIE),,10.1109/ICAIE53562.2021.00023,https://doi.org/10.1109/ICAIE53562.2021.00023,https://semanticscholar.org/paper/467dc3ecfec931adb0ecafd67ac093022b07b875,,"The development of responsible artificial intelligence has been incorporated into the governance framework of the Chinese government, and has become an important tool for technological change in government governance. It is reflected in e-government, government robots and data governance. The application of AI in governance requires a rational examination of several questions: Who is responsible? To whom? What is responsibility? And how to responsible for? Through the study, the following understandings are obtained: first, the artificial intelligence participating in government governance cannot assume administrative responsibility as the administrative subject because it does not have the sense of autonomy. Second, artificial intelligence based on big data and cloud computing has developed a new ""human-computer interaction"" relationship with human beings. In the future, the public and the government themselves should be included in the scope of the responsible objects of artificial intelligence. Third, due to the immature development of artificial intelligence, its existing technical loopholes are easy to cause the security risk of government data and personal privacy data leakage. Fourth, to develop responsible artificial intelligence and improve the effectiveness of government governance, we need to start from responsibility awareness, regulatory system, ethical norms and legal policies.",,
Responsible AI and Its Stakeholders,All stakeholders involved in the development of AI are responsible for their systems.,Search,2020,3,"Gabriel  Lima, Meeyoung  Cha",ArXiv,,,,https://semanticscholar.org/paper/1d2eac19d1bd75d9d9f2afc919c2612b819c4ac2,,"Responsible Artificial Intelligence (AI) proposes a framework that holds all stakeholders involved in the development of AI to be responsible for their systems. It, however, fails to accommodate the possibility of holding AI responsible per se, which could close some legal and moral gaps concerning the deployment of autonomous and self-learning systems. We discuss three notions of responsibility (i.e., blameworthiness, accountability, and liability) for all stakeholders, including AI, and suggest the roles of jurisdiction and the general public in this matter.",,
Measures and Best Practices for Responsible AI,"The development of task-specific datasets, metrics, and best practices is essential to determine the trustworthiness of machine learning models.",Search,2021,,"Sunipa  Dev, Mehrnoosh  Sameki, Jwala  Dhamala, Cho-Jui  Hsieh",KDD,,10.1145/3447548.3469458,https://doi.org/10.1145/3447548.3469458,https://semanticscholar.org/paper/7b7f889440dd3bbb234ca5a0033b28bef1db0144,,"The use of machine learning (ML) based systems has become ubiquitous including their usage in critical applications like medicine and assistive technologies. Therefore, it is important to determine the trustworthiness of these ML models and tasks. A key component in this determination is the development of task specific datasets, metrics, and best practices which are able to measure the various aspects of responsible model development and deployment including robustness, interpretability and fairness. Further, datasets are also key when training for a given task, be it coreference resolution in language modeling or facial recognition in computer vision. Imbalances and inadequate representation in datasets can have repercussions of an undesirable nature. Some common examples include how coreference resolution systems in NLU are often not all gender inclusive, discrepancies in the measurement of how robust and trustworthy machine predictions are in domains where the selective labels problem is prevalent, and discriminatory determination of pain or care levels of people belonging to different demographics in health science applications. Development of task specific datasets which do better in this regard is also extremely vital. In this workshop, we invite contributions towards different (i) datasets which help enhance task performance and inclusivity, (ii) measures and metrics which help in determining the trustworthiness of a model/dataset, (iii) assessment or remediation tools for fairer, more transparent, robust, and reliable models, and (iv) case studies describing responsible development and deployment of AI systems across fields such as healthcare, financial services, insurance, etc. The datasets, measures, mitigation techniques, and best practices could focus on different areas including (but not restricted to) the following: Fairness and Bias Robustness Reliability and Safety Interpretability Explainability Ethical AI Causal Inference Counterfactual Example Analysis They could also be focussed on the applications in diverse fields such as industry, finance, healthcare and beyond. Text based datasets can be in languages other than English as well.",,
Toward an Understanding of Responsible Artificial Intelligence Practices,There is an urgently need to understand how AI can be designed to operate responsibly and act in a manner meeting stakeholders’ expectations and applicable regulations.,Search,2020,16,"Yichuan  Wang, Mengran  Xiong, Hossein  Olya",HICSS,,10.24251/hicss.2020.610,https://doi.org/10.24251/hicss.2020.610,https://semanticscholar.org/paper/6f62e85aa4034e206caa2482e90c349c954e21fb,http://eprints.whiterose.ac.uk/162719/8/Toward%20an%20Understanding%20of%20Responsible%20Artificial%20Intelligence%20Practices.pdf,"Artificial Intelligence (AI) is influencing all aspects of human and business activities nowadays. Although potential benefits emerged from AI technologies have been widely discussed in many current literature, there is an urgently need to understand how AI can be designed to operate responsibly and act in a manner meeting stakeholders’ expectations and applicable regulations. We seek to fill the gap by exploring the practices of responsible AI and identifying the potential benefits when implementing responsible AI practices. In this study, 10 responsible AI cases were selected from different industries to better understand the use of responsible AI in practices. Four responsible AI practices are identified, including governance, ethically design solutions, risk control and training and education and five strategies for firms who are considering to adopt responsible AI practices are recommended.",,
Software Engineering for Responsible AI: An Empirical Study and Operationalised Patterns,"Many AI ethics principles and guidelines for responsible AI have been issued by governments, organizations, and enterprises.",Search,2021,1,"Qinghua  Lu, Liming  Zhu, Xiwei  Xu, Jon  Whittle, David  Douglas, Conrad  Sanderson",ArXiv,,,,https://semanticscholar.org/paper/6a03b02e61b447ce1456624853d7accfd24a2711,,"Although artificial intelligence (AI) is solving real-world challenges and transforming industries, there are serious concerns about its ability to behave and make decisions in a responsible way. Many AI ethics principles and guidelines for responsible AI have been recently issued by governments, organisations, and enterprises. However, these AI ethics principles and guidelines are typically high-level and do not provide concrete guidance on how to design and develop responsible AI systems. To address this shortcoming, we first present an empirical study where we interviewed 21 scientists and engineers to understand the practitioners’ perceptions on AI ethics principles and their implementation. We then propose a template that enables AI ethics principles to be operationalised in the form of concrete patterns and suggest a list of patterns using the newly created template. These patterns provide concrete, operationalised guidance that facilitate the development of responsible AI systems.",,
Responsible AI,AI can be used to improve the lives of people with disabilities.,Search,2021,1,Ben  Shneiderman,Commun. ACM,,10.1145/3445973,https://doi.org/10.1145/3445973,https://semanticscholar.org/paper/dd8216b7c6329d7931ed5ad842263e960d15397d,,Recommendations for increasing the benefits of artificial intelligence technologies.,,
Responsible AI: A Primer for the Legal Community,"The legal community should have a good understanding of the responsible development and deployment of artificial intelligence in order to inform, translate, and advise on the legal implications of AI systems.",Search,2020,,"Ilana  Golbin, Anand S. Rao, Ali  Hadjarian, Daniel  Krittman",2020 IEEE International Conference on Big Data (Big Data),,10.1109/BigData50022.2020.9377738,https://doi.org/10.1109/BigData50022.2020.9377738,https://semanticscholar.org/paper/7d6cd81f02876c8bdd3c75582a73734339fdd711,,"Artificial intelligence (AI) is increasingly being adopted for automation and decision-making tasks across all industries, public sector, and law. Applications range from hiring and credit limit decisions, to loan and healthcare claim approvals, to criminal sentencing, and even the selective provision of information by social media companies to different groups of viewers. The increased adoption of AI, affecting so many aspects of our daily lives, highlights the potential risks around automated decision making and the need for better governance and ethical standards when deploying such systems. In response to that need, governments, states, municipalities, private sector organizations, and industry groups around the world have drafted hundreds, perhaps even thousands at this point - of new, regulatory proposals and guidelines; many already in effect and more on the way. The data-driven and often black box nature of these systems does not absolve organizations from the social responsibility or increasingly commonplace regulatory requirements to confirm they work as intended and are deployed in a responsible manner, lest they run the risk of reputational damage, regulatory fines, and/or legal action. The legal community should have a good understanding of the responsible development and deployment of artificial intelligence in order to inform, translate, and advise on the legal implications of AI systems.",,
Principles to Practices for Responsible AI: Closing the Gap,Companies need to develop responsible AI practices in order to be a part of the responsible AI movement.,Search,2020,10,"Daniel  Schiff, Bogdana  Rakova, Aladdin  Ayesh, Anat  Fanti, Michael  Lennon",ArXiv,,,,https://semanticscholar.org/paper/973b72984abceec59d1a97622b1a34946a9d89ef,,"Companies have considered adoption of various high-level artificial intelligence (AI) principles for responsible AI, but there is less clarity on how to implement these principles as organizational practices. This paper reviews the principles-to-practices gap. We outline five explanations for this gap ranging from a disciplinary divide to an overabundance of tools. In turn, we argue that an impact assessment framework which is broad, operationalizable, flexible, iterative, guided, and participatory is a promising approach to close the principles-to-practices gap. Finally, to help practitioners with applying these recommendations, we review a case study of AI's use in forest ecosystem restoration, demonstrating how an impact assessment framework can translate into effective and responsible AI practices.",,Review
Principles and business processes for responsible AI,A risk assessment approach is required to manage AI responsibly.,Search,2019,25,Roger  Clarke,Comput. Law Secur. Rev.,,10.1016/J.CLSR.2019.04.007,https://doi.org/10.1016/J.CLSR.2019.04.007,https://semanticscholar.org/paper/9042677e67305726a4511ef3e9a7a00239af2a79,,"Abstract The first article in this series examined why the world wants controls over Artificial Intelligence (AI). This second article discusses how an organisation can manage AI responsibly, in order to protect its own interests, but also those of its stakeholders and society as a whole. A limited amount of guidance is provided by ethical analysis. A much more effective approach is to apply adapted forms of the established techniques of risk assessment and risk management. Critically, risk assessment needs to be undertaken not only with the organisation's own interests in focus, but also from the perspectives of other stakeholders. To underpin this new form of business process, a set of Principles for Responsible AI is presented, consolidating proposals put forward by a diverse collection of 30 organisations.",,
Responsible AI for Digital Health: a Synthesis and a Research Agenda,There are significant issues regarding each of the areas of responsible AI in health AI.,Search,2021,11,"Cristina  Trocin, Patrick  Mikalef, Zacharoula  Papamitsiou, Kieran  Conboy",Information Systems Frontiers,,10.1007/s10796-021-10146-4,https://doi.org/10.1007/s10796-021-10146-4,https://semanticscholar.org/paper/758289be073e7d4e6be6e6e4a7f937ef48ae81bd,https://link.springer.com/content/pdf/10.1007/s10796-021-10146-4.pdf,"Responsible AI is concerned with the design, implementation and use of ethical, transparent, and accountable AI technology in order to reduce biases, promote fairness, equality, and to help facilitate interpretability and explainability of outcomes, which are particularly pertinent in a healthcare context. However, the extant literature on health AI reveals significant issues regarding each of the areas of responsible AI, posing moral and ethical consequences. This is particularly concerning in a health context where lives are at stake and where there are significant sensitivities that are not as pertinent in other domains outside of health. This calls for a comprehensive analysis of health AI using responsible AI concepts as a structural lens. A systematic literature review supported our data collection and sampling procedure, the corresponding analysis, and extraction of research themes helped us provide an evidence-based foundation. We contribute with a systematic description and explanation of the intellectual structure of Responsible AI in digital health and develop an agenda for future research.",,Review