Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Responsibility and Artificial Intelligence,"AI systems require designers to consider accountability, responsibility, and transparency principles.",Search,2020,4,Virginia  Dignum,,,10.1093/oxfordhb/9780190067397.013.12,https://doi.org/10.1093/oxfordhb/9780190067397.013.12,https://semanticscholar.org/paper/faf748f8f38d48f2ef310e9e6f55ed277dcbebbf,,"This chapter explores the concept of responsibility in artificial intelligence (AI). Being fundamentally tools, AI systems are fully under the control and responsibility of their owners or users. However, their potential autonomy and capability to learn require that design considers accountability, responsibility, and transparency principles in an explicit and systematic manner. The main concern of Responsible AI is thus the identification of the relative responsibility of all actors involved in the design, development, deployment, and use of AI systems. Firstly, society must be prepared to take responsibility for AI impact. Secondly, Responsible AI implies the need for mechanisms that enable AI systems to act according to ethics and human values. Lastly, Responsible AI is about participation. It is necessary to understand how different people work with and live with AI technologies across cultures in order to develop frameworks for responsible AI.",,
Toward an Understanding of Responsible Artificial Intelligence Practices,There is an urgently need to understand how AI can be designed to operate responsibly and act in a manner meeting stakeholders’ expectations and applicable regulations.,Search,2020,16,"Yichuan  Wang, Mengran  Xiong, Hossein  Olya",HICSS,,10.24251/hicss.2020.610,https://doi.org/10.24251/hicss.2020.610,https://semanticscholar.org/paper/6f62e85aa4034e206caa2482e90c349c954e21fb,http://eprints.whiterose.ac.uk/162719/8/Toward%20an%20Understanding%20of%20Responsible%20Artificial%20Intelligence%20Practices.pdf,"Artificial Intelligence (AI) is influencing all aspects of human and business activities nowadays. Although potential benefits emerged from AI technologies have been widely discussed in many current literature, there is an urgently need to understand how AI can be designed to operate responsibly and act in a manner meeting stakeholders’ expectations and applicable regulations. We seek to fill the gap by exploring the practices of responsible AI and identifying the potential benefits when implementing responsible AI practices. In this study, 10 responsible AI cases were selected from different industries to better understand the use of responsible AI in practices. Four responsible AI practices are identified, including governance, ethically design solutions, risk control and training and education and five strategies for firms who are considering to adopt responsible AI practices are recommended.",,
Responsible AI Tutorial,A key aspect to making AI responsible is to have a development pipeline that can promote reproducibility of results and manage the lineage of data and ML models.,Search,2022,,"Dr Mukta Paliwal, Dattaraj  Rao, Amogh Kamat Tarcar",COMAD/CODS,,10.1145/3493700.3493769,https://doi.org/10.1145/3493700.3493769,https://semanticscholar.org/paper/04b7d3004cdf971ea05803fbe39c25de561afcc5,,"There is rapid technical progress and widespread adoption of Artificial Intelligence (AI) based products and workflows influencing many aspects of human and business activities like banking, healthcare, advertising and many more. Although accuracy of AI models is undoubtedly the most important factor considered while deploying AI based products, there is urgent need to understand how AI can be designed to operate responsibly. Responsible AI is a framework that each software developing organization needs to adapt to build customer trust in the transparency, accountability, fairness, and security of deployed AI solutions. At the same time a key aspect to making AI responsible is to have a development pipeline that can promote reproducibility of results and manage the lineage of data and ML models. This tutorial will throw light on these aspects of Responsible AI with a working example demonstrating the concept. The intent of the tutorial will be to equip the audience with enough knowledge of the concepts along with code to gain appreciation for the importance of building Responsible AI.",,
Tools and Practices for Responsible AI Engineering,Hydra-zen and rAI-toolbox represent critical needs for responsible AI engineering.,Search,2022,,"Ryan  Soklaski, Justin  Goodwin, Olivia  Brown, Michael  Yee, Jason  Matterer",,,,,https://semanticscholar.org/paper/9a15c604696e672d2ccbcc07d36bf38ba3817bba,,"Responsible Artificial Intelligence (AI)—the practice of developing, evaluating, and maintaining accurate AI systems that also exhibit essential properties such as robustness and explainability—represents a multifaceted challenge that often stretches standard machine learning tooling, frameworks, and testing methods beyond their limits. In this paper, we present two new software libraries—hydra-zen and the rAI-toolbox—that address critical needs for responsible AI engineering. hydra-zen dramatically simplifies the process of making complex AI applications configurable, and their behaviors reproducible. The rAI-toolbox is designed to enable methods for evaluating and enhancing the robustness of AI-models in a way that is scalable and that composes naturally with other popular ML frameworks. We describe the design principles and methodologies that make these tools effective, including the use of property-based testing to bolster the reliability of the tools themselves. Finally, we demonstrate the composability and flexibility of the tools by showing how various use cases from adversarial robustness and explainable AI can be concisely implemented with familiar APIs.",,
Principles and business processes for responsible AI,Organizations must responsibly manage Artificial Intelligence in order to protect their own interests.,Search,2019,25,Roger  Clarke,Comput. Law Secur. Rev.,,10.1016/J.CLSR.2019.04.007,https://doi.org/10.1016/J.CLSR.2019.04.007,https://semanticscholar.org/paper/9042677e67305726a4511ef3e9a7a00239af2a79,,"Abstract The first article in this series examined why the world wants controls over Artificial Intelligence (AI). This second article discusses how an organisation can manage AI responsibly, in order to protect its own interests, but also those of its stakeholders and society as a whole. A limited amount of guidance is provided by ethical analysis. A much more effective approach is to apply adapted forms of the established techniques of risk assessment and risk management. Critically, risk assessment needs to be undertaken not only with the organisation's own interests in focus, but also from the perspectives of other stakeholders. To underpin this new form of business process, a set of Principles for Responsible AI is presented, consolidating proposals put forward by a diverse collection of 30 organisations.",,
Where Responsible AI meets Reality,Large technology companies invest in responsible AI to increase algorithmic accountability.,Search,2021,5,"Bogdana  Rakova, Jingying  Yang, Henriette  Cramer, Rumman  Chowdhury",Proc. ACM Hum. Comput. Interact.,,10.1145/3449081,https://doi.org/10.1145/3449081,https://semanticscholar.org/paper/889add991f6f00ab10a8ea59feb7d472d87391b9,http://arxiv.org/pdf/2006.12358,"Large and ever-evolving technology companies continue to invest more time and resources to incorporate responsible Artificial Intelligence (AI) into production-ready systems to increase algorithmic accountability. This paper examines and seeks to offer a framework for analyzing how organizational culture and structure impact the effectiveness of responsible AI initiatives in practice. We present the results of semi-structured qualitative interviews with practitioners working in industry, investigating common challenges, ethical tensions, and effective enablers for responsible AI initiatives. Focusing on major companies developing or utilizing AI, we have mapped what organizational structures currently support or hinder responsible AI initiatives, what aspirational future processes and structures would best enable effective initiatives, and what key elements comprise the transition from current work practices to the aspirational future.",,
Responsible AI and Its Stakeholders,All stakeholders involved in the development of AI should be responsible for their systems.,Search,2020,3,"Gabriel  Lima, Meeyoung  Cha",ArXiv,,,,https://semanticscholar.org/paper/1d2eac19d1bd75d9d9f2afc919c2612b819c4ac2,,"Responsible Artificial Intelligence (AI) proposes a framework that holds all stakeholders involved in the development of AI to be responsible for their systems. It, however, fails to accommodate the possibility of holding AI responsible per se, which could close some legal and moral gaps concerning the deployment of autonomous and self-learning systems. We discuss three notions of responsibility (i.e., blameworthiness, accountability, and liability) for all stakeholders, including AI, and suggest the roles of jurisdiction and the general public in this matter.",,
Responsible AI Challenges in End-to-end Machine Learning,Responsible AI is becoming critical as AI is widely used in our everyday lives.,Search,2021,,"Steven Euijong Whang, Ki Hyun Tae, Yuji  Roh, Geon  Heo",ArXiv,,,,https://semanticscholar.org/paper/0233cd95dd0bc327dd72a14d60216c98021250ab,,"Responsible AI is becoming critical as AI is widely used in our everyday lives. Many companies that deploy AI publicly state that when training a model, we not only need to improve its accuracy, but also need to guarantee that the model does not discriminate against users (fairness), is resilient to noisy or poisoned data (robustness), is explainable, and more. In addition, these objectives are not only relevant to model training, but to all steps of end-to-end machine learning, which include data collection, data cleaning and validation, model training, model evaluation, and model management and serving. Finally, responsible AI is conceptually challenging, and supporting all the objectives must be as easy as possible. We thus propose three key research directions towards this vision – depth, breadth, and usability – to measure progress and introduce our ongoing research. First, responsible AI must be deeply supported where multiple objectives like fairness and robust must be handled together. To this end, we propose FR-Train, a holistic framework for fair and robust model training in the presence of data bias and poisoning. Second, responsible AI must be broadly supported, preferably in all steps of machine learning. Currently we focus on the data pre-processing steps and propose Slice Tuner, a selective data acquisition framework for training fair and accurate models, and MLClean, a data cleaning framework that also improves fairness and robustness. Finally, responsible AI must be usable where the techniques must be easy to deploy and actionable. We propose FairBatch, a batch selection approach for fairness that is effective and simple to use, and Slice Finder, a model evaluation tool that automatically finds problematic slices. We believe we scratched the surface of responsible AI for end-to-end machine learning and suggest research challenges moving forward.",,
Responsible AI for Digital Health: a Synthesis and a Research Agenda,The issues regarding responsible AI in health are particularly concerning given the sensitivities in that domain.,Search,2021,11,"Cristina  Trocin, Patrick  Mikalef, Zacharoula  Papamitsiou, Kieran  Conboy",Information Systems Frontiers,,10.1007/s10796-021-10146-4,https://doi.org/10.1007/s10796-021-10146-4,https://semanticscholar.org/paper/758289be073e7d4e6be6e6e4a7f937ef48ae81bd,https://link.springer.com/content/pdf/10.1007/s10796-021-10146-4.pdf,"Responsible AI is concerned with the design, implementation and use of ethical, transparent, and accountable AI technology in order to reduce biases, promote fairness, equality, and to help facilitate interpretability and explainability of outcomes, which are particularly pertinent in a healthcare context. However, the extant literature on health AI reveals significant issues regarding each of the areas of responsible AI, posing moral and ethical consequences. This is particularly concerning in a health context where lives are at stake and where there are significant sensitivities that are not as pertinent in other domains outside of health. This calls for a comprehensive analysis of health AI using responsible AI concepts as a structural lens. A systematic literature review supported our data collection and sampling procedure, the corresponding analysis, and extraction of research themes helped us provide an evidence-based foundation. We contribute with a systematic description and explanation of the intellectual structure of Responsible AI in digital health and develop an agenda for future research.",,Review
Companies Committed to Responsible AI: From Principles towards Implementation and Regulation?,Some companies have carried out valuable steps towards implementing responsible AI principles.,Search,2021,,Paul B. de Laat,Philosophy & technology,,10.1007/s13347-021-00474-3,https://doi.org/10.1007/s13347-021-00474-3,https://semanticscholar.org/paper/da6eb144c2f88f2523edf78445517bb32f97d1f1,https://link.springer.com/content/pdf/10.1007/s13347-021-00474-3.pdf,"The term ‘responsible AI’ has been coined to denote AI that is fair and non-biased, transparent and explainable, secure and safe, privacy-proof, accountable, and to the benefit of mankind. Since 2016, a great many organizations have pledged allegiance to such principles. Amongst them are 24 AI companies that did so by posting a commitment of the kind on their website and/or by joining the ‘Partnership on AI’. By means of a comprehensive web search, two questions are addressed by this study: (1) Did the signatory companies actually try to implement these principles in practice, and if so, how? (2) What are their views on the role of other societal actors in steering AI towards the stated principles (the issue of regulation)? It is concluded that some three of the largest amongst them have carried out valuable steps towards implementation, in particular by developing and open sourcing new software tools. To them, charges of mere ‘ethics washing’ do not apply. Moreover, some 10 companies from both the USA and Europe have publicly endorsed the position that apart from self-regulation, AI is in urgent need of governmental regulation. They mostly advocate focussing regulation on high-risk applications of AI, a policy which to them represents the sensible middle course between laissez-faire on the one hand and outright bans on technologies on the other. The future shaping of standards, ethical codes, and laws as a result of these regulatory efforts remains, of course, to be determined.",,
Ensuring Responsible AI in Practice,Ethical reasoning by AI systems requires the systems to be able to explain their decisions to humans.,Search,2019,,Virginia  Dignum,Responsible Artificial Intelligence,,10.1007/978-3-030-30371-6_6,https://doi.org/10.1007/978-3-030-30371-6_6,https://semanticscholar.org/paper/dd9b74c42bd880f84b3b2a0a984fda481ec83d49,,"In the previous chapters, we have discussed the issue of responsibility with respect to the processes to design, develop, deploy and use AI (Chapter 4), and how to deal with ethical reasoning by the AI systems themselves (Chapter 5). In this chapter, we will look at mechanisms that can ensure that all involved will indeed take the responsible route.",,
Software as a Medical Device: Regulating AI in Healthcare via Responsible AI,The increased adoption of AI in healthcare requires regulation to avoid potential harm and unfair bias.,Search,2021,,"Muhammad Aurangzeb Ahmad, Steve  Overman, Christine  Allen, Vikas  Kumar, Ankur  Teredesai, Carly  Eckert",KDD,,10.1145/3447548.3470823,https://doi.org/10.1145/3447548.3470823,https://semanticscholar.org/paper/86bd1e97f6db49710b4f00f8b94dffc6f1964d9a,,"With the increased adoption of AI in healthcare, there is a growing recognition and demand to regulate AI in healthcare to avoid potential harm and unfair bias against vulnerable populations. Around a hundred governmental bodies and commissions as well as leaders in the tech sector have proposed principles to create responsible AI systems. However, most of these proposals are short on specifics which has led to charges of ethics washing. In this tutorial we offer a guide to help navigate through complex governmental regulations and explain the various constituent practical elements of a responsible AI system in healthcare in the light of proposed regulations. Additionally, we breakdown and emphasize that the recommendations from regulatory bodies like FDA or the EU are necessary but not sufficient elements of creating a responsible AI system. We elucidate how regulations and guidelines often focus on epistemic concerns to the detriment of practical concerns e.g., requirement for fairness without explicating what fairness constitutes for a use case. FDA's Software as a medical device document and EU's GDPR among other AI governance documents talk about the need for implementing sufficiently good machine learning practices. In this tutorial we elucidate what that would mean from a practical perspective for real world use cases in healthcare throughout the machine learning cycle i.e., Data Management, Data Specification, Feature Engineering, Model Evaluation, Model Specification, Model Explainability, Model Fairness, Reproducibility, checks for data leakage and model leakage. We note that conceptualizing responsible AI as a process rather than an end goal accords well with how AI systems are used in practice. We also discuss how a domain centric stakeholder perspective translates into balancing requirements for multiple competing optimization criteria.",,
Responsible Artificial Intelligence: Designing Ai for Human Values,Artificial intelligence increasingly affects lives in smaller or greater ways.,Search,2017,55,Virginia  Dignum,,,,,https://semanticscholar.org/paper/c9fd2a6b240caf3d18f641d5956e71cbd29930e3,,"Artificial intelligence (AI) is increasingly affecting our lives in smaller or greater ways. In order to ensure that systems will uphold human values, design methods are needed that incorporate ethical principles and address societal concerns. In this paper, we explore the impact of AI in the case of the expected effects on the European labor market, and propose the accountability, responsibility and transparency (ART) design principles for the development of AI systems that are sensitive to human values.",,
Responsible bots: 10 guidelines for developers of conversational AI,Bot developers need to earn the trust of people in order for people and society to realize the full potential of bots.,Search,2019,9,"Peter  Bailey, Ryen W. White, Han  Liu, A  Kumaran",,,,,https://semanticscholar.org/paper/d8359aa90bb44e0d88fe2e0fd3e52d06560a2c14,,"In order for people and society to realize the full potential of bots, they need to be designed in such a way that they earn the trust of others. These guidelines are aimed at helping you to design a bot that builds trust in the company and service that the bot represents. These guidelines are not intended as legal advice and you should separately ensure that your bot complies with the fast-paced developments in the law in this area. Also, in designing your bot, you should consider a broad set of responsibilities you have when developing any data-centric AI system, including ethics, privacy, security, safety, inclusion, transparency and accountability. See, for example, Microsoft’s six principles for the responsible development of AI published in the January 2018 book, The Future Computed.",,
AI assisted ethics,"AI programs need oversight programs to monitor, audit, and hold them accountable.",Search,2016,52,"Amitai  Etzioni, Oren  Etzioni",Ethics and Information Technology,,10.1007/s10676-016-9400-6,https://doi.org/10.1007/s10676-016-9400-6,https://semanticscholar.org/paper/cb90d3732a50bce46165e75b2260e0c71a70ba33,,"The growing number of ‘smart’ instruments, those equipped with AI, has raised concerns because these instruments make autonomous decisions; that is, they act beyond the guidelines provided them by programmers. Hence, the question the makers and users of smart instrument (e.g., driver-less cars) face is how to ensure that these instruments will not engage in unethical conduct (not to be conflated with illegal conduct). The article suggests that to proceed we need a new kind of AI program—oversight programs—that will monitor, audit, and hold operational AI programs accountable.",,
Responsible AI,AI technologies should be developed in a way that is beneficial to all of humanity.,Search,2021,1,Ben  Shneiderman,Commun. ACM,,10.1145/3445973,https://doi.org/10.1145/3445973,https://semanticscholar.org/paper/dd8216b7c6329d7931ed5ad842263e960d15397d,,Recommendations for increasing the benefits of artificial intelligence technologies.,,