Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Qualitative Analysis for Human Centered AI,"Qualitative analysis can assist in the process of selecting the data, variables, and model architectures of AI models.",Search,2021,,"Orestis  Papakyriakopoulos, Elizabeth Anne Watkins, Amy  Winecoff, Klaudia  Ja'zwi'nska, Tithi  Chattopadhyay",ArXiv,,,,https://semanticscholar.org/paper/46c823a97599eab441bfc24b8ccf2c64ef959bdc,,"Human-centered artificial intelligence (AI) posits that machine learning and AI should be developed and applied in a socially aware way. In this article, we argue that qualitative analysis (QA) can be a valuable tool in this process, supplementing, informing, and extending the possibilities of AI models. We show this by describing how QA can be integrated in the current prediction paradigm of AI, assisting scientists in the process of selecting data, variables, and model architectures. Furthermore, we argue that QA can be a part of novel paradigms towards Human Centered AI. QA can support scientists and practitioners in practical problem solving and situated model development. It can also promote participatory design approaches, reveal understudied and emerging issues in AI systems, and assist policy making.",,
On Design and Evaluation of Human-centered Explainable AI systems,AI systems need careful investigation of the human side of the equation.,Search,2019,5,Upol  Ehsan,,,,,https://semanticscholar.org/paper/224b00003cdaa9f698be41520a3164d67d47951f,,"AsAI systems become ubiquitous in our lives, the human side of the equation needs careful investigation. The challenges of designing and evaluating ""black-boxed"" AI systems depends crucially on who the human is in the loop. Explanations, viewed as a form of post-hoc interpretability, can help establish rapport, confidence, and understanding between the AI agent and the user, especially when it comes to understanding failures and unexpected AI behavior. To effectively design and evaluate explanation generation systems, we need deeper end-to-end investigations of incorporating fully-realized AI agents and automated explanation generation systems into user studies. In this paper, we present a case study that focuses on how non-expert users perceive different styles of automatically generated rationales by an AI agent along the dimensions of confidence, humanlike-ness, adequate justification, and understandability. We summarize our results and provide a desiderata of research questions yet to be addressed.",,
A Survey of Human‐Centered Evaluations in Human‐Centered Machine Learning,Visual analytics systems integrate interactive visualizations and machine learning to enable expert users to solve complex analysis tasks.,Search,2021,6,"F.  Sperrle, M.  El‐Assady, G.  Guo, R.  Borgo, D. Horng  Chau, A.  Endert, D.  Keim",Comput. Graph. Forum,,10.1111/cgf.14329,https://doi.org/10.1111/cgf.14329,https://semanticscholar.org/paper/76dc15232628e3b5e3ddd5dc8a1b5ad1ef2bf4f6,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/cgf.14329,"Visual analytics systems integrate interactive visualizations and machine learning to enable expert users to solve complex analysis tasks. Applications combine techniques from various fields of research and are consequently not trivial to evaluate. The result is a lack of structure and comparability between evaluations. In this survey, we provide a comprehensive overview of evaluations in the field of human‐centered machine learning. We particularly focus on human‐related factors that influence trust, interpretability, and explainability. We analyze the evaluations presented in papers from top conferences and journals in information visualization and human‐computer interaction to provide a systematic review of their setup and findings. From this survey, we distill design dimensions for structured evaluations, identify evaluation gaps, and derive future research opportunities.",,Systematic Review
Human-Centered Artificial Intelligence and Machine Learning,AI systems must be designed with awareness that they are part of a larger system consisting of humans.,Search,2019,67,Mark O. Riedl,Human Behavior and Emerging Technologies,,10.1002/HBE2.117,https://doi.org/10.1002/HBE2.117,https://semanticscholar.org/paper/1fccba11583dc9e1030713d61bd65e9e9990e39f,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/hbe2.117,"Humans are increasingly coming into contact with artificial intelligence and machine learning systems. Human-centered artificial intelligence is a perspective on AI and ML that algorithms must be designed with awareness that they are part of a larger system consisting of humans. We lay forth an argument that human-centered artificial intelligence can be broken down into two aspects: (1) AI systems that understand humans from a sociocultural perspective, and (2) AI systems that help humans understand them. We further argue that issues of social responsibility such as fairness, accountability, interpretability, and transparency.",,
Human-centered AI: The role of Human-centered Design Research in the development of AI,Artificial Intelligence has the tremendous potential to produce progress and innovation in society.,Search,2020,12,Jan  Auernhammer,,,10.21606/drs.2020.282,https://doi.org/10.21606/drs.2020.282,https://semanticscholar.org/paper/647e53dbfa26c84eb4908ed67855b167da79398f,https://dl.designresearchsociety.org/cgi/viewcontent.cgi?article=1178&context=drs-conference-papers,"Artificial Intelligence has the tremendous potential to produce progress and innovation in society. Designing AI for people has been expressed as essential for societal well-being and the common good. However, human-centered is often used generically without any commitment to a philosophy or overarching approach. This paper outlines different philosophical perspectives and several Human-centered Design approaches and discusses their contribution to the development of Artificial Intelligence. The paper argues that humanistic design research should play a vital role in the pan-disciplinary collaboration with technologists and policymakers to mitigate the impact of AI. Ultimately, Human-centered Artificial Intelligence incorporates involving people and designing Artificial Intelligence systems for people through a genuine human-centered philosophy and approach.",,
Human-centered artificial intelligence in education: Seeing the invisible through the visible,"The misuse of AI due to algorithm bias and a lack of governance could inhibit human rights and result in employment, gender, and racial inequality.",Search,2021,14,"Stephen J.H. Yang, Hiroaki  Ogata, Tatsunori  Matsui, Nian-Shing  Chen",Comput. Educ. Artif. Intell.,,10.1016/J.CAEAI.2021.100008,https://doi.org/10.1016/J.CAEAI.2021.100008,https://semanticscholar.org/paper/8a90ab1c8336d99048e16d5ce3e0148da7cf1371,https://repository.kulib.kyoto-u.ac.jp/dspace/bitstream/2433/261148/1/j.caeai.2021.100008.pdf,"Abstract The inevitable rise and development of artificial intelligence (AI) was not a sudden occurrence. The greater the effect that AI has on humans, the more pressing the need is for us to understand it. This paper addresses research on the use of AI to evaluate new design methods and tools that can be leveraged to advance AI research, education, policy, and practice to improve the human condition. AI has the potential to educate, train, and improve the performance of humans, making them better at their tasks and activities. The use of AI can enhance human welfare in numerous respects, such as through improving the productivity of food, health, water, education, and energy services. However, the misuse of AI due to algorithm bias and a lack of governance could inhibit human rights and result in employment, gender, and racial inequality. We envision that AI can evolve into human-centered AI (HAI), which refers to approaching AI from a human perspective by considering human conditions and contexts. Most current discussions on AI technology focus on how AI can enable human performance. However, we explore AI can also inhibit the human condition and advocate for an in-depth dialog between technology- and humanity-based researchers to improve understanding of HAI from various perspectives.",,
Human-centered Artificial Intelligence: A Multidimensional Approach towards Real World Evidence,An iterative methodology using hermeneutics outlines the need for a forward-thinking approach to deal with Real World Evidence.,Search,2019,3,"Bettina  Schneider, Petra Maria Asprion, Frank  Grimberg",ICEIS,,10.5220/0007715503810390,https://doi.org/10.5220/0007715503810390,https://semanticscholar.org/paper/f831bf2857fe27c3211f602f2839dec59222f251,http://pdfs.semanticscholar.org/603b/6573fa4f30d51652c687e3a6ace0bf6d3c01.pdf,"This study indicates the significance of a human-centered perspective in the analysis and interpretation of Real World Data. As an exemplary use-case, the construct of perceived ‘Health-related Quality of Life’ is chosen to show, firstly, the significance of Real World Data and, secondly, the associated ‘Real World Evidence’. We settled on an iterative methodology and used hermeneutics for a detailed literature analysis to outline the relevance and the need for a forward-thinking approach to deal with Real World Evidence in the life science and health care industry. The novelty of the study is its focus on a human-centered artificial intelligence, which can be achieved by using ‘System Dynamics’ modelling techniques. The outcome – a human-centered ‘Indicator Set’ can be combined with results from data-driven, AI-based analytics. With this multidimensional approach, human intelligence and artificial intelligence can be intertwined towards an enriched Real World Evidence. The developed approach considers three perspectives – the elementary, the algorithmic and – as novelty – the human-centered evidence. As conclusion, we claim that Real World Data are more valuable and applicable to achieve patient-centricity and personalization if the human-centered perspective is considered ‘by design’.",,
Human-centered Explainable AI: Towards a Reflective Sociotechnical Approach,A reflective sociotechnical approach is advocated in AI assessment for understanding the human factors.,Search,2020,22,"Upol  Ehsan, Mark O. Riedl",HCI,,10.1007/978-3-030-60117-1_33,https://doi.org/10.1007/978-3-030-60117-1_33,https://semanticscholar.org/paper/2c9d71966e1e8a527a392bbe28aa53f8e0918755,http://arxiv.org/pdf/2002.01092,"Explanations--a form of post-hoc interpretability--play an instrumental role in making systems accessible as AI continues to proliferate complex and sensitive sociotechnical systems. In this paper, we introduce Human-centered Explainable AI (HCXAI) as an approach that puts the human at the center of technology design. It develops a holistic understanding of ""who"" the human is by considering the interplay of values, interpersonal dynamics, and the socially situated nature of AI systems. In particular, we advocate for a reflective sociotechnical approach. We illustrate HCXAI through a case study of an explanation system for non-technical end-users that shows how technical advancements and the understanding of human factors co-evolve. Building on the case study, we lay out open research questions pertaining to further refining our understanding of ""who"" the human is and extending beyond 1-to-1 human-computer interactions. Finally, we propose that a reflective HCXAI paradigm-mediated through the perspective of Critical Technical Practice and supplemented with strategies from HCI, such as value-sensitive design and participatory design--not only helps us understand our intellectual blind spots, but it can also open up new design and research spaces.",,
How to center AI on humans,AI emulating human intelligence involves a shift from emulating intelligent human tasks to emulating human intelligence.,Search,2020,1,"Frank  Dignum, Virginia  Dignum",NeHuAI@ECAI,,,,https://semanticscholar.org/paper/001d4ec84341de6c75a3ef4fffc6b77409979818,,"In this position paper we investigate what it means for AI to be human-centered. Although many organisations and researchers by now have given requirements for human-centeredness, such as: transparancy, respect for human autonomy, fairness and accountability, this does little to indicate how the AI techniques should be designed in order to be human-centered. In this paper we argue that human-centered AI involves a shift from AI emulating intelligent human tasks, to emulating human intelligence such that we capture enough social intelligence in order for the AI system to be able to center its activity and reasoning on its human users.",,
Human-Centered Artificial Intelligence: Three Fresh Ideas,A three-level governance structure can promote trustworthy human-centered artificial intelligence systems.,Search,2020,32,Ben  Shneiderman,,,10.17705/1thci.00131,https://doi.org/10.17705/1thci.00131,https://semanticscholar.org/paper/454af1728ba52b16965f7d18fc9301d0ffb6d708,https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1136&context=thci,"Human-Centered AI (HCAI) is a promising direction for designing AI systems that support human self-efficacy, promote creativity, clarify responsibility, and facilitate social participation. These human aspirations also encourage consideration of privacy, security, environmental protection, social justice, and human rights. This commentary reverses the current emphasis on algorithms and AI methods, by putting humans at the center of systems design thinking, in effect, a second Copernican Revolution. It offers three ideas: (1) a two-dimensional HCAI framework, which shows how it is possible to have both high levels of human control AND high levels of automation, (2) a shift from emulating humans to empowering people with a plea to shift language, imagery, and metaphors away from portrayals of intelligent autonomous teammates towards descriptions of powerful tool-like appliances and tele-operated devices, and (3) a three-level governance structure that describes how software engineering teams can develop more reliable systems, how managers can emphasize a safety culture across an organization, and how industry-wide certification can promote trustworthy HCAI systems. These ideas will be challenged by some, refined by others, extended to accommodate new technologies, and validated with quantitative and qualitative research. They offer a reframe -a chance to restart design discussions for products and services -which could bring greater benefits to individuals, families, communities, businesses, and society.",,
Human-Centered AI,"AI systems require critical and reflective oversight to uphold ethical principles and proactively consider the risks of bias, misuse, abuse, and unintended consequences.",Search,2021,4,"Hollen  Barmer, Rachel  Dzombak, Matthew  Gaston, Vijaykumar  Palat, Frank  Redner, Carol  Smith, Tanisha  Smith",,,10.1184/R1/16560183.V1,https://doi.org/10.1184/R1/16560183.V1,https://semanticscholar.org/paper/264b9b136889da3b4d7e50ef58c77678b35dc3e0,,"We identify three specific areas of focus to advance human-centered AI:• Designers and systems must understand the context of use and sense changes over time: Successful AI Engineering depends on the team’s ability to identify and articulate the desired system outcome and understand human and contextual factors affecting the outcome. The system itself must be able to learn when shifts in context have occurred. What are the best ways to maintain clarity around operational intent and mechanisms for adapting and evolving systems based on dynamic contexts and user needs? • Development of tools, processes, and practices to scope and facilitate human-machine teaming: Implementation of AI systems entails high levels of interdependence between human and machine. Adoption of AI systems requires the primary users to interact with and understand systems, gaining appropriate levels of trust. Every AI system needs to be designed to recognize boundaries and unfamiliar scenarios, and to provide transparency regarding its limitations. • Methods, mechanisms, and mindsets to engage in critical oversight: AI systems learn through data and observations, rather than being explicitly programmed for a deterministic outcome. Critical and reflective oversight by organizations, teams, and individuals that create and use AI systems is needed to uphold ethical principles and proactively consider the risks of bias, misuse, abuse, and unintended consequences through design, development, and ongoing deployment.For each area, we identify ongoing work as well and challenges and opportunities in developing and deploying AI systems with confidence.",,
"Human-Centered Artificial Intelligence: Trusted, Reliable & Safe.","The new goal of Human-Centered Artificial Intelligence is more likely to produce designs that are Trusted, Reliable & Safe.",Search,2020,2,Ben  Shneiderman,,,,,https://semanticscholar.org/paper/e0b2bfdfcc251747538004be479f3914d0932316,,"Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The new goal of HCAI is more likely to produce designs that are Trusted, Reliable & Safe (TRS). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.",,
"Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy","The methods of Human-Centered Artificial Intelligence are more likely to produce designs that are Reliable, Safe & Trustworthy.",Search,2020,105,Ben  Shneiderman,Int. J. Hum. Comput. Interact.,,10.1080/10447318.2020.1741118,https://doi.org/10.1080/10447318.2020.1741118,https://semanticscholar.org/paper/e49f67fa5c946ad24afcf59699a9cacf1ca53924,http://arxiv.org/pdf/2002.04087,"ABSTRACT Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The methods of HCAI are more likely to produce designs that are Reliable, Safe & Trustworthy (RST). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.",,
Towards Human-Centered AI: Psychological concepts as foundation for empirical XAI research,End-users with no experience in machine learning may perceive XAI techniques to shed light on AI systems differently.,Search,2021,,Katharina  Weitz,it - Information Technology,,10.1515/itit-2021-0047,https://doi.org/10.1515/itit-2021-0047,https://semanticscholar.org/paper/1b11c9fc8c6bce9dd50504282fcd7eaef06ebeb7,,"Abstract Human-Centered AI is a widely requested goal for AI applications. To reach this is explainable AI promises to help humans to understand the inner workings and decisions of AI systems. While different XAI techniques have been developed to shed light on AI systems, it is still unclear how end-users with no experience in machine learning perceive these. Psychological concepts like trust, mental models, and self-efficacy can serve as instruments to evaluate XAI approaches in empirical studies with end-users. First results in applications for education, healthcare, and industry suggest that one XAI does not fit all. Instead, the design of XAI has to consider user needs, personal background, and the specific task of the AI system.",,
Toward the human – Centered approach. A revised model of individual acceptance of AI,The current academic debate is overly concerned by the impact that future AI will have on business and society.,Search,2021,1,"Manlio  Del Giudice, Veronica  Scuotto, Beatrice  Orlando, Mario  Mustilli",Human Resource Management Review,,10.1016/j.hrmr.2021.100856,https://doi.org/10.1016/j.hrmr.2021.100856,https://semanticscholar.org/paper/8b08e549fe4c88b32c31b988ac97adf74d1bf63d,,"Abstract The aim of the study is to understand how humans' acceptance of Artificial Intelligences (AIs) affects human resource management (HRM). To this end, we propose an original conceptual framework based on the idea of a sustainable growth driven by the interplay between AI and HRM. Current academic debate is overly concerned by the impact that future AI will have on business and society. One of the central aspects of the conversation is whether or not AI will replace humans in value-added activities. The study remarks that humanoids are an amplificator of human potential, in light of a human-centered approach. In this vein, present work reconceptualizes the tenets of society 5.0 by considering the category of “innovation ventura”, the evolution of the innovative enterprise in the next AI landscape.",,
Artificial Intelligence for Smart Systems Critical Analysis of the Human Centered Approach,"AI that is human-based is a perspective of ML and AI, which algorithms have to be established with the awareness they are a major segment of the massive system incorporating humans.",Search,2021,,Zoran Galic Hajnal,Journal of Computing and Natural Science,,10.53759/181x/jcns202101013,https://doi.org/10.53759/181x/jcns202101013,https://semanticscholar.org/paper/06ebcb128cc429befb8bc063755c7346f5055e6e,http://anapub.co.ke/journals/jcns/jcns_pdf/2021/jcns_volume_1-issue_3/JCNS202101013.pdf,"A program for Artificial Intelligence (AI) is knowledge as intelligent agent, which typically interacts with the ecosystem. This agent is capable of identifying the status of the ecosystem using the sensors before affecting the state via the actuators. We call the smart systems ""agents” whenever they are able to make some decisions on their own with respect on particular goals. On the other hand, Machine Learning (ML) signifies a specific strategy meant to design smart systems whereby these systems can adapt to specific behaviors with respect to data. In the modern age, humans are rapidly collaborating with ML and AI systems. The AI that is human-based is a perspective of ML and AI, which algorithms have to be established with the awareness that they are a major segment of the massive system incorporating human. In this paper, we have presented a research that means that AI systems understand humans with respect to their socio-cultural aspects and that AI system assist humans comprehend them. We also present an argument of the challenges of social responsibility e.g. transparency, interpretability, accountability and fairness.",,