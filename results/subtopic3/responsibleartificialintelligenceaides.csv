Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Responsible AI Tutorial,A key aspect to making AI responsible is to have a development pipeline that can promote reproducibility of results and manage the lineage of data and ML models.,Search,2022,,"Dr Mukta Paliwal, Dattaraj  Rao, Amogh Kamat Tarcar",COMAD/CODS,,10.1145/3493700.3493769,https://doi.org/10.1145/3493700.3493769,https://semanticscholar.org/paper/04b7d3004cdf971ea05803fbe39c25de561afcc5,,"There is rapid technical progress and widespread adoption of Artificial Intelligence (AI) based products and workflows influencing many aspects of human and business activities like banking, healthcare, advertising and many more. Although accuracy of AI models is undoubtedly the most important factor considered while deploying AI based products, there is urgent need to understand how AI can be designed to operate responsibly. Responsible AI is a framework that each software developing organization needs to adapt to build customer trust in the transparency, accountability, fairness, and security of deployed AI solutions. At the same time a key aspect to making AI responsible is to have a development pipeline that can promote reproducibility of results and manage the lineage of data and ML models. This tutorial will throw light on these aspects of Responsible AI with a working example demonstrating the concept. The intent of the tutorial will be to equip the audience with enough knowledge of the concepts along with code to gain appreciation for the importance of building Responsible AI.",,
Toward an Understanding of Responsible Artificial Intelligence Practices,There is an urgently need to understand how AI can be designed to operate responsibly and act in a manner meeting stakeholders’ expectations and applicable regulations.,Search,2020,16,"Yichuan  Wang, Mengran  Xiong, Hossein  Olya",HICSS,,10.24251/hicss.2020.610,https://doi.org/10.24251/hicss.2020.610,https://semanticscholar.org/paper/6f62e85aa4034e206caa2482e90c349c954e21fb,http://eprints.whiterose.ac.uk/162719/8/Toward%20an%20Understanding%20of%20Responsible%20Artificial%20Intelligence%20Practices.pdf,"Artificial Intelligence (AI) is influencing all aspects of human and business activities nowadays. Although potential benefits emerged from AI technologies have been widely discussed in many current literature, there is an urgently need to understand how AI can be designed to operate responsibly and act in a manner meeting stakeholders’ expectations and applicable regulations. We seek to fill the gap by exploring the practices of responsible AI and identifying the potential benefits when implementing responsible AI practices. In this study, 10 responsible AI cases were selected from different industries to better understand the use of responsible AI in practices. Four responsible AI practices are identified, including governance, ethically design solutions, risk control and training and education and five strategies for firms who are considering to adopt responsible AI practices are recommended.",,
Responsible AI Challenges in End-to-end Machine Learning,Responsible AI is becoming critical as AI is widely used in our everyday lives.,Search,2021,,"Steven Euijong Whang, Ki Hyun Tae, Yuji  Roh, Geon  Heo",ArXiv,,,,https://semanticscholar.org/paper/0233cd95dd0bc327dd72a14d60216c98021250ab,,"Responsible AI is becoming critical as AI is widely used in our everyday lives. Many companies that deploy AI publicly state that when training a model, we not only need to improve its accuracy, but also need to guarantee that the model does not discriminate against users (fairness), is resilient to noisy or poisoned data (robustness), is explainable, and more. In addition, these objectives are not only relevant to model training, but to all steps of end-to-end machine learning, which include data collection, data cleaning and validation, model training, model evaluation, and model management and serving. Finally, responsible AI is conceptually challenging, and supporting all the objectives must be as easy as possible. We thus propose three key research directions towards this vision – depth, breadth, and usability – to measure progress and introduce our ongoing research. First, responsible AI must be deeply supported where multiple objectives like fairness and robust must be handled together. To this end, we propose FR-Train, a holistic framework for fair and robust model training in the presence of data bias and poisoning. Second, responsible AI must be broadly supported, preferably in all steps of machine learning. Currently we focus on the data pre-processing steps and propose Slice Tuner, a selective data acquisition framework for training fair and accurate models, and MLClean, a data cleaning framework that also improves fairness and robustness. Finally, responsible AI must be usable where the techniques must be easy to deploy and actionable. We propose FairBatch, a batch selection approach for fairness that is effective and simple to use, and Slice Finder, a model evaluation tool that automatically finds problematic slices. We believe we scratched the surface of responsible AI for end-to-end machine learning and suggest research challenges moving forward.",,
Making Responsible AI the Norm rather than the Exception,The National Security Commission on Artificial Intelligence (NSCAI) document recommends Responsible AI.,Search,2021,,Abhishek  Gupta,ArXiv,,,,https://semanticscholar.org/paper/75299097114e0eca55790c8f37e4acca6a92cdaa,,"This report prepared by the Montreal AI Ethics Institute provides recommendations in response to the National Security Commission on Artificial Intelligence (NSCAI) Key Considerations for Responsible Development and Fielding of Artificial Intelligence document. The report centres on the idea that Responsible AI should be made the Norm rather than an Exception. It does so by utilizing the guiding principles of: (1) alleviating friction in existing workflows, (2) empowering stakeholders to get buy-in, and (3) conducting an effective translation of abstract standards into actionable engineering practices. After providing some overarching comments on the document from the NSCAI, the report dives into the primary contribution of an actionable framework to help operationalize the ideas presented in the document from the NSCAI. The framework consists of: (1) a learning, knowledge, and information exchange (LKIE), (2) the Three Ways of Responsible AI, (3) an empirically-driven risk-prioritization matrix, and (4) achieving the right level of complexity. All components reinforce each other to move from principles to practice in service of making Responsible AI the norm rather than the exception.",,
Towards Responsible Artificial Intelligence in Long-term Care: A Scoping Review on Practical Approaches.,There is limited empirical evidence detailing how responsible AI innovation is addressed in context.,Search,2021,,"Dirk R M Lukkien, Henk Herman Nap, Hendrik P Buimer, Alexander  Peine, Wouter P C Boon, Johannes C F Ket, Mirella M N Minkman, Ellen H M Moors",The Gerontologist,,10.1093/geront/gnab180,https://doi.org/10.1093/geront/gnab180,https://semanticscholar.org/paper/a2adc42d39d81e6cdb5b32c45451c42fd3aa3427,https://academic.oup.com/gerontologist/advance-article-pdf/doi/10.1093/geront/gnab180/42216937/gnab180.pdf,"BACKGROUND AND OBJECTIVES

Artificial intelligence (AI) is widely positioned to become a key element of intelligent technologies used in the long-term care (LTC) for older adults. The increasing relevance and adoption of AI has encouraged debate over the societal and ethical implications of introducing and scaling AI. This scoping review investigates how the design and implementation of AI technologies in LTC is addressed responsibly: so called responsible innovation (RI).

RESEARCH DESIGN AND METHODS

We conducted a systematic literature search in five electronic databases using concepts related to LTC, AI and RI. We then performed a descriptive and thematic analysis to map the key concepts, types of evidence and gaps in the literature.

RESULTS

After reviewing 3,339 papers, 25 papers were identified that met our inclusion criteria. From this literature, we extracted three overarching themes: user-oriented AI innovation; framing AI as a solution to RI issues; and context-sensitivity. Our results provide an overview of measures taken and recommendations provided to address responsible AI innovation in LTC.

DISCUSSION AND IMPLICATIONS

The review underlines the importance of the context of use when addressing responsible AI innovation in LTC. However, limited empirical evidence actually details how responsible AI innovation is addressed in context. Therefore, we recommend expanding empirical studies on RI at the level of specific AI technologies and their local contexts of use. Also, we call for more specific frameworks for responsible AI innovation in LTC to flexibly guide researchers and innovators. Future frameworks should clearly distinguish between RI processes and outcomes.",,Review
Responsible Machine Learning for Ethical Artificial Intelligence in Business and Industry,Artificial intelligence has become ubiquitous to virtually all socio-economic activities in business and industry.,Search,2021,,"Deepak  Saxena, Markus  Lamest, Veena  Bansal",Advances in Business Information Systems and Analytics,,10.4018/978-1-7998-6985-6.ch030,https://doi.org/10.4018/978-1-7998-6985-6.ch030,https://semanticscholar.org/paper/0d82f696baa2e1d010769ff00109ae5c39d01e98,,"Artificial intelligence (AI) systems have become a new reality of modern life. They have become ubiquitous to virtually all socio-economic activities in business and industry. With the extent of AI's influence on our lives, it is an imperative to focus our attention on the ethics of AI. While humans develop their moral and ethical framework via self-awareness and reflection, the current generation of AI lacks these abilities. Drawing from the concept of human-AI hybrid, this chapter offers managerial and developers' action towards responsible machine learning for ethical artificial intelligence. The actions consist of privacy by design, development of explainable AI, identification and removal of inherent biases, and most importantly, using AI as a moral enabler. Application of these action would not only help towards ethical AI; it would also help in supporting moral development of human-AI hybrid.",,
Responsible AI: A Primer for the Legal Community,The data-driven and often black box nature of these systems does not absolve organizations from the social responsibility.,Search,2020,,"Ilana  Golbin, Anand S. Rao, Ali  Hadjarian, Daniel  Krittman",2020 IEEE International Conference on Big Data (Big Data),,10.1109/BigData50022.2020.9377738,https://doi.org/10.1109/BigData50022.2020.9377738,https://semanticscholar.org/paper/7d6cd81f02876c8bdd3c75582a73734339fdd711,,"Artificial intelligence (AI) is increasingly being adopted for automation and decision-making tasks across all industries, public sector, and law. Applications range from hiring and credit limit decisions, to loan and healthcare claim approvals, to criminal sentencing, and even the selective provision of information by social media companies to different groups of viewers. The increased adoption of AI, affecting so many aspects of our daily lives, highlights the potential risks around automated decision making and the need for better governance and ethical standards when deploying such systems. In response to that need, governments, states, municipalities, private sector organizations, and industry groups around the world have drafted hundreds, perhaps even thousands at this point - of new, regulatory proposals and guidelines; many already in effect and more on the way. The data-driven and often black box nature of these systems does not absolve organizations from the social responsibility or increasingly commonplace regulatory requirements to confirm they work as intended and are deployed in a responsible manner, lest they run the risk of reputational damage, regulatory fines, and/or legal action. The legal community should have a good understanding of the responsible development and deployment of artificial intelligence in order to inform, translate, and advise on the legal implications of AI systems.",,
Responsible AI,AI technologies should be developed in a way that is beneficial to all of humanity.,Search,2021,1,Ben  Shneiderman,Commun. ACM,,10.1145/3445973,https://doi.org/10.1145/3445973,https://semanticscholar.org/paper/dd8216b7c6329d7931ed5ad842263e960d15397d,,Recommendations for increasing the benefits of artificial intelligence technologies.,,
The Quest for Interpretable and Responsible Artificial Intelligence,"Artificial intelligence drives applications in computational biology, finance, law, and robotics.",Search,2019,,Vaishak  Belle,The Biochemist,,10.1042/bio04105016,https://doi.org/10.1042/bio04105016,https://semanticscholar.org/paper/eaa4c65d5a1cbbc78dbdcd4c537ef9bda81bcffc,https://portlandpress.com/biochemist/article-pdf/41/5/16/858257/bio041050016.pdf,"Artificial intelligence (AI) provides many opportunities to improve private and public life. Discovering patterns and structures in large troves of data in an automated manner is a core component of data science, and currently drives applications in computational biology, finance, law and robotics. However, such a highly positive impact is coupled with significant challenges: how do we understand the decisions suggested by these systems in order that we can trust them? How can they be held accountable for those decisions?",,
How to achieve trustworthy artificial intelligence for health,"The EU's guidance leaves room for local, contextualized discretion in the health sector.",Search,2020,15,"Kristine  Bærøe, Ainar  Miyata-Sturm, Edmund  Henden",Bulletin of the World Health Organization,,10.2471/BLT.19.237289,https://doi.org/10.2471/BLT.19.237289,https://semanticscholar.org/paper/0a3c92d6c4fa4670743fb13758916067e772a143,https://europepmc.org/articles/pmc7133476?pdf=render,"Abstract Artificial intelligence holds great promise in terms of beneficial, accurate and effective preventive and curative interventions. At the same time, there is also awareness of potential risks and harm that may be caused by unregulated developments of artificial intelligence. Guiding principles are being developed around the world to foster trustworthy development and application of artificial intelligence systems. These guidelines can support developers and governing authorities when making decisions about the use of artificial intelligence. The High-Level Expert Group on Artificial Intelligence set up by the European Commission launched the report Ethical guidelines for trustworthy artificial intelligence in2019. The report aims to contribute to reflections and the discussion on the ethics of artificial intelligence technologies also beyond the countries of the European Union (EU). In this paper, we use the global health sector as a case and argue that the EU’s guidance leaves too much room for local, contextualized discretion for it to foster trustworthy artificial intelligence globally. We point to the urgency of shared globalized efforts to safeguard against the potential harms of artificial intelligence technologies in health care.",,
Beneficial AI: the next battlefield,"AI-based systems may be prone to be misused and require Accountability, Responsibility and Transparency.",Search,2018,4,Eugénio  Oliveira,,,10.24840/2183-0606_005.004_0002,https://doi.org/10.24840/2183-0606_005.004_0002,https://semanticscholar.org/paper/8057c0ff9771c321f51e09d0d351776f00e60387,https://journalsojs3.fe.up.pt/index.php/jim/article/download/2183-0606_005.004_0002/293,"When planting our human print in a new technology-driven world we should ask, remembering Neil Armstrong in 1969, “after many small steps for AI researchers, will it result in a giant leap in the unknown for mankind?” An “Artificial Intelligence-first” world is being preached all over the media by many responsible players in economic and scientific communities. This letter states our belief in AI potentialities, including its major and decisive role in computer science and engineering, while warning against the current hyping of its near future. Although quite excited by several recent interesting revelations about the future of AI, we here argue in favor of a more cautious interpretation of the current and future AI-based systems potential outreach. We also include some personal perspectives on simple remedies to preventing recognized possible dangers. We advocate a set of practices and principles that may prevent the development of AI-based systems prone to be misused. Accountable “Data curators”, appropriate Software Engineering specification methods, the inclusion, when needed, of the “human in the loop”, software agents with emotion-like states might be important factors leading to more secure AI-based systems. Moreover, to inseminate ART in Artificial Intelligence, ART standing for Accountability, Responsibility and Transparency, becomes also mandatory for trustworthy AI-based systems. This letter is an abbreviation of a more substantial article to be published in IJCA journal.",,
Designing AI systems that obey our laws and values,Calling for research on automatic oversight for artificial intelligence systems.,Search,2016,23,"Amitai  Etzioni, Oren  Etzioni",Commun. ACM,,10.1145/2955091,https://doi.org/10.1145/2955091,https://semanticscholar.org/paper/260f4a655a63e9f0e8867140a8797e7a64e0cdd2,,Calling for research on automatic oversight for artificial intelligence systems.,,
Artificial intelligence in medical diagnosis.,Computer programs that simulate expert human reasoning have not led to clinically useful programs.,Search,1988,166,"P  Szolovits, R S Patil, W B Schwartz",Annals of internal medicine,,10.7326/0003-4819-108-1-80,https://doi.org/10.7326/0003-4819-108-1-80,https://semanticscholar.org/paper/2640a33d0b8f3cac8942ee5e60498d482b0c10d9,,"In an attempt to overcome limitations inherent in conventional computer-aided diagnosis, investigators have created programs that simulate expert human reasoning. Hopes that such a strategy would lead to clinically useful programs have not been fulfilled, but many of the problems impeding creation of effective artificial intelligence programs have been solved. Strategies have been developed to limit the number of hypotheses that a program must consider and to incorporate pathophysiologic reasoning. The latter innovation permits a program to analyze cases in which one disorder influences the presentation of another. Prototypes embodying such reasoning can explain their conclusions in medical terms that can be reviewed by the user. Despite these advances, further major research and developmental efforts will be necessary before expert performance by the computer becomes a reality.",,
Letter to the Editor: Research Priorities for Robust and Beneficial Artificial Intelligence: An Open Letter,AI research must focus on making AI systems beneficial and robust to maximize societal benefit.,Search,2015,41,"Stuart J. Russell, Thomas G. Dietterich, Eric  Horvitz, Bart  Selman, Francesca  Rossi, Demis  Hassabis, Shane  Legg, Mustafa  Suleyman, Dileep  George, D. Scott Phoenix",AI Mag.,,10.1609/aimag.v36i4.2621,https://doi.org/10.1609/aimag.v36i4.2621,https://semanticscholar.org/paper/29b8fb53f600348f0e92787c159f66ffb94d52ac,https://aaai.org/ojs/index.php/aimagazine/article/download/2621/2508,"Artificial intelligence (AI) research has explored a variety of problems and approaches since its inception, but for the last 20 years or so has been focused on the problems surrounding the construction of intelligent agents — systems that perceive and act in some environment. In this context, ""intelligence"" is related to statistical and economic notions of rationality — colloquially, the ability to make good decisions, plans, or inferences. The adoption of probabilistic and decision-theoretic representations and statistical learning methods has led to a large degree of integration and cross-fertilization among AI, machine learning, statistics, control theory, neuroscience, and other fields. The establishment of shared theoretical frameworks, combined with the availability of data and processing power, has yielded remarkable successes in various component tasks such as speech recognition, image classification, autonomous vehicles, machine translation, legged locomotion, and question-answering systems. As capabilities in these areas and others cross the threshold from laboratory research to economically valuable technologies, a virtuous cycle takes hold whereby even small improvements in performance are worth large sums of money, prompting greater investments in research. There is now a broad consensus that AI research is progressing steadily, and that its impact on society is likely to increase. The potential benefits are huge, since everything that civilization has to offer is a product of human intelligence; we cannot predict what we might achieve when this intelligence is magnified by the tools AI may provide, but the eradication of disease and poverty are not unfathomable. Because of the great potential of AI, it is important to research how to reap its benefits while avoiding potential pitfalls. The progress in AI research makes it timely to focus research not only on making AI more capable, but also on maximizing the societal benefit of AI. Such considerations motivated the AAAI 2008–09 Presidential Panel on Long-Term AI Futures and other projects on AI impacts, and constitute a significant expansion of the field of AI itself, which up to now has focused largely on techniques that are neutral with respect to purpose. We recommend expanded research aimed at ensuring that increasingly capable AI systems are robust and beneficial: our AI systems must do what we want them to do. The attached research priorities document [see page X] gives many examples of such research directions that can help maximize the societal benefit of AI. This research is by necessity interdisciplinary, because it involves both society and AI. It ranges from economics, law and philosophy to computer security, formal methods and, of course, various branches of AI itself. In summary, we believe that research on how to make AI systems robust and beneficial is both important and timely, and that there are concrete research directions that can be pursued today.",,
Data-Informed Duties in AI Development,Firms relying on faulty data can be required to compensate those harmed by that data use.,Search,2019,6,Frank A. Pasquale,,,,,https://semanticscholar.org/paper/5391f8441ac5b637d728d138727c7b08d268dfb0,,"Law should help direct—and not merely constrain—the development of artificial intelligence (AI). One path to influence is the development of standards of care both supplemented and informed by rigorous regulatory guidance. Such standards are particularly important given the potential for inaccurate and inappropriate data to contaminate machine learning. Firms relying on faulty data can be required to compensate those harmed by that data use—and should be subject to punitive damages when such use is repeated or willful. Regulatory standards for data collection, analysis, use, and stewardship can inform and complement generalist judges. Such regulation will not only provide guidance to industry to help it avoid preventable accidents. It will also assist a judiciary that is increasingly called upon to develop common law in response to legal disputes arising out of the deployment of AI.",,
Towards Safe Artificial General Intelligence,"If humanity would find itself in conflict with a system of much greater intelligence than itself, then human society would likely lose.",Search,2018,21,Tom  Everitt,,,10.25911/5D134A2F8A7D3,https://doi.org/10.25911/5D134A2F8A7D3,https://semanticscholar.org/paper/8b1e149ae23ea7839c9e3a2bd063c354ff7075d0,,"The field of artificial intelligence has recently experienced a number of breakthroughs thanks to progress in deep learning and reinforcement learning. Computer algorithms now outperform humans at Go, Jeopardy, image classification, and lip reading, and are becoming very competent at driving cars and interpreting natural language. The rapid development has led many to conjecture that artificial intelligence with greater-thanhuman ability on a wide range of tasks may not be far. This in turn raises concerns whether we know how to control such systems, in case we were to successfully build them. Indeed, if humanity would find itself in conflict with a system of much greater intelligence than itself, then human society would likely lose. One way to make sure we avoid such a conflict is to ensure that any future AI system with potentially greater-thanhuman-intelligence has goals that are aligned with the goals of the rest of humanity. For example, it should not wish to kill humans or steal their resources. The main focus of this thesis will therefore be goal alignment, i.e. how to design artificially intelligent agents with goals coinciding with the goals of their designers. Focus will mainly be directed towards variants of reinforcement learning, as reinforcement learning currently seems to be the most promising path towards powerful artificial intelligence. We identify and categorize goal misalignment problems in reinforcement learning agents as designed today, and give examples of how these agents may cause catastrophes in the future. We also suggest a number of reasonably modest modifications that can be used to avoid or mitigate each identified misalignment problem. Finally, we also study various choices of decision algorithms, and conditions for when a powerful reinforcement learning system will permit us to shut it down. The central conclusion is that while reinforcement learning systems as designed today are inherently unsafe to scale to human levels of intelligence, there are ways to potentially address many of these issues without straying too far from the currently so successful reinforcement learning paradigm. Much work remains in turning the high-level proposals suggested in this thesis into practical algorithms, however. Central claim: There are a number of theoretically valid, partial solutions to the problem of keeping artificial general intelligence both safe and useful.",,