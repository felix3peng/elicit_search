Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Artificial Intelligence: the global landscape of ethics guidelines,A global convergence is emerging around five ethical principles with substantive divergence in interpretation.,Search,2019,228,"Anna  Jobin, Marcello  Ienca, Effy  Vayena",ArXiv,,10.1038/s42256-019-0088-2,https://doi.org/10.1038/s42256-019-0088-2,https://semanticscholar.org/paper/7bf47af1f989c1a999d7dab24d86d19f13e8ba55,http://arxiv.org/pdf/1906.11668,"In the last five years, private companies, research institutions as well as public sector organisations have issued principles and guidelines for ethical AI, yet there is debate about both what constitutes ""ethical AI"" and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analyzed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted; why they are deemed important; what issue, domain or actors they pertain to; and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies.",,
The EU Approach to Ethics Guidelines for Trustworthy Artificial Intelligence,The EU Commission established an independent High-Level Expert Group on Artificial Intelligence (AI HLEG).,Search,2019,56,Nathalie A. Smuha,Computer Law Review International,,10.9785/cri-2019-200402,https://doi.org/10.9785/cri-2019-200402,https://semanticscholar.org/paper/a00ee7ae4642b986b622e0f48c845e79707b707b,https://lirias.kuleuven.be/bitstream/123456789/640572/2/EU%20Approach%20for%20Trustworthy%20AI%20-%20a%20continuous%20journey.pdf,"As part of its European strategy for Artificial Intelligence (AI), and as a response to the increasing ethical questions raised by this technology, the European Commission established an independent High-Level Expert Group on Artificial Intelligence (AI HLEG) in June 2018. The group was tasked to draft two deliverables: AI Ethics Guidelines and Policy and Investment Recommendations. Nine months later, its first deliverable was published, putting forward a comprehensive framework to achieve “Trustworthy AI” by offering ethical guidance to AI practitioners. This paper dives into the work carried out by the group, focusing in particular on its AI Ethics Guidelines. First, this paper clarifies the context that led to the creation of the AI HLEG and its mandate (I.). Subsequently, it elaborates on the Guidelines’ aim and purpose (II.), and analyses the Guidelines’ drafting process (III.). Particular focus is given to the questions surrounding the respective role played by ethics and law in the AI governance landscape (IV.), as well as some of the challenges that had to be overcome throughout the process (V.). Finally, this paper places the Guidelines in an international context, and sets out the next steps (VI.) ahead on the journey towards an appropriate governance framework for AI (VII.).",,
The global landscape of AI ethics guidelines,There is a global convergence emerging around five ethical principles with substantial divergence in implementation.,Search,2019,642,"Anna  Jobin, Marcello  Ienca, Effy  Vayena",Nat. Mach. Intell.,,10.1038/S42256-019-0088-2,https://doi.org/10.1038/S42256-019-0088-2,https://semanticscholar.org/paper/35ebed28c967acbfe38fa757f4e7023d075beaeb,http://arxiv.org/pdf/1906.11668,"In the past five years, private companies, research institutions and public sector organizations have issued principles and guidelines for ethical artificial intelligence (AI). However, despite an apparent agreement that AI should be ‘ethical’, there is debate about both what constitutes ‘ethical AI’ and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analysed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted, why they are deemed important, what issue, domain or actors they pertain to, and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies.As AI technology develops rapidly, it is widely recognized that ethical guidelines are required for safe and fair implementation in society. But is it possible to agree on what is ‘ethical AI’? A detailed analysis of 84 AI ethics reports around the world, from national and international organizations, companies and institutes, explores this question, finding a convergence around core principles but substantial divergence on practical implementation.",,
Lessons learned from AI ethics principles for future actions,AI ethics is urgently calling for tangible action to move from high-level abstractions and conceptual arguments towards applying ethics in practice and creating accountability mechanisms.,Search,2021,17,Merve  Hickok,AI Ethics,,10.1007/s43681-020-00008-1,https://doi.org/10.1007/s43681-020-00008-1,https://semanticscholar.org/paper/eb22e505d84b31f52a5bd8bd973f89711891e836,https://link.springer.com/content/pdf/10.1007/s43681-020-00008-1.pdf,"As the use of artificial intelligence (AI) systems became significantly more prevalent in recent years, the concerns on how these systems collect, use and process big data also increased. To address these concerns and advocate for ethical and responsible development and implementation of AI, non-governmental organizations (NGOs), research centers, private companies, and governmental agencies published more than 100 AI ethics principles and guidelines. This first wave was followed by a series of suggested frameworks, tools, and checklists that attempt a technical fix to issues brought up in the high-level principles. Principles are important to create a common understanding for priorities and are the groundwork for future governance and opportunities for innovation. However, a review of these documents based on their country of origin and funding entities shows that private companies from US-West axis dominate the conversation. Several cases surfaced in the meantime which demonstrate biased algorithms and their impact on individuals and society. The field of AI ethics is urgently calling for tangible action to move from high-level abstractions and conceptual arguments towards applying ethics in practice and creating accountability mechanisms. However, lessons must be learned from the shortcomings of AI ethics principles to ensure the future investments, collaborations, standards, codes or legislation reflect the diversity of voices and incorporate the experiences of those who are already impacted by the biased algorithms.",,Review
Understanding artificial intelligence ethics and safety,"The UK public sector can counteract harmful AI by putting in place governance processes that support the design and implementation of ethical, fair, and safe AI systems.",Search,2019,37,David  Leslie,ArXiv,,10.5281/zenodo.3240529,https://doi.org/10.5281/zenodo.3240529,https://semanticscholar.org/paper/adeb97576107e9f8e1140302cf614d1da709d523,,"A remarkable time of human promise has been ushered in by the convergence of the ever-expanding availability of big data, the soaring speed and stretch of cloud computing platforms, and the advancement of increasingly sophisticated machine learning algorithms. Innovations in AI are already leaving a mark on government by improving the provision of essential social goods and services from healthcare, education, and transportation to food supply, energy, and environmental management. These bounties are likely just the start. The prospect that progress in AI will help government to confront some of its most urgent challenges is exciting, but legitimate worries abound. As with any new and rapidly evolving technology, a steep learning curve means that mistakes and miscalculations will be made and that both unanticipated and harmful impacts will occur.

This guide, written for department and delivery leads in the UK public sector and adopted by the British Government in its publication, 'Using AI in the Public Sector,' identifies the potential harms caused by AI systems and proposes concrete, operationalisable measures to counteract them. It stresses that public sector organisations can anticipate and prevent these potential harms by stewarding a culture of responsible innovation and by putting in place governance processes that support the design and implementation of ethical, fair, and safe AI systems. It also highlights the need for algorithmically supported outcomes to be interpretable by their users and made understandable to decision subjects in clear, non-technical, and accessible ways. Finally, it builds out a vision of human-centred and context-sensitive implementation that gives a central role to communication, evidence-based reasoning, situational awareness, and moral justifiability.",,
Principles and business processes for responsible AI,A risk assessment approach is required to manage AI responsibly.,Search,2019,25,Roger  Clarke,Comput. Law Secur. Rev.,,10.1016/J.CLSR.2019.04.007,https://doi.org/10.1016/J.CLSR.2019.04.007,https://semanticscholar.org/paper/9042677e67305726a4511ef3e9a7a00239af2a79,,"Abstract The first article in this series examined why the world wants controls over Artificial Intelligence (AI). This second article discusses how an organisation can manage AI responsibly, in order to protect its own interests, but also those of its stakeholders and society as a whole. A limited amount of guidance is provided by ethical analysis. A much more effective approach is to apply adapted forms of the established techniques of risk assessment and risk management. Critically, risk assessment needs to be undertaken not only with the organisation's own interests in focus, but also from the perspectives of other stakeholders. To underpin this new form of business process, a set of Principles for Responsible AI is presented, consolidating proposals put forward by a diverse collection of 30 organisations.",,
Recommendations for the ethical use and design of artificial intelligent care providers,Artificial intelligent care providers present new ethical issues that will have significant ramifications for the mental health care and other helping professions.,Search,2014,63,David D. Luxton,Artif. Intell. Medicine,,10.1016/j.artmed.2014.06.004,https://doi.org/10.1016/j.artmed.2014.06.004,https://semanticscholar.org/paper/c3fc33be2a7ed7912b23653576e04f7588e77698,,"OBJECTIVE

This paper identifies and reviews ethical issues associated with artificial intelligent care providers (AICPs) in mental health care and other helping professions. Specific recommendations are made for the development of ethical codes, guidelines, and the design of AICPs.

METHODS

Current developments in the application of AICPs and associated technologies are reviewed and a foundational overview of applicable ethical principles in mental health care is provided. Emerging ethical issues regarding the use of AICPs are then reviewed in detail. Recommendations for ethical codes and guidelines as well as for the development of semi-autonomous and autonomous AICP systems are described. The benefits of AICPs and implications for the helping professions are discussed in order to weigh the pros and cons of their use.

RESULTS

Existing ethics codes and practice guidelines do not presently consider the current or the future use of interactive artificial intelligent agents to assist and to potentially replace mental health care professionals. AICPs present new ethical issues that will have significant ramifications for the mental health care and other helping professions. Primary issues involve the therapeutic relationship, competence, liability, trust, privacy, and patient safety. Many of the same ethical and philosophical considerations are applicable to use and design of AICPs in medicine, nursing, social work, education, and ministry.

CONCLUSION

The ethical and moral aspects regarding the use of AICP systems must be well thought-out today as this will help to guide the use and development of these systems in the future. Topics presented are relevant to end users, AI developers, and researchers, as well as policy makers and regulatory boards.",,Review
AI ethics,Integrating ethics into AI education and development is important to ensure that AI is used responsibly.,Search,2021,17,Illah Reza Nourbakhsh,Commun. ACM,,10.1145/3478516,https://doi.org/10.1145/3478516,https://semanticscholar.org/paper/89153f52ca3db65db85b2da24d7970d9e1c15023,https://dl.acm.org/doi/pdf/10.1145/3478516,Integrating ethics into artificial intelligence education and development.,,
Establishing the rules for building trustworthy AI,The European Commission’s report ‘Ethics guidelines for trustworthy AI’ facilitates international support for AI solutions that are good for humanity and the environment.,Search,2019,67,Luciano  Floridi,Nature Machine Intelligence,,10.1038/S42256-019-0055-Y,https://doi.org/10.1038/S42256-019-0055-Y,https://semanticscholar.org/paper/dc44e2be0f85b6225f05390c570885337a99ef83,https://philpapers.org/archive/FLOETR.pdf,"The European Commission’s report ‘Ethics guidelines for trustworthy AI’ provides a clear benchmark to evaluate the responsible development of AI systems, and facilitates international support for AI solutions that are good for humanity and the environment, says Luciano Floridi.",,
On the Governance of Artificial Intelligence through Ethics Guidelines,The EU Commission published the Ethics Guidelines for Trustworthy AI in April 2019.,Search,2020,20,Stefan  LARSSON,Asian Journal of Law and Society,,10.1017/als.2020.19,https://doi.org/10.1017/als.2020.19,https://semanticscholar.org/paper/48268a9d24db58c9a5331acaef8821a7e983a321,https://www.cambridge.org/core/services/aop-cambridge-core/content/view/992BD33CA7CBBE83E2FBBF6B0179896C/S2052901520000194a.pdf/div-class-title-on-the-governance-of-artificial-intelligence-through-ethics-guidelines-div.pdf,"Abstract This article uses a socio-legal perspective to analyze the use of ethics guidelines as a governance tool in the development and use of artificial intelligence (AI). This has become a central policy area in several large jurisdictions, including China and Japan, as well as the EU, focused on here. Particular emphasis in this article is placed on the Ethics Guidelines for Trustworthy AI published by the EU Commission’s High-Level Expert Group on Artificial Intelligence in April 2019, as well as the White Paper on AI, published by the EU Commission in February 2020. The guidelines are reflected against partially overlapping and already-existing legislation as well as the ephemeral concept construct surrounding AI as such. The article concludes by pointing to (1) the challenges of a temporal discrepancy between technological and legal change, (2) the need for moving from principle to process in the governance of AI, and (3) the multidisciplinary needs in the study of contemporary applications of data-dependent AI.",,
Ethical Artificial Intelligence for Digital Health Organizations,A US-based Digital Health company developed an ethical code for emotional AI services.,Search,2020,9,"Angela  Joerin, Michiel  Rauws, Russell  Fulmer, Valerie  Black",Cureus,,10.7759/cureus.7202,https://doi.org/10.7759/cureus.7202,https://semanticscholar.org/paper/a8f262b28aa4a35196814b447346f99173c4795a,https://www.cureus.com/articles/25462-ethical-artificial-intelligence-for-digital-health-organizations.pdf,"This technical report describes the methods undertaken by a US-based Digital Health company (X2AI or X2 for short) to develop an ethical code for startup environments and other organizations delivering emotional artificial intelligence (AI) services, especially for mental health support. With a growing demand worldwide for scalable, affordable, and accessible health care solutions, the use of AI offers tremendous potential to improve emotional well-being. To realize this potential, it is imperative that AI service providers prioritize clear and consistent ethical guidelines that align with global considerations regarding user safety and privacy. This report offers a template for an ethical code that can be implemented by other emotional AI services and their affiliates. It includes practical guidelines for integrating support from clients, collaborators, and research partners. It also shows how existing ethical systems can inform the development of AI ethics.",,
A critical perspective on guidelines for responsible and trustworthy artificial intelligence,The ethical issues of AI technology vary from privacy and confidentiality of personal data to the ethical status and value of AI entities.,Search,2020,4,"Banu  Buruk, Perihan Elif Ekmekci, Berna  Arda","Medicine, health care, and philosophy",,10.1007/s11019-020-09948-1,https://doi.org/10.1007/s11019-020-09948-1,https://semanticscholar.org/paper/4990df10e6423ad5d44888697dd8bc523287fd14,,"Artificial intelligence (AI) is among the fastest developing areas of advanced technology in medicine. The most important qualia of AI which makes it different from other advanced technology products is its ability to improve its original program and decision-making algorithms via deep learning abilities. This difference is the reason that AI technology stands out from the ethical issues of other advanced technology artifacts. The ethical issues of AI technology vary from privacy and confidentiality of personal data to ethical status and value of AI entities in a wide spectrum, depending on their capability of deep learning and scope of the domains in which they operate. Developing ethical norms and guidelines for planning, development, production, and usage of AI technology has become an important issue to overcome these problems. In this respect three outstanding documents have been produced: 1. The Montréal Declaration for Responsible Development of Artificial Intelligence 2. Ethics Guidelines for Trustworthy AI 3. Asilomar Artificial Intelligence Principles In this study, these three documents will be analyzed with respect to the ethical principles and values they involve, their perspectives for approaching ethical issues, and their prospects for ethical reasoning when one or more of these values and principles are in conflict. Then, the sufficiency of these guidelines for addressing current or prospective ethical issues emerging from the existence of AI technology in medicine will be evaluated. The discussion will be pursued in terms of the ambiguity of interlocutors and efficiency for working out ethical dilemmas occurring in practical life.",,
The Ethics of Artificial Intelligence,Some ethical issues arise when some future AI systems may have moral status.,Search,2014,224,"Nick  Bostrom, Eliezer  Yudkowsky",,,10.1017/CBO9781139046855.020,https://doi.org/10.1017/CBO9781139046855.020,https://semanticscholar.org/paper/787996496a300356188ba921f02f926331f80a63,http://intelligence.org/files/EthicsofAI.pdf,"This chapter surveys some of the ethical challenges that may arise as one can create artificial intelligences (AI) of various kinds and degrees. Some challenges of machine ethics are much like many other challenges involved in designing machines. There is nearly universal agreement among modern AI professionals that artificial intelligence falls short of human capabilities in some critical sense, even though AI algorithms have beaten humans in many specific domains such as chess. In creating a superhuman chess player, the human programmers necessarily sacrificed their ability to predict Deep Blue's local, specific game behavior. A different set of ethical issues arises when one can contemplate the possibility that some future AI systems might be candidates for having moral status. One also has moral reasons to treat them in certain ways, and to refrain from treating them in certain other ways. Superintelligence may be achievable by increasing processing speed.",,
Beyond the promise: implementing ethical AI,"Businesses require strong, mandated governance controls to ensure responsible AI use in enterprises.",Search,2021,19,Ray  Eitel-Porter,AI Ethics,,10.1007/s43681-020-00011-6,https://doi.org/10.1007/s43681-020-00011-6,https://semanticscholar.org/paper/0a7109502e7fe91f4decc3dd3515e1fecbc02da7,https://link.springer.com/content/pdf/10.1007/s43681-020-00011-6.pdf,"Artificial Intelligence (AI) applications can and do have unintended negative consequences for businesses if not implemented with care. Specifically, faulty or biased AI applications risk compliance and governance breaches and damage to the corporate brand. These issues commonly arise from a number of pitfalls associated with AI development, which include rushed development, a lack of technical understanding, and improper quality assurance, among other factors. To mitigate these risks, a growing number of organisations are working on ethical AI principles and frameworks. However, ethical AI principles alone are not sufficient for ensuring responsible AI use in enterprises. Businesses also require strong, mandated governance controls including tools for managing processes and creating associated audit trails to enforce their principles. Businesses that implement strong governance frameworks, overseen by an ethics board and strengthened with appropriate training, will reduce the risks associated with AI. When applied to AI modelling, the governance will also make it easier for businesses to bring their AI deployments to scale.",,
Artificial Intelligence (AI) Ethics: Ethics of AI and Ethical AI,AI ethics is still in the infancy stage.,Search,2020,26,"Keng  Siau, Weiyu  Wang",J. Database Manag.,,10.4018/jdm.2020040105,https://doi.org/10.4018/jdm.2020040105,https://semanticscholar.org/paper/39d1f020a585d3f28cb4b4c14497649e6a469ef1,,"Artificial intelligence (AI)-based technology has achieved many great things, such as facial recognition, medical diagnosis, and self-driving cars. AI promises enormous benefits for economic growth, social development, as well as human well-being and safety improvement. However, the low-level of explainability, data biases, data security, data privacy, and ethical problems of AI-based technology pose significant risks for users, developers, humanity, and societies. As AI advances, one critical issue is how to address the ethical and moral challenges associated with AI. Even though the concept of “machine ethics” was proposed around 2006, AI ethics is still in the infancy stage. AI ethics is the field related to the study of ethical issues in AI. To address AI ethics, one needs to consider the ethics of AI and how to build ethical AI. Ethics of AI studies the ethical principles, rules, guidelines, policies, and regulations that are related to AI. Ethical AI is an AI that performs and behaves ethically. One must recognize and understand the potential ethical and moral issues that may be caused by AI to formulate the necessary ethical principles, rules, guidelines, policies, and regulations for AI (i.e., Ethics of AI). With the appropriate ethics of AI, one can then build AI that exhibits ethical behavior (i.e., Ethical AI). This paper will discuss AI ethics by looking at the ethics of AI and ethical AI. What are the perceived ethical and moral issues with AI? What are the general and common ethical principles, rules, guidelines, policies, and regulations that can resolve or at least attenuate these ethical and moral issues with AI? What are some of the necessary features and characteristics of an ethical AI? How to adhere to the ethics of AI to build ethical AI?",,
AI 4 People — An ethical framework for a good AI society,"A ""Good AI Society"" should develop and adopt ethical principles to assess, develop, incentivise, and support good AI.",Search,2018,19,"Cowls, Beltrametti, Chatila, Dignum, Luetge, Madelin, Pagallo, Rossi, Schafer, Valcke",,,,,https://semanticscholar.org/paper/65376df1c3ccf41c2cc4d2088d259c8788789f00,,"This article reports the findings of AI4People, an Atomium—EISMD initiative designed to lay the foundations for a “Good AI Society”. We introduce the core opportunities and risks of AI for society; present a synthesis of five ethical principles that should undergird its development and adoption; and offer 20 concrete recommendations—to assess, to develop, to incentivise, and to support good AI—which in some cases may be undertaken directly by national or supranational policy makers, while in others may be led by other stakeholders. If adopted, these recommendations would serve as a firm foundation for the establishment of a Good AI Society.",,