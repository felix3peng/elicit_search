Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Guidelines for Trustworthy AI application in clinical trials,"Artificial intelligence is becoming increasingly important in medicine, and requirements for trustworthy AI are necessary.",Search,2020,,"N  Leventi, A  Vodenitcharova, K  Popova",,,10.1093/eurpub/ckaa165.806,https://doi.org/10.1093/eurpub/ckaa165.806,https://semanticscholar.org/paper/29898969890b3d4d8a5813a6750d308b3fb7117e,https://academic.oup.com/eurpub/article-pdf/30/Supplement_5/ckaa165.806/33817815/ckaa165.806.pdf,"Innovative information technologies (IIT) like artificial intelligence (AI), big data, etc. promise to support individual patient care, and promote public health. Their use raises ethical, social and legal issues. Here we demonstrate how the guidelines for trustworthy AI, can assist to answer those ethical issues in the case of clinical trials (CT).

In 2018 the European Commission established the High-Level Expert Group on Artificial Intelligence (AI HLEG). The group proposed Guidelines to promote Trustworthy AI, with three components, which should be met throughout the system's entire life cycle, as it should be lawful, ethical and robust.

Trustworthiness is a prerequisite for people and societies to develop, and use AI systems. We used a focus group methodology to explore how the guidelines for trustworthy AI can assist to answer the ethical issues that rise by the application of AI in CTs.

The discussion was directed to the seven requirements for trustworthy AI in CTs, by questions like:

Are they relevant in CTs as a whole? Would they be applicable to the use of IIT as AI in CTs? Are you currently applying part, or all, of the proposed list? In the future, would you attach some, or all, of the proposed list? Is the administrative burden of applying the requirements justified by the effect?

It was recommended that:

the guidelines are relevant in the conduct of the CT; planning and implementation of CTs using IIT, should take them into account; ethical aspects and challenges are of the utmost importance; the proposed list is a very comprehensive framework; particular attention should be paid where more vulnerable groups are affected; the administrative burden is acceptable, as the effect exceeds the resources invested.

IIT are becoming increasingly important in medicine, and requirements for trustworthy IIT, and AI are necessary. Appropriate instrument in the case of the CTs are the provided by AI HLEG guidelines.",,
Trustworthy AI Inference Systems: An Industry Research View,Trends in AI inference systems require collective attention to sustain the operation of trustworthy AI inference systems.,Search,2020,2,"Rosario  Cammarota, Matthias  Schunter, Anand  Rajan, Fabian  Boemer, 'Agnes  Kiss, Amos  Treiber, Christian  Weinert, Thomas  Schneider, Emmanuel  Stapf, Ahmad-Reza  Sadeghi, Daniel  Demmler, Huili  Chen, Siam Umar Hussain, Sadegh  Riazi, Farinaz  Koushanfar, Saransh  Gupta, Tajan Simunic Rosing, Kamalika  Chaudhuri, Hamid  Nejatollahi, Nikil  Dutt, Mohsen  Imani, Kim  Laine, Anuj  Dubey, Aydin  Aysu, Fateme Sadat Hosseini, Chengmo  Yang, Eric  Wallace, Pamela  Norton",ArXiv,,,,https://semanticscholar.org/paper/828947e3e9e06c506e6a30e3eb7e176c0b8b953d,,"In this work, we provide an industry research view for approaching the design, deployment, and operation of trustworthy Artificial Intelligence (AI) inference systems. Such systems provide customers with timely, informed, and customized inferences to aid their decision, while at the same time utilizing appropriate security protection mechanisms for AI models. Additionally, such systems should also use Privacy-Enhancing Technologies (PETs) to protect customers' data at any time.

To approach the subject, we start by introducing trends in AI inference systems. We continue by elaborating on the relationship between Intellectual Property (IP) and private data protection in such systems. Regarding the protection mechanisms, we survey the security and privacy building blocks instrumental in designing, building, deploying, and operating private AI inference systems. For example, we highlight opportunities and challenges in AI systems using trusted execution environments combined with more recent advances in cryptographic techniques to protect data in use. Finally, we outline areas of further development that require the global collective attention of industry, academia, and government researchers to sustain the operation of trustworthy AI inference systems.",,
Trustworthy AI,The pursuit of responsible AI raises the ante on both the trustworthy computing and formal methods communities.,Search,2021,7,Jeannette M. Wing,Commun. ACM,,10.1145/3448248,https://doi.org/10.1145/3448248,https://semanticscholar.org/paper/33cf9b4d6c76f988380b1adff2c06c30010f93d3,https://dl.acm.org/doi/pdf/10.1145/3448248,The pursuit of responsible AI raises the ante on both the trustworthy computing and formal methods communities.,,
Trustworthy AI in the Age of Pervasive Computing and Big Data,The requirements of trustworthy AI systems are specifically focused on the aspects that can be integrated into the design and development of AI systems.,Search,2020,15,"Abhishek  Kumar, Tristan  Braud, Sasu  Tarkoma, Pan  Hui",2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops),,10.1109/percomworkshops48775.2020.9156127,https://doi.org/10.1109/percomworkshops48775.2020.9156127,https://semanticscholar.org/paper/f92cedfdf08f7c92ddefebd06fa763d7a8359c1f,http://repository.ust.hk/ir/bitstream/1783.1-101388/1/neutral-ai.pdf,"The era of pervasive computing has resulted in countless devices that continuously monitor users and their environment, generating an abundance of user behavioural data. Such data may support improving the quality of service, but may also lead to adverse usages such as surveillance and advertisement. In parallel, Artificial Intelligence (AI) systems are being applied to sensitive fields such as healthcare, justice, or human resources, raising multiple concerns on the trustworthiness of such systems. Trust in AI systems is thus intrinsically linked to ethics, including the ethics of algorithms, the ethics of data, or the ethics of practice. In this paper, we formalise the requirements of trustworthy AI systems through an ethics perspective. We specifically focus on the aspects that can be integrated into the design and development of AI systems. After discussing the state of research and the remaining challenges, we show how a concrete use-case in smart cities can benefit from these methods.",,
Questioning the Role of Moral AI as an Adviser within the Framework of Trustworthiness Ethics,Moral AI as an adviser raises concerns about the trustworthiness of its moral model.,Search,2021,,Silviya  Serafimova,Filosofiya-Philosophy,,10.53656/phil2021-04-07,https://doi.org/10.53656/phil2021-04-07,https://semanticscholar.org/paper/da0d6f6c6646773ec04772dad977f2e6f1e20155,,"The main objective of this article is to demonstrate why despite the growing interest in justifying AI’s trustworthiness, one can argue for AI’s reliability. By analyzing why trustworthiness ethics in Nickel’s sense provides some wellgrounded hints for rethinking the rational, affective and normative accounts of trust in respect to AI, I examine some concerns about the trustworthiness of Savulescu and Maslen’s model of moral AI as an adviser. Specifically, I tackle one of its exemplifications regarding Klincewicz’s hypothetical scenario of John which is refracted through the lens of the HLEG’s fifth requirement of trustworthy artificial intelligence (TAI), namely, that of Diversity, non-discrimination and fairness.",,
Opening the software engineering toolbox for the assessment of trustworthy AI,Software engineering and testing practices can be applied to the assessment of trustworthy AI.,Search,2020,2,"Mohit Kumar Ahuja, Mohamed-Bachir  Belaid, Pierre  Bernab'e, Mathieu  Collet, Arnaud  Gotlieb, Chhagan  Lal, Dusica  Marijan, Sagar  Sen, Aizaz  Sharif, Helge  Spieker",NeHuAI@ECAI,,,,https://semanticscholar.org/paper/3b0ff6bd000e9c615d024614343f2c1cf12bf124,,"Trustworthiness is a central requirement for the acceptance and success of human-centered artificial intelligence (AI). To deem an AI system as trustworthy, it is crucial to assess its behaviour and characteristics against a gold standard of Trustworthy AI, consisting of guidelines, requirements, or only expectations. While AI systems are highly complex, their implementations are still based on software. The software engineering community has a long-established toolbox for the assessment of software systems, especially in the context of software testing. In this paper, we argue for the application of software engineering and testing practices for the assessment of trustworthy AI. We make the connection between the seven key requirements as defined by the European Commission's AI high-level expert group and established procedures from software engineering and raise questions for future work.",,
"Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy",The methods of Human-Centered Artificial Intelligence are more likely to produce RST technologies.,Search,2020,105,Ben  Shneiderman,Int. J. Hum. Comput. Interact.,,10.1080/10447318.2020.1741118,https://doi.org/10.1080/10447318.2020.1741118,https://semanticscholar.org/paper/e49f67fa5c946ad24afcf59699a9cacf1ca53924,http://arxiv.org/pdf/2002.04087,"ABSTRACT Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The methods of HCAI are more likely to produce designs that are Reliable, Safe & Trustworthy (RST). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.",,
Trustworthiness of Artificial Intelligence,"AI has a lot of benefits when it comes to societal, individual or cultural development.",Search,2020,4,"Sonali  Jain, Manan  Luthra, Shagun  Sharma, Mehtab  Fatima",2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS),,10.1109/ICACCS48705.2020.9074237,https://doi.org/10.1109/ICACCS48705.2020.9074237,https://semanticscholar.org/paper/2efae53ba8d84c6f11d3f7151f23b9e22ca806e4,,"This paper discusses the need for a trustworthy AI, along with the ethics which are required to keep that trust intact. AI has a lot of benefits when it comes to societal, individual or cultural development. But any mistake in either the development or in the working phase of the AI system can be disastrous, especially when human lives are involved. The main goal of this paper is to understand what really makes an Artificial Intelligence system trustworthy.",,
Zombies in the Loop? Humans Trust Untrustworthy AI-Advisors for Ethical Decisions,AI is overtrusted rather than distrusted.,Search,2021,,"Sebastian  Krugel, Andreas  Ostermaier, Matthias  Uhl",,,,,https://semanticscholar.org/paper/5fa1ca52f54ec170d42f899ff918ec3609895d42,,"Departing from the claim that AI needs to be trustworthy, we find that ethical advice from an AI-powered algorithm is trusted even when its users know nothing about its training data and when they learn information about it that warrants distrust. We conducted online experiments where the subjects took the role of decision-makers who received advice from an algorithm on how to deal with an ethical dilemma. We manipulated the information about the algorithm and studied its influence. Our findings suggest that AI is overtrusted rather than distrusted. We suggest digital literacy as a potential remedy to ensure the responsible use of AI.",,
Trustworthy AI: From Principles to Practices,"AI practitioners need to develop AI systems that are robust, generalizable, explainable, transparent, reproducible, fair, private, and aligned with human values.",Search,2021,1,"Bo  Li, Peng  Qi, Bo  Liu, Shuai  Di, Jingen  Liu, Jiquan  Pei, Jinfeng  Yi, Bowen  Zhou",ArXiv,,,,https://semanticscholar.org/paper/c3689493757f90267908e776aeada9194fce55c7,,"Fast developing artificial intelligence (AI) technology has enabled various applied systems deployed in the real world, impacting people’s everyday lives. However, many current AI systems were found vulnerable to imperceptible attacks, biased against underrepresented groups, lacking in user privacy protection, etc., which not only degrades user experience but erodes the society’s trust in all AI systems. In this review, we strive to provide AI practitioners a comprehensive guide towards building trustworthy AI systems. We first introduce the theoretical framework of important aspects of AI trustworthiness, including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, alignment with human values, and accountability. We then survey leading approaches in these aspects in the industry. To unify the current fragmented approaches towards trustworthy AI, we propose a systematic approach that considers the entire lifecycle of AI systems, ranging from data acquisition to model development, to development and deployment, finally to continuous monitoring and governance. In this framework, we offer concrete action items to practitioners and societal stakeholders (e.g., researchers and regulators) to improve AI trustworthiness. Finally, we identify key opportunities and challenges in the future development of trustworthy AI systems, where we identify the need for paradigm shift towards comprehensive trustworthy AI systems.",,Review
Trustworthy AI,The issue of bias and fairness is one of the critical issues in enhancing user and public trust in AI systems.,Search,2021,,"Richa  Singh, Mayank  Vatsa, Nalini  Ratha",COMAD/CODS,,10.1145/3430984.3431966,https://doi.org/10.1145/3430984.3431966,https://semanticscholar.org/paper/4f52a1c995d5b7ba2be6d419146dbf9ee6b0316c,,"Modern AI systems are reaping the advantage of novel learning methods. With their increasing usage, we are realizing the limitations and shortfalls of these systems. Brittleness to minor adversarial changes in the input data, ability to explain the decisions, address the bias in their training data, high opacity in terms of revealing the lineage of the system, how they were trained and tested, and under which parameters and conditions they can reliably guarantee a certain level of performance, are some of the most prominent limitations. Ensuring the privacy and security of the data, assigning appropriate credits to data sources, and delivering decent outputs are also required features of an AI system. We propose the tutorial on “Trustworthy AI” to address six critical issues in enhancing user and public trust in AI systems, namely: (i) bias and fairness, (ii) explainability, (iii) robust mitigation of adversarial attacks, (iv) improved privacy and security in model building, (v) being decent, and (vi) model attribution, including the right level of credit assignment to the data sources, model architectures, and transparency in lineage.",,
A secure composition framework for trustworthy personal information assistants,A key benefit of a personal information assistant is that the user's information is guaranteed to be free from accidental leakage to Websites that are not trustworthy.,Search,2005,1,"V.N.  Venkatakrishnan, Wei  Xu, I.V.  Ramakrishnan, R.  Sekar","International Conference on Integration of Knowledge Intensive Multi-Agent Systems, 2005.",,10.1109/KIMAS.2005.1427144,https://doi.org/10.1109/KIMAS.2005.1427144,https://semanticscholar.org/paper/2e1ff6d6eba0b50f850db53229a5517911051747,,"In this paper, we provide a framework that supports composition of individual agents that enables users to accomplish complex tasks that would otherwise be laborious and difficult with mere use of traditional keyword based search engines. A key benefit of our approach is that in the framework the personal information handled by the agent system is guaranteed to be free from accidental leakage to Websites that are not trustworthy, thereby ensuring the privacy of end-user data. We describe our approach with a prototype example which suggests that such highly usable, trustworthy agent systems can be built and deployed quickly with modest implementation efforts.",,
Trustworthy AI Development Guidelines for Human System Interaction,AI development guidelines can improve the user trust in AI systems to enhance human-AI interactions.,Search,2020,3,"Chathurika S. Wickramasinghe, Daniel L. Marino, Javier  Grandio, Milos  Manic",2020 13th International Conference on Human System Interaction (HSI),,10.1109/HSI49210.2020.9142644,https://doi.org/10.1109/HSI49210.2020.9142644,https://semanticscholar.org/paper/238fa66062114f39e404c40d0b1abc03b86e54bd,,"Artificial Intelligence (AI) is influencing almost all areas of human life. Even though these AI-based systems frequently provide state-of-the-art performance, humans still hesitate to develop, deploy, and use AI systems. The main reason for this is the lack of trust in AI systems caused by the deficiency of transparency of existing AI systems. As a solution, “Trustworthy AI” research area merged with the goal of defining guidelines and frameworks for improving user trust in AI systems, allowing humans to use them without fear. While trust in AI is an active area of research, very little work exists where the focus is to build human trust to improve the interactions between human and AI systems. In this paper, we provide a concise survey on concepts of trustworthy AI. Further, we present trustworthy AI development guidelines for improving the user trust to enhance the interactions between AI systems and humans, that happen during the AI system life cycle.",,
Trustworthy AI Services in the Public Sector: What Are Citizens Saying About It?,All the participants in the study wanted public AI services to be transparent.,Search,2021,,"Karolina  Drobotowicz, Marjo  Kauppinen, Sari  Kujala",REFSQ,,10.1007/978-3-030-73128-1_7,https://doi.org/10.1007/978-3-030-73128-1_7,https://semanticscholar.org/paper/10c7382f4a3db039089ae54b56229a96f7f0a38a,https://research.aalto.fi/files/65489479/Trustworthy_AI_Services_in_the_Public_Sector.preprint_Trustworthy_AI_Reqs_1_.pdf,"[Motivation] Artificial intelligence (AI) creates many opportunities for public institutions, but the unethical use of AI in public services can reduce citizens’ trust. [Question] The aim of this study was to identify what kind of requirements citizens have for trustworthy AI services in the public sector. The study included 21 interviews and a design workshop of four public AI services. [Results] The main finding was that all the participants wanted public AI services to be transparent. This transparency requirement covers a number of questions that trustworthy AI services must answer, such as about their purposes. The participants also asked about the data used in AI services and from what sources the data were collected. They pointed out that AI must provide easy-to-understand explanations. We also distinguished two other important requirements: controlling personal data usage and involving humans in AI services. [Contribution] For practitioners, the paper provides a list of questions that trustworthy public AI services should answer. For the research community, it illuminates the transparency requirement of AI systems from the perspective of citizens.",,
An agile framework for trustworthy AI,The AI High Level Expert Group (AI-HLEG) ethics guidelines present a list of requirements that trustworthy AI systems should meet.,Search,2020,2,"Stefan  Leijnen, Huib  Aldewereld, Rudy van Belkom, Roland  Bijvank, Roelant  Ossewaarde",NeHuAI@ECAI,,,,https://semanticscholar.org/paper/880049a16c8fea47dcfe07450668f5507db5e96d,,"From the article: The ethics guidelines put forward by the AI High Level Expert Group (AI-HLEG) present a list of seven key requirements that Human-centered, trustworthy AI systems should meet. These guidelines are useful for the evaluation of AI systems, but can be complemented by applied methods and tools for the development of trustworthy AI systems in practice. In this position paper we propose a framework for translating the AI-HLEG ethics guidelines into the specific context within which an AI system operates. This approach aligns well with a set of Agile principles commonly employed in software engineering. http://ceur-ws.org/Vol-2659/",,
Applied artificial intelligence and trust—The case of autonomous vehicles and medical assistance devices,Firms must foster trust in applied AI in order to increase trust in the technology and the firm that developed it.,Search,2016,271,"Monika  Hengstler, Ellen  Enkel, Selina  Duelli",,,10.1016/J.TECHFORE.2015.12.014,https://doi.org/10.1016/J.TECHFORE.2015.12.014,https://semanticscholar.org/paper/203b30269d27e158cd26bd1f47c3207f52e6aec8,,"Automation with inherent artificial intelligence (AI) is increasingly emerging in diverse applications, for instance, autonomous vehicles and medical assistance devices. However, despite their growing use, there is still noticeable skepticism in society regarding these applications. Drawing an analogy from human social interaction, the concept of trust provides a valid foundation for describing the relationship between humans and automation. Accordingly, this paper explores how firms systematically foster trust regarding applied AI. Based on empirical analysis using nine case studies in the transportation and medical technology industries, our study illustrates the dichotomous constitution of trust in applied AI. Concretely, we emphasize the symbiosis of trust in the technology as well as in the innovating firm and its communication about the technology. In doing so, we provide tangible approaches to increase trust in the technology and illustrate the necessity of a democratic development process for applied AI.",,