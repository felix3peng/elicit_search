Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Human-Centered AI,"AI systems require the primary users to gain appropriate levels of trust, transparency regarding limitations, and reflective oversight.",Search,2021,4,"Hollen  Barmer, Rachel  Dzombak, Matthew  Gaston, Vijaykumar  Palat, Frank  Redner, Carol  Smith, Tanisha  Smith",,,10.1184/R1/16560183.V1,https://doi.org/10.1184/R1/16560183.V1,https://semanticscholar.org/paper/264b9b136889da3b4d7e50ef58c77678b35dc3e0,,"We identify three specific areas of focus to advance human-centered AI:• Designers and systems must understand the context of use and sense changes over time: Successful AI Engineering depends on the team’s ability to identify and articulate the desired system outcome and understand human and contextual factors affecting the outcome. The system itself must be able to learn when shifts in context have occurred. What are the best ways to maintain clarity around operational intent and mechanisms for adapting and evolving systems based on dynamic contexts and user needs? • Development of tools, processes, and practices to scope and facilitate human-machine teaming: Implementation of AI systems entails high levels of interdependence between human and machine. Adoption of AI systems requires the primary users to interact with and understand systems, gaining appropriate levels of trust. Every AI system needs to be designed to recognize boundaries and unfamiliar scenarios, and to provide transparency regarding its limitations. • Methods, mechanisms, and mindsets to engage in critical oversight: AI systems learn through data and observations, rather than being explicitly programmed for a deterministic outcome. Critical and reflective oversight by organizations, teams, and individuals that create and use AI systems is needed to uphold ethical principles and proactively consider the risks of bias, misuse, abuse, and unintended consequences through design, development, and ongoing deployment.For each area, we identify ongoing work as well and challenges and opportunities in developing and deploying AI systems with confidence.",,
Human-Centered Artificial Intelligence: Three Fresh Ideas,"A two-dimensional HCAI framework, a shift from emulating humans to empowering people, and a three-level governance structure can promote trustworthy HCAI systems.",Search,2020,32,Ben  Shneiderman,,,10.17705/1thci.00131,https://doi.org/10.17705/1thci.00131,https://semanticscholar.org/paper/454af1728ba52b16965f7d18fc9301d0ffb6d708,https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1136&context=thci,"Human-Centered AI (HCAI) is a promising direction for designing AI systems that support human self-efficacy, promote creativity, clarify responsibility, and facilitate social participation. These human aspirations also encourage consideration of privacy, security, environmental protection, social justice, and human rights. This commentary reverses the current emphasis on algorithms and AI methods, by putting humans at the center of systems design thinking, in effect, a second Copernican Revolution. It offers three ideas: (1) a two-dimensional HCAI framework, which shows how it is possible to have both high levels of human control AND high levels of automation, (2) a shift from emulating humans to empowering people with a plea to shift language, imagery, and metaphors away from portrayals of intelligent autonomous teammates towards descriptions of powerful tool-like appliances and tele-operated devices, and (3) a three-level governance structure that describes how software engineering teams can develop more reliable systems, how managers can emphasize a safety culture across an organization, and how industry-wide certification can promote trustworthy HCAI systems. These ideas will be challenged by some, refined by others, extended to accommodate new technologies, and validated with quantitative and qualitative research. They offer a reframe -a chance to restart design discussions for products and services -which could bring greater benefits to individuals, families, communities, businesses, and society.",,
"Human-Centered Artificial Intelligence: Trusted, Reliable & Safe.","The new goal of Human-Centered Artificial Intelligence is more likely to produce designs that are Trusted, Reliable & Safe.",Search,2020,2,Ben  Shneiderman,,,,,https://semanticscholar.org/paper/e0b2bfdfcc251747538004be479f3914d0932316,,"Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The new goal of HCAI is more likely to produce designs that are Trusted, Reliable & Safe (TRS). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.",,
Human-Centered Artificial Intelligence and Machine Learning,AI systems must be designed with awareness that they are part of a larger system consisting of humans.,Search,2019,67,Mark O. Riedl,Human Behavior and Emerging Technologies,,10.1002/HBE2.117,https://doi.org/10.1002/HBE2.117,https://semanticscholar.org/paper/1fccba11583dc9e1030713d61bd65e9e9990e39f,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/hbe2.117,"Humans are increasingly coming into contact with artificial intelligence and machine learning systems. Human-centered artificial intelligence is a perspective on AI and ML that algorithms must be designed with awareness that they are part of a larger system consisting of humans. We lay forth an argument that human-centered artificial intelligence can be broken down into two aspects: (1) AI systems that understand humans from a sociocultural perspective, and (2) AI systems that help humans understand them. We further argue that issues of social responsibility such as fairness, accountability, interpretability, and transparency.",,
"Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy","The methods of Human-Centered Artificial Intelligence are more likely to produce designs that are Reliable, Safe & Trustworthy.",Search,2020,105,Ben  Shneiderman,Int. J. Hum. Comput. Interact.,,10.1080/10447318.2020.1741118,https://doi.org/10.1080/10447318.2020.1741118,https://semanticscholar.org/paper/e49f67fa5c946ad24afcf59699a9cacf1ca53924,http://arxiv.org/pdf/2002.04087,"ABSTRACT Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The methods of HCAI are more likely to produce designs that are Reliable, Safe & Trustworthy (RST). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.",,
Human-centered AI: The role of Human-centered Design Research in the development of AI,A humanistic design research should play a vital role in the pan-disciplinary collaboration with technologists and policymakers to mitigate the impact of AI.,Search,2020,12,Jan  Auernhammer,,,10.21606/drs.2020.282,https://doi.org/10.21606/drs.2020.282,https://semanticscholar.org/paper/647e53dbfa26c84eb4908ed67855b167da79398f,https://dl.designresearchsociety.org/cgi/viewcontent.cgi?article=1178&context=drs-conference-papers,"Artificial Intelligence has the tremendous potential to produce progress and innovation in society. Designing AI for people has been expressed as essential for societal well-being and the common good. However, human-centered is often used generically without any commitment to a philosophy or overarching approach. This paper outlines different philosophical perspectives and several Human-centered Design approaches and discusses their contribution to the development of Artificial Intelligence. The paper argues that humanistic design research should play a vital role in the pan-disciplinary collaboration with technologists and policymakers to mitigate the impact of AI. Ultimately, Human-centered Artificial Intelligence incorporates involving people and designing Artificial Intelligence systems for people through a genuine human-centered philosophy and approach.",,
Towards the Development of Artificial Intelligence-based Systems: Human-Centered Functional Requirements and Open Problems,"AI-powered systems, including self-aware and unmanned systems, are becoming an inseparable part of human lives.",Search,2019,,"Temitayo M. Fagbola, Surendra C. Thakur",2019 International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS),,10.1109/ICIIBMS46890.2019.8991505,https://doi.org/10.1109/ICIIBMS46890.2019.8991505,https://semanticscholar.org/paper/2241ddea2e4ca13c039fbc155b46abe80a4178e1,,"The increasing capability of AI-powered systems, including self-aware and unmanned systems, at automating simple to sophisticated tasks and their wide areas of real-world interventions in boosting productivity and enhancing competitiveness has offered transformative potentials leading to better quality of life. These systems have lately become an inseparable part of human lives. However, incorrect use leading to unintended consequences, safety, fairness, trustworthiness are major concerns of these emerging ubiquitous systems. In this paper, an attempt was made to concisely present and discuss key human-centered functional requirement specifications of emerging Artificial intelligence-based systems especially interpretability, explainability, fairness, transparency and security. Some emerging toolkits and open libraries for developing and evaluating AI-based systems are also discussed. A number of open problems with respect to managing the tradeoff among these requirements and systems’ performance are presented to guide future researches in this direction.",,
"Tutorial: Human-Centered AI: Reliable, Safe and Trustworthy",Artificial Intelligence (AI) algorithms are combined with human-centered thinking to make Human-Centered AI (HCAI).,Search,2021,,Ben  Shneiderman,IUI Companion,,10.1145/3397482.3453994,https://doi.org/10.1145/3397482.3453994,https://semanticscholar.org/paper/77891ecacb567308c7ee8f117b8ffd5634d61e0f,,"This 3-hour tutorial proposes a new synthesis, in which Artificial Intelligence (AI) algorithms are combined with human-centered thinking to make Human-Centered AI (HCAI). This approach combines research on AI algorithms with user experience design methods to shape technologies that amplify, augment, empower, and enhance human performance. Researchers and developers for HCAI systems value meaningful human control, putting people first by serving human needs, values, and goals.",,
Personal dynamic memories are necessary to deal with meaning and understanding in human-centric AI,AI that has meaning and understanding at its core is necessary to achieve human-centric AI.,Search,2020,2,Luc  Steels,NeHuAI@ECAI,,,,https://semanticscholar.org/paper/6748fa68d4cf6e8edfd2e4e95c4cce76263a6672,,"Human-centric AI requires not only a fundamental shift in the way AI systems are conceived and designed but also a reorientation in basic research in order to figure out how AI can come to grips with meaning and understanding. Meanings are made up of distinctions to categorize and conceptualize an experience at different levels, from directly observable factual meanings to expressional, social, conventional and intrinsic meanings. Meanings get organised into larger-scale narratives that conceptualize experiences from a particular perspective. Understanding is the process of constructing and then integrating these narratives into a Personal Dynamic Memory that stores narratives from past experiences. This memory plays a crucial role to construct more narratives and thus works intimately together with inferences, mental simulations, and the analysis of experiences in terms of syntactic and semantic structures. This paper outlines this approach to meaning and understanding by clarifying what it entails, outlining technical challenges that must be overcome, and providing links to earlier relevant AI work as well as new technical advances that could make Personal Dynamic Memories a reality in the near future. 2 1 What is human-centric AI? “Human-centric AI focuses on collaborating with humans, enhancing human capabilities, and empowering humans to better achieve their goals.” [17]. Human-centric AI has become a focal point of current research, particularly in Europe, where it is now the stated objective of the EU strategy recently (February 2020) issued by the European Commission. This strategy calls for AI that shows human agency and oversight, technical robustness and safety, privacy and data governance, transparency, care for diversity, non-discrimination and fairness, focus on societal and environmental well-being, and accountability [36]. Achieving human-centric AI requires a number of changes in focus compared to current AI: (i) Human-centric AI systems should be made aware of the goals and intentions of their users and base their own goals and dialog on meanings rather than on statistical patterns of past behavior only, even if statistical patterns can play a very important role, for example for drastically reducing search or carrying out approximate inference. Human goals and values should always take precedence. Respect for human autonomy should be built into the system by design, leading 1 Catalan Institute for Advanced Studies ICREA Institute for Evolutionary Biology (UPF-CSIC) Barcelona Spain, email: steels@arti.vub.ac.be 2 Copyright 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0) to qualities such as fairness and respect. (ii) Human-centric AI requires that a system is able to explain its reasoning and learning strategies so that the decisions are understandable by humans. Only by emphasizing human understandability will human-centric AI achieve proper explainability and transparency. (iii) Human-centric AI should not only learn by observation or theorizing about reality but also by taking advice from humans, as suggested in John McCarthy’s original 1958 proposal of the Advice Taker [13]. (iv) Human-centric AI should be able to use natural communication, i.e. communication primarily based on human language, not only by mimicking language syntax but, more importantly, using the rich semantics of natural languages, augmented with multi-modal communication channels. This is needed to support explainability, and accountability. (v) Human-centric AI should have the capacity of self-reflection which can be achieved by a meta-level architecture that is able to track decision-making and intervene by catching failures and repairing them. By extension, the architecture should support the construction of a theory of mind of other agents, i.e. how they see the world, what their motivations and intentions are, and what knowledge they are using or lacking. Only through this capacity can AI achieve intelligent cooperation and adequate explicability, and learn efficiently through cultural transmission. (vi) Finally, human-centric AI should reflect the ethical and moral standards that are also expected from humans or organisations in our society, particularly for supporting tasks that are close to human activity and interest. Today the dominating perspective on AI is not human-centric. It focuses primarily on achieving high predictive performance on predefined benchmarks, trying to exceed human performance so that humans can be replaced in the task being considered. This approach is machine-centric rather than human-centric. It emphasizes numerical (subsymbolic) techniques (from neural network research, pattern recognition, information retrieval, and data science), often ignoring valuable contributions from symbolic AI that are needed to achieve explicability and robustness. Admittedly the machine-oriented focus has recently lead to a jump in performance on chosen benchmarks, particularly in the domain of pattern recognition and computer vision, but unfortunately also to a kind of AI that is opaque, cannot explain or defend its decisions, is unable to take human advice, is not robust against adversarial attacks, has no understanding of the motivations of its users, and requires vast amounts of data and computing power. Although for a large, growing class of applications these shortcomings are not an issue, for AI applications that touch on human lives and are socially consequential, these disadvantages are highly problematic. Different approaches to human-centric AI have been proposed recently. They are all valuable. Some researchers have advocated guidelines and design methodologies to make AI more trust-worthy and responsible by emphasizing safety, privacy, data governance, transparency, diversity, fairness, and accountability [30], [7]. Others have emphasized that we need more human-centric interfaces for AI systems, including better explanation facilities and ways for humans to provide guidance during machine learning or decisionmaking[38]. Here I focus on the idea that human-centric AI requires above all another kind of AI, namely AI which has meaning and understanding at its core. The present paper is a position paper, trying to clarifying this point of view and reflecting on the key issues and possible technical solutions. But first, what do we mean by meaning and understanding? 2 Meaning and understanding The notion of meaning is related to how we try to understand how humans make sense of an experience. An experience can be a behavior or the observation of a behavior, an image or a sequence of images, sounds, soundscapes, smells and tastes, spoken or written text, and more generally cultural artefacts like scenes in a theatre play. In the real world, there is a flow of experiences that we need to interpret and cope with quickly. For example, if we are driving a car there is a quick succession of situations that we have to gauge correctly in order to act appropriately, even in unusual situations: Why is the car behind mine honking its horn? Is the woman with a baby stroller going to cross the street or has she seen me coming? Why is everybody slowing down? What does this red light on the dashboard mean? Meanings are built from categorisations of reality, for example, colors, actions types, temporal and spatial relations, etc. Categorisations are distinctions that are relevant for the interaction between humans (or agents more generally) and their environment, including other agents [25]. For example, the distinction between red and green is relevant in traffic lights because it tells you whether it is safe to start driving or cross the road. The distinction between angry and sad is relevant for knowing how to behave with respect to another person. The distinction between left and right is relevant for giving or following instructions how to reach a location or how to find an object in a scene. Categories are the building blocks for constructing different levels of meaning for an experience, The following levels are often discussed in the appreciation of art works [18] but are actually useful for interpreting any kind of experience [27]: • The base level of an experience details the external formal properties directly derivable from the perceived appearance of the experience, for example, the lines, shapes, color differences in hue, value (brightness) and saturation, textures, shading, spatial positions of elements, etc. in the case of images. • The first level of meaning is that of factual meaning. It identifies and categorises events, actors, entities and roles they play in events, as well as the temporal, spatial and causal relations between them. In the case of images they require a suite of sophisticated processing steps, starting from object segmentation, object location, object recognition, 3D reconstruction, tracking over time, etc. • When there are actors involved, a second level, that of expressional meaning becomes relevant. It identifies the intentions, goals, interests, and motivations of the actors and their psychological states or the manner in which they carry out actions. • The next level is that of social meaning. It is about the social relations between the actors and how the activities are integrated into the local community or the society as a whole. • The fourth level is that of conventional meaning, based on figuring out what is depicted or spoken about and the historical or cultural context, which has to be learned from conversations or cultural artefacts, like books or films. • The fifth level is known as the intrinsic meaning or content of an experience. It is about the ultimate motive of certain images or texts, or why somebody is carrying out a certain behavior. It explains why this particular experience may have occurred. We define a narrative as a coherent reconstruction of the different levels of meaning of",,
Explainable Artificial Intelligence: Human-centered Perspective,AI can be explained to users because they have different goals and levels of expertise.,Search,2021,,Hana  Kopecká,,,,,https://semanticscholar.org/paper/21d01ada95b6fdafe31f8ad340e934e77a323b35,,"Users prefer different explanations because they have different goals and levels of expertise. Users prefer different explanations because they have different goals and levels of expertise and because they are embedded in different socio-cultural structures that affect their cognitive style. AI Explainable Artificial Intelligence: Human-centered Perspective Hana Kopecká hana.kopecka@kcl.ac.uk King’s College London, United Kingdom",,
Human-centered artificial intelligence in education: Seeing the invisible through the visible,The rise of artificial intelligence requires understanding of HAI from various perspectives.,Search,2021,14,"Stephen J.H. Yang, Hiroaki  Ogata, Tatsunori  Matsui, Nian-Shing  Chen",Comput. Educ. Artif. Intell.,,10.1016/J.CAEAI.2021.100008,https://doi.org/10.1016/J.CAEAI.2021.100008,https://semanticscholar.org/paper/8a90ab1c8336d99048e16d5ce3e0148da7cf1371,https://repository.kulib.kyoto-u.ac.jp/dspace/bitstream/2433/261148/1/j.caeai.2021.100008.pdf,"Abstract The inevitable rise and development of artificial intelligence (AI) was not a sudden occurrence. The greater the effect that AI has on humans, the more pressing the need is for us to understand it. This paper addresses research on the use of AI to evaluate new design methods and tools that can be leveraged to advance AI research, education, policy, and practice to improve the human condition. AI has the potential to educate, train, and improve the performance of humans, making them better at their tasks and activities. The use of AI can enhance human welfare in numerous respects, such as through improving the productivity of food, health, water, education, and energy services. However, the misuse of AI due to algorithm bias and a lack of governance could inhibit human rights and result in employment, gender, and racial inequality. We envision that AI can evolve into human-centered AI (HAI), which refers to approaching AI from a human perspective by considering human conditions and contexts. Most current discussions on AI technology focus on how AI can enable human performance. However, we explore AI can also inhibit the human condition and advocate for an in-depth dialog between technology- and humanity-based researchers to improve understanding of HAI from various perspectives.",,
Human-centric Requirements Engineering for Artificial Intelligence Software Systems,"Building AI systems with a human-centric approach produces more ethical, transparent, inclusive, and non-bias outcomes.",Search,2021,,Khlood  Ahmad,2021 IEEE 29th International Requirements Engineering Conference (RE),,10.1109/RE51729.2021.00070,https://doi.org/10.1109/RE51729.2021.00070,https://semanticscholar.org/paper/60727256f6d41a2d5b5e20a45c3eb53a04fe2565,,"The surge in data availability and processing power has made it possible for Artificial Intelligence (AI) to advance at a faster rate. However, the different nature of AI systems has posed significant new challenges to Requirements Engineering (RE). Literature has shown that AI systems do not use current RE methods. It was also found that data scientists are taking the role of the requirements engineers resulting in software that does not focus on users needs. Building AI software with a human-centric approach has proven to produce more ethical, transparent, inclusive and non-bias outcomes. This research will look into adjusting current RE methodologies to fit into AI systems from a human-centric perspective. The project will aim to establish requirements specifications for human-centric AI and map them into a modeling language. A platform will be used to visually model and present requirements. Finally, I plan to conduct a case study to evaluate the modeling language. To date, I have conducted a Systematic Literature Review (SLR) to find current RE methodologies and challenges in AI and currently in the planning phase of a survey to find adopted practices in the industry.",,
Towards Human Centered Ambient Intelligence,Integrating humans into AmI environments requires a dynamic and active user model.,Search,2008,4,"Thomas  Plötz, Christian  Kleine-Cosack, Gernot A. Fink",AmI,,10.1007/978-3-540-89617-3_3,https://doi.org/10.1007/978-3-540-89617-3_3,https://semanticscholar.org/paper/9fca45ef14d33b4c4736740f07cdfce1904e5133,,"In this paper we present a novel approach to the integration of humans into AmI environments. The key aspect of the concept which we call human centered Ami is a dynamic and active user model which creates a virtual doppelganger of the user on software level. This agent not only complies to the specific characteristics of humans but directly affects and triggers environmental activities. In fact the user's persona and behavior is mapped to system level. Utilizing this doppelganger we introduce the integration of the users' capabilities and skills into the functionality of the environment. Human services enrich intelligent environments and allow to overcome the ""all-or-nothing"" dilemma which we identified in conventional approaches. The concept of human centered AmI is put into effect within the perception-oriented intelligent environment FINCA. Results of a Wizard-of-Oz experiment with real users show the benefits of the presented approach.",,
Human-centered Artificial Intelligence: A Multidimensional Approach towards Real World Evidence,,Search,2019,3,"Bettina  Schneider, Petra Maria Asprion, Frank  Grimberg",ICEIS,,10.5220/0007715503810390,https://doi.org/10.5220/0007715503810390,https://semanticscholar.org/paper/f831bf2857fe27c3211f602f2839dec59222f251,http://pdfs.semanticscholar.org/603b/6573fa4f30d51652c687e3a6ace0bf6d3c01.pdf,"This study indicates the significance of a human-centered perspective in the analysis and interpretation of Real World Data. As an exemplary use-case, the construct of perceived ‘Health-related Quality of Life’ is chosen to show, firstly, the significance of Real World Data and, secondly, the associated ‘Real World Evidence’. We settled on an iterative methodology and used hermeneutics for a detailed literature analysis to outline the relevance and the need for a forward-thinking approach to deal with Real World Evidence in the life science and health care industry. The novelty of the study is its focus on a human-centered artificial intelligence, which can be achieved by using ‘System Dynamics’ modelling techniques. The outcome – a human-centered ‘Indicator Set’ can be combined with results from data-driven, AI-based analytics. With this multidimensional approach, human intelligence and artificial intelligence can be intertwined towards an enriched Real World Evidence. The developed approach considers three perspectives – the elementary, the algorithmic and – as novelty – the human-centered evidence. As conclusion, we claim that Real World Data are more valuable and applicable to achieve patient-centricity and personalization if the human-centered perspective is considered ‘by design’.",,
Interactive Human Centered Artificial Intelligence: A Definition and Research Challenges,AI will allow the automation of mental routine tasks and that it will extend our ability to perceive the world and foresee events.,Search,2020,7,Albrecht  Schmidt,AVI,,10.1145/3399715.3400873,https://doi.org/10.1145/3399715.3400873,https://semanticscholar.org/paper/5267f3927eeaf45ed6c8340f07c34ff986474c84,,"Artificial Intelligence (AI) has become the buzzword of the last decade. Advances so far have been largely technical with a focus on machine learning (ML). Only recently have we begun seeing a shift towards focusing on the human aspects of artificial intelligence, centered on the narrow view of making AI interactive and explainable. In this paper I suggest a definition for ""Interactive Human Centered Artificial Intelligence and outline the required properties. Staying in control is essential for humans to feel safe and have self-determination. Hence, we need to find ways for humans to understand AI based systems and means to allow human control and oversight. In our work, we argue that levels of abstractions and granularity of control are a general solution to this. Furthermore, it is essential that we make explicit why we want AI and what are the goals of AI research and development. We need to state the properties that we expect of future intelligent systems and who will benefit from a system or service. For me, AI and ML are very much comparable to raw materials (like stone, iron, or bronze). Historical periods are named after these materials as they fundamentally changed what humans can build and what tools humans can engineer. Hence, I argue that in the AI age we need to shift the focus from the material (e.g. the AI algorithms, as there will be plenty of material) towards the tools and infrastructures that are enabled which are beneficial to humans. It is apparent that AI will allow the automation of mental routine tasks and that it will extend our ability to perceive the world and foresee events. For me, the central question is how to create these tools for amplifying the human mind without compromising human values.",,
Human-centered AI and robotics,Robotics has a special place in AI as robots are connected to the real world and increasingly appear in humans' everyday environment.,Search,2022,,"Stephane  Doncieux, Raja  Chatila, Sirko  Straube, Frank  Kirchner",AI Perspectives,,10.1186/s42467-021-00014-x,https://doi.org/10.1186/s42467-021-00014-x,https://semanticscholar.org/paper/bdf33e61681273d821ee4622104badc058cbe5ce,https://aiperspectives.springeropen.com/track/pdf/10.1186/s42467-021-00014-x,"Robotics has a special place in AI as robots are connected to the real world and robots increasingly appear in humans everyday environment, from home to industry. Apart from cases were robots are expected to completely replace them, humans will largely benefit from real interactions with such robots. This is not only true for complex interaction scenarios like robots serving as guides, companions or members in a team, but also for more predefined functions like autonomous transport of people or goods. More and more, robots need suitable interfaces to interact with humans in a way that humans feel comfortable and that takes into account the need for a certain transparency about actions taken. The paper describes the requirements and state-of-the-art for a human-centered robotics research and development, including verbal and non-verbal interaction, understanding and learning from each other, as well as ethical questions that have to be dealt with if robots will be included in our everyday environment, influencing human life and societies.",,