Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
AI assisted ethics,"A new kind of AI program—oversight programs—is required to monitor, audit, and hold operational AI programs accountable.",Search,2016,52,"Amitai  Etzioni, Oren  Etzioni",Ethics and Information Technology,,10.1007/s10676-016-9400-6,https://doi.org/10.1007/s10676-016-9400-6,https://semanticscholar.org/paper/cb90d3732a50bce46165e75b2260e0c71a70ba33,,"The growing number of ‘smart’ instruments, those equipped with AI, has raised concerns because these instruments make autonomous decisions; that is, they act beyond the guidelines provided them by programmers. Hence, the question the makers and users of smart instrument (e.g., driver-less cars) face is how to ensure that these instruments will not engage in unethical conduct (not to be conflated with illegal conduct). The article suggests that to proceed we need a new kind of AI program—oversight programs—that will monitor, audit, and hold operational AI programs accountable.",,
Beyond the promise: implementing ethical AI,"Businesses require strong, mandated governance controls to ensure responsible AI use in enterprises.",Search,2021,19,Ray  Eitel-Porter,AI Ethics,,10.1007/s43681-020-00011-6,https://doi.org/10.1007/s43681-020-00011-6,https://semanticscholar.org/paper/0a7109502e7fe91f4decc3dd3515e1fecbc02da7,https://link.springer.com/content/pdf/10.1007/s43681-020-00011-6.pdf,"Artificial Intelligence (AI) applications can and do have unintended negative consequences for businesses if not implemented with care. Specifically, faulty or biased AI applications risk compliance and governance breaches and damage to the corporate brand. These issues commonly arise from a number of pitfalls associated with AI development, which include rushed development, a lack of technical understanding, and improper quality assurance, among other factors. To mitigate these risks, a growing number of organisations are working on ethical AI principles and frameworks. However, ethical AI principles alone are not sufficient for ensuring responsible AI use in enterprises. Businesses also require strong, mandated governance controls including tools for managing processes and creating associated audit trails to enforce their principles. Businesses that implement strong governance frameworks, overseen by an ethics board and strengthened with appropriate training, will reduce the risks associated with AI. When applied to AI modelling, the governance will also make it easier for businesses to bring their AI deployments to scale.",,
"From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices",The AI community’s ability to take action to mitigate the associated risks of Artificial Intelligence is still at its infancy.,Search,2020,137,"Jessica  Morley, Luciano  Floridi, Libby  Kinsey, Anat  Elhalal",Sci. Eng. Ethics,,10.1007/s11948-019-00165-5,https://doi.org/10.1007/s11948-019-00165-5,https://semanticscholar.org/paper/7700d89c3a2c898daadd111372566f7146310f5a,https://link.springer.com/content/pdf/10.1007/s11948-019-00165-5.pdf,"The debate about the ethical implications of Artificial Intelligence dates from the 1960s (Samuel in Science, 132(3429):741–742, 1960. 10.1126/science.132.3429.741; Wiener in Cybernetics: or control and communication in the animal and the machine, MIT Press, New York, 1961). However, in recent years symbolic AI has been complemented and sometimes replaced by (Deep) Neural Networks and Machine Learning (ML) techniques. This has vastly increased its potential utility and impact on society, with the consequence that the ethical debate has gone mainstream. Such a debate has primarily focused on principles—the ‘what’ of AI ethics (beneficence, non-maleficence, autonomy, justice and explicability)—rather than on practices, the ‘how.’ Awareness of the potential issues is increasing at a fast rate, but the AI community’s ability to take action to mitigate the associated risks is still at its infancy. Our intention in presenting this research is to contribute to closing the gap between principles and practices by constructing a typology that may help practically-minded developers apply ethics at each stage of the Machine Learning development pipeline, and to signal to researchers where further work is needed. The focus is exclusively on Machine Learning, but it is hoped that the results of this research may be easily applicable to other branches of AI. The article outlines the research method for creating this typology, the initial findings, and provides a summary of future research needs. Electronic supplementary material The online version of this article (10.1007/s11948-019-00165-5) contains supplementary material, which is available to authorized users.",,Review
Lessons learned from AI ethics principles for future actions,AI ethics is urgently calling for tangible action to move from high-level abstractions and conceptual arguments towards applying ethics in practice and creating accountability mechanisms.,Search,2021,17,Merve  Hickok,AI Ethics,,10.1007/s43681-020-00008-1,https://doi.org/10.1007/s43681-020-00008-1,https://semanticscholar.org/paper/eb22e505d84b31f52a5bd8bd973f89711891e836,https://link.springer.com/content/pdf/10.1007/s43681-020-00008-1.pdf,"As the use of artificial intelligence (AI) systems became significantly more prevalent in recent years, the concerns on how these systems collect, use and process big data also increased. To address these concerns and advocate for ethical and responsible development and implementation of AI, non-governmental organizations (NGOs), research centers, private companies, and governmental agencies published more than 100 AI ethics principles and guidelines. This first wave was followed by a series of suggested frameworks, tools, and checklists that attempt a technical fix to issues brought up in the high-level principles. Principles are important to create a common understanding for priorities and are the groundwork for future governance and opportunities for innovation. However, a review of these documents based on their country of origin and funding entities shows that private companies from US-West axis dominate the conversation. Several cases surfaced in the meantime which demonstrate biased algorithms and their impact on individuals and society. The field of AI ethics is urgently calling for tangible action to move from high-level abstractions and conceptual arguments towards applying ethics in practice and creating accountability mechanisms. However, lessons must be learned from the shortcomings of AI ethics principles to ensure the future investments, collaborations, standards, codes or legislation reflect the diversity of voices and incorporate the experiences of those who are already impacted by the biased algorithms.",,Review
Ethical Artificial Intelligence - An Open Question,"Artificial Intelligence is an effective science that employs strong enough approaches, methods, and techniques to solve unsolvable real world based problems.",Search,2017,12,"Alice  Pavaloiu, Utku  Kose",ArXiv,,,,https://semanticscholar.org/paper/b952eaffb220ed192728d2ce7436235827132057,,"Artificial Intelligence (AI) is an effective science which employs strong enough approaches, methods, and techniques to solve unsolvable real world based problems. Because of its unstoppable rise towards the future, there are also some discussions about its ethics and safety. Shaping an AI friendly environment for people and a people friendly environment for AI can be a possible answer for finding a shared context of values for both humans and robots. In this context, objective of this paper is to address the ethical issues of AI and explore the moral dilemmas that arise from ethical algorithms, from pre set or acquired values. In addition, the paper will also focus on the subject of AI safety. As general, the paper will briefly analyze the concerns and potential solutions to solving the ethical issues presented and increase readers awareness on AI safety as another related research interest.",,
Ethical Artificial Intelligence for Digital Health Organizations,A US-based Digital Health company developed an ethical code for emotional AI services.,Search,2020,9,"Angela  Joerin, Michiel  Rauws, Russell  Fulmer, Valerie  Black",Cureus,,10.7759/cureus.7202,https://doi.org/10.7759/cureus.7202,https://semanticscholar.org/paper/a8f262b28aa4a35196814b447346f99173c4795a,https://www.cureus.com/articles/25462-ethical-artificial-intelligence-for-digital-health-organizations.pdf,"This technical report describes the methods undertaken by a US-based Digital Health company (X2AI or X2 for short) to develop an ethical code for startup environments and other organizations delivering emotional artificial intelligence (AI) services, especially for mental health support. With a growing demand worldwide for scalable, affordable, and accessible health care solutions, the use of AI offers tremendous potential to improve emotional well-being. To realize this potential, it is imperative that AI service providers prioritize clear and consistent ethical guidelines that align with global considerations regarding user safety and privacy. This report offers a template for an ethical code that can be implemented by other emotional AI services and their affiliates. It includes practical guidelines for integrating support from clients, collaborators, and research partners. It also shows how existing ethical systems can inform the development of AI ethics.",,
Ethical AI for the Governance of the Society: Challenges and Opportunities,Artificial Intelligence (AI) technologies are expected to have numerous and diverse social implications that cut deep into our society.,Search,2019,2,"Mika P. Nieminen, Nadezhda  Gotcheva, Jaana  Leikas, Raija  Koivisto",Tethics,,,,https://semanticscholar.org/paper/1e366a346a1464dbd093bcb90b0ee7c91fc8a8ac,,"Artificial Intelligence (AI) technologies are expected to have numerous and diverse social implications that cut deep into our society. Due to AI’s specific nature as emergent and constantly evolving generic technology, we need new approaches, methodologies, and processes to govern and steer the utilization of AI technologies both in the public and private sectors. This is both a multilevel and multi-dimensional governance challenge. First, there has to be a shared and coordinated understanding across various social and administrational sectors on how AI is implemented and regulated. Second, good coordination between different levels of governance is crucial. Third, there is a challenge to find a balance between soft and hard governance mechanisms in varying implementation and organizational contexts. This paper presents an overview of a new Strategic Research Council funded project project entitled “Ethical AI for the Governance of the Society” (ETAIROS). The project focuses on studying and co-developing together with stakeholders practical governance approaches, as well as design and technology solutions that help public, private and civil society actors enhance the ethical sustainability of operations in the use of AI. To achieve its ambitious goals, this interdisciplinary endeavour integrates expertise in foresight, ethics, design, machine learning and governance.",,Review
Artificial Intelligence (AI) Ethics: Ethics of AI and Ethical AI,AI ethics is still in the infancy stage.,Search,2020,26,"Keng  Siau, Weiyu  Wang",J. Database Manag.,,10.4018/jdm.2020040105,https://doi.org/10.4018/jdm.2020040105,https://semanticscholar.org/paper/39d1f020a585d3f28cb4b4c14497649e6a469ef1,,"Artificial intelligence (AI)-based technology has achieved many great things, such as facial recognition, medical diagnosis, and self-driving cars. AI promises enormous benefits for economic growth, social development, as well as human well-being and safety improvement. However, the low-level of explainability, data biases, data security, data privacy, and ethical problems of AI-based technology pose significant risks for users, developers, humanity, and societies. As AI advances, one critical issue is how to address the ethical and moral challenges associated with AI. Even though the concept of “machine ethics” was proposed around 2006, AI ethics is still in the infancy stage. AI ethics is the field related to the study of ethical issues in AI. To address AI ethics, one needs to consider the ethics of AI and how to build ethical AI. Ethics of AI studies the ethical principles, rules, guidelines, policies, and regulations that are related to AI. Ethical AI is an AI that performs and behaves ethically. One must recognize and understand the potential ethical and moral issues that may be caused by AI to formulate the necessary ethical principles, rules, guidelines, policies, and regulations for AI (i.e., Ethics of AI). With the appropriate ethics of AI, one can then build AI that exhibits ethical behavior (i.e., Ethical AI). This paper will discuss AI ethics by looking at the ethics of AI and ethical AI. What are the perceived ethical and moral issues with AI? What are the general and common ethical principles, rules, guidelines, policies, and regulations that can resolve or at least attenuate these ethical and moral issues with AI? What are some of the necessary features and characteristics of an ethical AI? How to adhere to the ethics of AI to build ethical AI?",,
Putting AI ethics to work: are the tools fit for purpose?,Current AI ethics tools in auditing and risk assessment should be considered going forward.,Search,2021,,"Jacqui  Ayling, Adriane  Chapman",AI and Ethics,,10.1007/s43681-021-00084-x,https://doi.org/10.1007/s43681-021-00084-x,https://semanticscholar.org/paper/dd5a6c9ebde898e89e2d3db8153de774dce53c1a,https://link.springer.com/content/pdf/10.1007/s43681-021-00084-x.pdf,"Bias, unfairness and lack of transparency and accountability in Artificial Intelligence (AI) systems, and the potential for the misuse of predictive models for decision-making have raised concerns about the ethical impact and unintended consequences of new technologies for society across every sector where data-driven innovation is taking place. This paper reviews the landscape of suggested ethical frameworks with a focus on those which go beyond high-level statements of principles and offer practical tools for application of these principles in the production and deployment of systems. This work provides an assessment of these practical frameworks with the lens of known best practices for impact assessment and audit of technology. We review other historical uses of risk assessments and audits and create a typology that allows us to compare current AI ethics tools to Best Practices found in previous methodologies from technology, environment, privacy, finance and engineering. We analyse current AI ethics tools and their support for diverse stakeholders and components of the AI development and deployment lifecycle as well as the types of tools used to facilitate use. From this, we identify gaps in current AI ethics tools in auditing and risk assessment that should be considered going forward.",,Review
From Bad Users and Failed Uses to Responsible Technologies: A Call to Expand the AI Ethics Toolkit,AI ethics needs to expand its theoretical and methodological toolkit in order to move away from prioritizing notions of good design.,Search,2020,2,Gina  Neff,AIES,,10.1145/3375627.3377141,https://doi.org/10.1145/3375627.3377141,https://semanticscholar.org/paper/0f87258b6072d1aec058d6415b10fa30aed375d2,,"Recent advances in artificial intelligence applications have sparked scholarly and public attention to the challenges of the ethical design of technologies. These conversations about ethics have been targeted largely at technology designers and concerned with helping to inform building better and fairer AI tools and technologies. This approach, however, addresses only a small part of the problem of responsible use and will not be adequate for describing or redressing the problems that will arise as more types of AI technologies are more widely used. Many of the tools being developed today have potentially enormous and historic impacts on how people work, how society organises, stores and distributes information, where and how people interact with one another, and how people's work is valued and compensated. And yet, our ethical attention has looked at a fairly narrow range of questions about expanding the access to, fairness of, and accountability for existing tools. Instead, I argue that scholars should develop much broader questions of about the reconfiguration of societal power, for which AI technologies form a crucial component. This talk will argue that AI ethics needs to expand its theoretical and methodological toolkit in order to move away from prioritizing notions of good design that privilege the work of good and ethical technology designers. Instead, using approaches from feminist theory, organization studies, and science and technology, I argue for expanding how we evaluate uses of AI. This approach begins with the assumption of socially informed technological affordances, or ""imagined affordances"" [1] shaping how people understand and use technologies in practice. It also gives centrality to the power of social institutions for shaping technologies-in-practice.",,
Applying Ethical AI Frameworks in practice: Evaluating conversational AI chatbot solutions,"Ethical AI researchers should focus on studying specific domains and not AI as a whole, and that ethical AI guidelines should focus more on creating measurable standards and less on stating high level principles.",Search,2021,,"Suzanne  Atkins, Ishwarradj  Badrie, Sieuwert  Otterloo",Computers and Society Research Journal,,10.54822/qxom4114,https://doi.org/10.54822/qxom4114,https://semanticscholar.org/paper/3e1d3287ad2e717133bbb28b8a2e3318a88515d7,,"Ethical AI frameworks are designed to encourage the accountability, responsibility and transparency of AI applications. They provide principles for ethical design. To be truly transparent, it should be clear to the user of the AI application that the designers followed responsible AI principles. In order to test how easy it is for a user to assess the responsibility of an AI system and to understand the differences between ethical AI frameworks, we evaluated four commercial chatbots against four responsible AI frameworks. We found that the ethical frameworks produced quite different assessment scores. Many ethical AI frameworks contain requirements/principles that are difficult to evaluate for anyone except the chatbot developer. Our results also show that domain-specific ethical AI guidelines are easier to use and yield more practical insights than domain-independent frameworks. We conclude that ethical AI researchers should focus on studying specific domains and not AI as a whole, and that ethical AI guidelines should focus more on creating measurable standards and less on stating high level principles.",,
Ethics in artificial intelligence: introduction to the special issue,"The development of intelligent systems must incorporate moral, ethical, and legal considerations.",Search,2018,129,Virginia  Dignum,Ethics and Information Technology,,10.1007/s10676-018-9450-z,https://doi.org/10.1007/s10676-018-9450-z,https://semanticscholar.org/paper/6b77b4235bd455cf6df68cfa4fe4e2aa9401d06c,https://link.springer.com/content/pdf/10.1007%2Fs10676-018-9450-z.pdf,"Recent developments in Artificial Intelligence (AI) have generated a steep interest from media and general public. As AI systems (e.g. robots, chatbots, avatars and other intelligent agents) are moving from being perceived as a tool to being perceived as autonomous agents and team-mates, an important focus of research and development is understanding the ethical impact of these systems. What does it mean for an AI system to make a decision? What are the moral, societal and legal consequences of their actions and decisions? Can an AI system be held accountable for its actions? How can these systems be controlled once their learning capabilities bring them into states that are possibly only remotely linked to their initial, designed, setup? Should such autonomous innovation in commercial systems even be allowed, and how should use and development be regulated? These and many other related questions are currently the focus of much attention. The way society and our systems will be able to deal with these questions will for a large part determine our level of trust, and ultimately, the impact of AI in society, and the existence of AI. Contrary to the frightening images of a dystopic future in media and popular fiction, where AI systems dominate the world and is mostly concerned with warfare, AI is already changing our daily lives mostly in ways that improve human health, safety, and productivity (Stone et al. 2016). This is the case in domain such as transportation; service robots; health-care; education; public safety and security; and entertainment. Nevertheless, and in order to ensure that those dystopic futures do not become reality, these systems must be introduced in ways that build trust and understanding, and respect human and civil rights. The need for ethical considerations in the development of intelligent interactive systems is becoming one of the main influential areas of research in the last few years, and has led to several initiatives both from researchers as from practitioners, including the IEEE initiative on Ethics of Autonomous Systems1, the Foundation for Responsible Robotics2, and the Partnership on AI3 amongst several others. As the capabilities for autonomous decision making grow, perhaps the most important issue to consider is the need to rethink responsibility (Dignum 2017). Whatever their level of autonomy and social awareness and their ability to learn, AI systems are artefacts, constructed by people to fulfil some goals. Theories, methods, algorithms are needed to integrate societal, legal and moral values into technological developments in AI, at all stages of development (analysis, design, construction, deployment and evaluation). These frameworks must deal both with the autonomic reasoning of the machine about such issues that we consider to have ethical impact, but most importantly, we need frameworks to guide design choices, to regulate the reaches of AI systems, to ensure proper data stewardship, and to help individuals determine their own involvement. Values are dependent on the socio-cultural context (Turiel 2002), and are often only implicit in deliberation processes, which means that methodologies are needed to elicit the values held by all the stakeholders, and to make these explicit can lead to better understanding and trust on artificial autonomous systems. That is, AI reasoning should be able to take into account societal values, moral and ethical considerations; weigh the respective priorities of values held by different stakeholders in various multicultural contexts; explain its reasoning; and guarantee transparency. Responsible Artificial Intelligence is about human responsibility for the development of intelligent systems along fundamental human principles and values, to ensure human flourishing and wellbeing in a sustainable world. In fact, Responsible AI is more than the ticking of some ethical ‘boxes’ in a report, or the development of some add-on features, or switch-off buttons in AI systems. Rather, responsibility is fundamental",,
Building Ethics into Artificial Intelligence,AI governance for ethical decision-making by AI is becoming increasingly important.,Search,2018,87,"Han  Yu, Zhiqi  Shen, Chunyan  Miao, Cyril  Leung, Victor R. Lesser, Qiang  Yang",IJCAI,,10.24963/ijcai.2018/779,https://doi.org/10.24963/ijcai.2018/779,https://semanticscholar.org/paper/80179a17eab0f9fb6e21840f3fed96c4d75c3442,https://www.ijcai.org/proceedings/2018/0779.pdf,"As artificial intelligence (AI) systems become increasingly ubiquitous, the topic of AI governance for ethical decision-making by AI has captured public imagination. Within the AI research community, this topic remains less familiar to many researchers. In this paper, we complement existing surveys, which largely focused on the psychological, social and legal discussions of the topic, with an analysis of recent advances in technical solutions for AI governance. By reviewing publications in leading AI conferences including AAAI, AAMAS, ECAI and IJCAI, we propose a taxonomy which divides the field into four areas: 1) exploring ethical dilemmas; 2) individual ethical decision frameworks; 3) collective ethical decision frameworks; and 4) ethics in human-AI interactions. We highlight the intuitions and key techniques used in each approach, and discuss promising future research directions towards successful integration of ethical AI systems into human societies.",,Review
The ethical AI—paradox: why better technology needs more and not less human responsibility,AI in itself has no ethics and that good or bad decisions by algorithms are caused by human choices made at an earlier stage.,Search,2021,3,"David  De Cremer, Garry  Kasparov",AI and Ethics,,10.1007/s43681-021-00075-y,https://doi.org/10.1007/s43681-021-00075-y,https://semanticscholar.org/paper/1a1308f6013fc4403c89a46f818467e925275530,https://link.springer.com/content/pdf/10.1007/s43681-021-00075-y.pdf,"Because AI is gradually moving into the position of decision-maker in business and organizations, its influence is increasingly impacting the outcomes and interests of the human end-user. As a result, scholars and practitioners alike have become worried about the ethical implications of decisions made where AI is involved. In approaching the issue of AI ethics, it is becoming increasingly clear that society and the business world—under the influence of the big technology companies—are accepting the narrative that AI has its own ethical compass, or, in other words, that AI can decide itself to do bad or good. We argue that this is not the case. We discuss and demonstrate that AI in itself has no ethics and that good or bad decisions by algorithms are caused by human choices made at an earlier stage. For this reason, we argue that even though technology is quickly becoming better and more sophisticated a need exists to simultaneously train humans even better in shaping their ethical compass and awareness.",,
Beyond Fairness Metrics: Roadblocks and Challenges for Ethical AI in Practice,"The practical challenges of ethical AI involve inconsistent regulatory pressures, conflicting business goals, data quality issues, development processes, systems integration practices, and the scale of deployment.",Search,2021,1,"Jiahao  Chen, Victor  Storchan, Eren  Kurshan",ArXiv,,,,https://semanticscholar.org/paper/dee1645003c297718e182e9a98a9f68d759c3a7c,,"We review practical challenges in building and deploying ethical AI at the scale of contemporary industrial and societal uses. Apart from the purely technical concerns that are the usual focus of academic research, the operational challenges of inconsistent regulatory pressures, conflicting business goals, data quality issues, development processes, systems integration practices, and the scale of deployment all conspire to create new ethical risks. Such ethical concerns arising from these practical considerations are not adequately addressed by existing research results. We argue that a holistic consideration of ethics in the development and deployment of AI systems is necessary for building ethical AI in practice, and exhort researchers to consider the full operational contexts of AI systems when assessing ethical risks.",,Review
Good Systems: Ethical AI for CSCW,"Artificial intelligence can lead to several potential ethical trade-offs, such as an invasion of privacy.",Search,2019,3,"Kenneth R. Fleischmann, Sherri R. Greenberg, Danna  Gurari, Abigale  Stangl, Nitin  Verma, Jaxsen R. Day, Rachel N. Simons, Tom  Yeh",CSCW Companion,,10.1145/3311957.3359437,https://doi.org/10.1145/3311957.3359437,https://semanticscholar.org/paper/d4f75fafc5d911cefdaf95b92bfaa1d6d2fe82d6,,"Artificial intelligence is revolutionizing work, including what it means for cooperative work to be supported by computers. The increased use of AI in CSCW can lead to many advantages, including increased productivity and efficiency, but it can also include several potential ethical trade-offs, such as invasions of privacy, loss of autonomy, and job displacement. This workshop will explore the ethical dimensions of AI in CSCW, building on Good Systems, a UT Grand Challenge. Specifically, the first half of the workshop will focus on the need to design AI to work for all users and to avoid bias through the use of universal design as well as the need for AI and CSCW researchers to interact with policy and legal experts to work together to ensure that AI will be developed in an ethical manner with sufficient consideration of its societal implications, and also that AI will be regulated and legislated in ways that will maximize its benefits to all people.",,