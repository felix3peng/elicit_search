Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Toward an Ethics of AI Assistants: an Initial Framework,Personal AI assistants are now nearly ubiquitous and pose several ethical concerns.,Search,2018,28,John  Danaher,Philosophy & Technology,,10.1007/S13347-018-0317-3,https://doi.org/10.1007/S13347-018-0317-3,https://semanticscholar.org/paper/0eec7dad1f60c6802b88ba7637ab84c567e97c8d,,"Personal AI assistants are now nearly ubiquitous. Every leading smartphone operating system comes with a personal AI assistant that promises to help you with basic cognitive tasks: searching, planning, messaging, scheduling and so on. Usage of such devices is effectively a form of algorithmic outsourcing: getting a smart algorithm to do something on your behalf. Many have expressed concerns about this algorithmic outsourcing. They claim that it is dehumanising, leads to cognitive degeneration, and robs us of our freedom and autonomy. Some people have a more subtle view, arguing that it is problematic in those cases where its use may degrade important interpersonal virtues. In this article, I assess these objections to the use of AI assistants. I will argue that the ethics of their use is complex. There are no quick fixes or knockdown objections to the practice, but there are some legitimate concerns. By carefully analysing and evaluating the objections that have been lodged to date, we can begin to articulate an ethics of personal AI use that navigates those concerns. In the process, we can locate some paradoxes in our thinking about outsourcing and technological dependence, and we can think more clearly about what it means to live a good life in the age of smart machines.",,
Ethical Artificial Intelligence for Digital Health Organizations,A US-based Digital Health company developed an ethical code for emotional AI services.,Search,2020,9,"Angela  Joerin, Michiel  Rauws, Russell  Fulmer, Valerie  Black",Cureus,,10.7759/cureus.7202,https://doi.org/10.7759/cureus.7202,https://semanticscholar.org/paper/a8f262b28aa4a35196814b447346f99173c4795a,https://www.cureus.com/articles/25462-ethical-artificial-intelligence-for-digital-health-organizations.pdf,"This technical report describes the methods undertaken by a US-based Digital Health company (X2AI or X2 for short) to develop an ethical code for startup environments and other organizations delivering emotional artificial intelligence (AI) services, especially for mental health support. With a growing demand worldwide for scalable, affordable, and accessible health care solutions, the use of AI offers tremendous potential to improve emotional well-being. To realize this potential, it is imperative that AI service providers prioritize clear and consistent ethical guidelines that align with global considerations regarding user safety and privacy. This report offers a template for an ethical code that can be implemented by other emotional AI services and their affiliates. It includes practical guidelines for integrating support from clients, collaborators, and research partners. It also shows how existing ethical systems can inform the development of AI ethics.",,
Recommendations for the ethical use and design of artificial intelligent care providers,Artificial intelligent care providers present new ethical issues that will have significant ramifications for the mental health care and other helping professions.,Search,2014,63,David D. Luxton,Artif. Intell. Medicine,,10.1016/j.artmed.2014.06.004,https://doi.org/10.1016/j.artmed.2014.06.004,https://semanticscholar.org/paper/c3fc33be2a7ed7912b23653576e04f7588e77698,,"OBJECTIVE

This paper identifies and reviews ethical issues associated with artificial intelligent care providers (AICPs) in mental health care and other helping professions. Specific recommendations are made for the development of ethical codes, guidelines, and the design of AICPs.

METHODS

Current developments in the application of AICPs and associated technologies are reviewed and a foundational overview of applicable ethical principles in mental health care is provided. Emerging ethical issues regarding the use of AICPs are then reviewed in detail. Recommendations for ethical codes and guidelines as well as for the development of semi-autonomous and autonomous AICP systems are described. The benefits of AICPs and implications for the helping professions are discussed in order to weigh the pros and cons of their use.

RESULTS

Existing ethics codes and practice guidelines do not presently consider the current or the future use of interactive artificial intelligent agents to assist and to potentially replace mental health care professionals. AICPs present new ethical issues that will have significant ramifications for the mental health care and other helping professions. Primary issues involve the therapeutic relationship, competence, liability, trust, privacy, and patient safety. Many of the same ethical and philosophical considerations are applicable to use and design of AICPs in medicine, nursing, social work, education, and ministry.

CONCLUSION

The ethical and moral aspects regarding the use of AICP systems must be well thought-out today as this will help to guide the use and development of these systems in the future. Topics presented are relevant to end users, AI developers, and researchers, as well as policy makers and regulatory boards.",,Review
The Ethics of Artificial Intelligence,Some ethical issues arise when some future artificial intelligence systems may have moral status.,Search,2014,224,"Nick  Bostrom, Eliezer  Yudkowsky",,,10.1017/CBO9781139046855.020,https://doi.org/10.1017/CBO9781139046855.020,https://semanticscholar.org/paper/787996496a300356188ba921f02f926331f80a63,http://intelligence.org/files/EthicsofAI.pdf,"This chapter surveys some of the ethical challenges that may arise as one can create artificial intelligences (AI) of various kinds and degrees. Some challenges of machine ethics are much like many other challenges involved in designing machines. There is nearly universal agreement among modern AI professionals that artificial intelligence falls short of human capabilities in some critical sense, even though AI algorithms have beaten humans in many specific domains such as chess. In creating a superhuman chess player, the human programmers necessarily sacrificed their ability to predict Deep Blue's local, specific game behavior. A different set of ethical issues arises when one can contemplate the possibility that some future AI systems might be candidates for having moral status. One also has moral reasons to treat them in certain ways, and to refrain from treating them in certain other ways. Superintelligence may be achievable by increasing processing speed.",,
Ethical Artificial Intelligence - An Open Question,"Artificial Intelligence is an effective science that employs strong enough approaches, methods, and techniques to solve unsolvable real world based problems.",Search,2017,12,"Alice  Pavaloiu, Utku  Kose",ArXiv,,,,https://semanticscholar.org/paper/b952eaffb220ed192728d2ce7436235827132057,,"Artificial Intelligence (AI) is an effective science which employs strong enough approaches, methods, and techniques to solve unsolvable real world based problems. Because of its unstoppable rise towards the future, there are also some discussions about its ethics and safety. Shaping an AI friendly environment for people and a people friendly environment for AI can be a possible answer for finding a shared context of values for both humans and robots. In this context, objective of this paper is to address the ethical issues of AI and explore the moral dilemmas that arise from ethical algorithms, from pre set or acquired values. In addition, the paper will also focus on the subject of AI safety. As general, the paper will briefly analyze the concerns and potential solutions to solving the ethical issues presented and increase readers awareness on AI safety as another related research interest.",,
Medical ethics considerations on artificial intelligence,"Artificial intelligence will afford many useful applications in many sectors ranging from banking, agriculture, medical procedures to military operations.",Search,2019,41,Kadircan H. Keskinbora,Journal of Clinical Neuroscience,,10.1016/j.jocn.2019.03.001,https://doi.org/10.1016/j.jocn.2019.03.001,https://semanticscholar.org/paper/bc6519025efcd4db20267691e0b6eabfe44dac95,,"Artificial intelligence (AI) is currently one of the mostly controversial matters of the world. This article discusses AI in terms of the medical ethics issues involved, both existing and potential. Once artificial intelligence is fully developed within electronic systems, it will afford many useful applications in many sectors ranging from banking, agriculture, medical procedures to military operations, especially by decreasing the involvement of humans in critically dangerous activities. Robots as well as computers themselves are embodiments of values inasmuch as they entail actions and choices, but their practical applications are modelled or programmed by the engineers building the systems. AI will need algorithmic procedures to ensure safety in the implementation of such systems. The AI algorithms written could naturally contain errors that may result in unforeseen consequences and unfair outcomes along economic and racial class lines. It is crucial that measures be taken to monitor technological developments ensuring preventative and precautionary safeguards are in place to safeguard the rights of those involved against direct or indirect coercion. While it is the responsibility of AI researchers to ensure that the future impact is more positive than negative, ethicists and philosophers need to be deeply involved in the development of such technologies from the beginning.",,
The ethics of robotic caregivers,"Robot caregivers raise many of the same ethical concerns as human caregivers, but some concerns are avoided when robot caregivers operate as partners.",Search,2017,9,"Amitai  Etzioni, Oren  Etzioni",,,10.1075/IS.18.2.02ETZ,https://doi.org/10.1075/IS.18.2.02ETZ,https://semanticscholar.org/paper/c08d482f5be1ab95a99d9527fdd5f5feb53c79c6,,"As Artificial Intelligence technology seems poised for a major take-off and changing societal dynamics are creating a high demand for caregivers for elders, children, and those infirmed, robotic caregivers may well be used much more often. This article examines the ethical concerns raised by the use of AI caregivers and concludes that many of these concerns are avoided when AI caregivers operate as partners rather than substitutes. Furthermore, most of the remaining concerns are minor and are faced by human caregivers as well. Nonetheless, because AI caregivers’ systems are learning systems, an AI caregiver could stray from its initial guidelines. Therefore, subjecting AI caregivers to an AI-based oversight system is proposed to ensure that their actions remain both legal and ethical.",,
"Better, Nicer, Clearer, Fairer: A Critical Assessment of the Movement for Ethical Artificial Intelligence and Machine Learning",High-profile values statements endorse ethical design for artificial intelligence and machine learning.,Search,2019,111,"Daniel  Greene, Anna Lauren Hoffmann, Luke  Stark",HICSS,,10.24251/HICSS.2019.258,https://doi.org/10.24251/HICSS.2019.258,https://semanticscholar.org/paper/e6bcf7d0e3798aebb7114cdc3d89a55a808b29de,http://scholarspace.manoa.hawaii.edu/bitstream/10125/59651/1/0211.pdf,"This paper uses frame analysis to examine recent high-profile values statements endorsing ethical design for artificial intelligence and machine learning (AI/ML). Guided by insights from values in design and the sociology of business ethics, we uncover the grounding assumptions and terms of debate that make some conversations about ethical design possible while forestalling alternative visions. Vision statements for ethical AI/ML co-opt the language of some critics, folding them into a limited, technologically deterministic, expert-driven view of what ethical AI/ML means and how it might work.",,
Towards ethical aspects on artificial intelligence,The progress of artificial intelligence brings ethical problems to society.,Search,2009,10,Liliana  Rogozea,,,,,https://semanticscholar.org/paper/a77957c323a8da93596a9cf4c086debfca4f7a31,,"This paper presents the role of ethics in developing artificial intelligence, and how the artificial intelligence could change our perspective, because artificial intelligence in fact is all around us. Artificial intelligence is an important part of our life, but we are sure that the possibility of acquiring the domination of AI over the humanity is only a myth. During the time, the progress helps society but also brings a number of ethical problems. In the academic society, like in real life, the process of using different kind of power are complex, and even if it is about the robots, the computer or other artificial intelligence tools, the ethical problems are not only theoretical but also practical, it is not only a concept, but it is also a practical support for our life.",,
Ethical Management of Artificial Intelligence,"The ethical management of AI involves managerial decision making, ethical considerations, and macro- and micro-environmental dimensions.",Search,2021,8,"Alfred Benedikt Brendel, Milad  Mirbabaie, Tim-Benjamin  Lembcke, Lennart  Hofeditz",,,10.3390/SU13041974,https://doi.org/10.3390/SU13041974,https://semanticscholar.org/paper/3dfd53d9fe69f0e7ea66ee4357bb84a3951f6e32,https://www.mdpi.com/2071-1050/13/4/1974/pdf?version=1613092527,"With artificial intelligence (AI) becoming increasingly capable of handling highly complex tasks, many AI-enabled products and services are granted a higher autonomy of decision-making, potentially exercising diverse influences on individuals and societies. While organizations and researchers have repeatedly shown the blessings of AI for humanity, serious AI-related abuses and incidents have raised pressing ethical concerns. Consequently, researchers from different disciplines widely acknowledge an ethical discourse on AI. However, managers—eager to spark ethical considerations throughout their organizations—receive limited support on how they may establish and manage AI ethics. Although research is concerned with technological-related ethics in organizations, research on the ethical management of AI is limited. Against this background, the goals of this article are to provide a starting point for research on AI-related ethical concerns and to highlight future research opportunities. We propose an ethical management of AI (EMMA) framework, focusing on three perspectives: managerial decision making, ethical considerations, and macro- as well as micro-environmental dimensions. With the EMMA framework, we provide researchers with a starting point to address the managing the ethical aspects of AI.",,
Beyond the promise: implementing ethical AI,"Businesses require strong, mandated governance controls to ensure responsible AI use in enterprises.",Search,2021,19,Ray  Eitel-Porter,AI Ethics,,10.1007/s43681-020-00011-6,https://doi.org/10.1007/s43681-020-00011-6,https://semanticscholar.org/paper/0a7109502e7fe91f4decc3dd3515e1fecbc02da7,https://link.springer.com/content/pdf/10.1007/s43681-020-00011-6.pdf,"Artificial Intelligence (AI) applications can and do have unintended negative consequences for businesses if not implemented with care. Specifically, faulty or biased AI applications risk compliance and governance breaches and damage to the corporate brand. These issues commonly arise from a number of pitfalls associated with AI development, which include rushed development, a lack of technical understanding, and improper quality assurance, among other factors. To mitigate these risks, a growing number of organisations are working on ethical AI principles and frameworks. However, ethical AI principles alone are not sufficient for ensuring responsible AI use in enterprises. Businesses also require strong, mandated governance controls including tools for managing processes and creating associated audit trails to enforce their principles. Businesses that implement strong governance frameworks, overseen by an ethics board and strengthened with appropriate training, will reduce the risks associated with AI. When applied to AI modelling, the governance will also make it easier for businesses to bring their AI deployments to scale.",,
Ethics in artificial intelligence: introduction to the special issue,"The development of intelligent systems requires the integration of societal, legal, and moral values.",Search,2018,129,Virginia  Dignum,Ethics and Information Technology,,10.1007/s10676-018-9450-z,https://doi.org/10.1007/s10676-018-9450-z,https://semanticscholar.org/paper/6b77b4235bd455cf6df68cfa4fe4e2aa9401d06c,https://link.springer.com/content/pdf/10.1007%2Fs10676-018-9450-z.pdf,"Recent developments in Artificial Intelligence (AI) have generated a steep interest from media and general public. As AI systems (e.g. robots, chatbots, avatars and other intelligent agents) are moving from being perceived as a tool to being perceived as autonomous agents and team-mates, an important focus of research and development is understanding the ethical impact of these systems. What does it mean for an AI system to make a decision? What are the moral, societal and legal consequences of their actions and decisions? Can an AI system be held accountable for its actions? How can these systems be controlled once their learning capabilities bring them into states that are possibly only remotely linked to their initial, designed, setup? Should such autonomous innovation in commercial systems even be allowed, and how should use and development be regulated? These and many other related questions are currently the focus of much attention. The way society and our systems will be able to deal with these questions will for a large part determine our level of trust, and ultimately, the impact of AI in society, and the existence of AI. Contrary to the frightening images of a dystopic future in media and popular fiction, where AI systems dominate the world and is mostly concerned with warfare, AI is already changing our daily lives mostly in ways that improve human health, safety, and productivity (Stone et al. 2016). This is the case in domain such as transportation; service robots; health-care; education; public safety and security; and entertainment. Nevertheless, and in order to ensure that those dystopic futures do not become reality, these systems must be introduced in ways that build trust and understanding, and respect human and civil rights. The need for ethical considerations in the development of intelligent interactive systems is becoming one of the main influential areas of research in the last few years, and has led to several initiatives both from researchers as from practitioners, including the IEEE initiative on Ethics of Autonomous Systems1, the Foundation for Responsible Robotics2, and the Partnership on AI3 amongst several others. As the capabilities for autonomous decision making grow, perhaps the most important issue to consider is the need to rethink responsibility (Dignum 2017). Whatever their level of autonomy and social awareness and their ability to learn, AI systems are artefacts, constructed by people to fulfil some goals. Theories, methods, algorithms are needed to integrate societal, legal and moral values into technological developments in AI, at all stages of development (analysis, design, construction, deployment and evaluation). These frameworks must deal both with the autonomic reasoning of the machine about such issues that we consider to have ethical impact, but most importantly, we need frameworks to guide design choices, to regulate the reaches of AI systems, to ensure proper data stewardship, and to help individuals determine their own involvement. Values are dependent on the socio-cultural context (Turiel 2002), and are often only implicit in deliberation processes, which means that methodologies are needed to elicit the values held by all the stakeholders, and to make these explicit can lead to better understanding and trust on artificial autonomous systems. That is, AI reasoning should be able to take into account societal values, moral and ethical considerations; weigh the respective priorities of values held by different stakeholders in various multicultural contexts; explain its reasoning; and guarantee transparency. Responsible Artificial Intelligence is about human responsibility for the development of intelligent systems along fundamental human principles and values, to ensure human flourishing and wellbeing in a sustainable world. In fact, Responsible AI is more than the ticking of some ethical ‘boxes’ in a report, or the development of some add-on features, or switch-off buttons in AI systems. Rather, responsibility is fundamental",,
‘Ethical’ artificial intelligence in the welfare state: Discourse and discrepancy in Australian social services,"In Australia, the discourse around ethical AI does not correspond with the reality of AI deployment in the public sector.",Search,2021,1,"Alexandra  James, Andrew  Whelan",Critical Social Policy,,10.1177/0261018320985463,https://doi.org/10.1177/0261018320985463,https://semanticscholar.org/paper/79472473bb90bba50e9018c6ae7b13a98b1ac9a9,,"In recent years, a discourse of ‘ethical artificial intelligence’ has emerged and gained international traction in response to widely publicised AI failures. In Australia, the discourse around ethical AI does not accord with the reality of AI deployment in the public sector. Drawing on institutional ethnographic approaches, this paper describes the misalignments between how technology is described in government documentation, and how it is deployed in social service delivery. We argue that the propagation of ethical principles legitimates established new public management strategies, and pre-empts questions regarding the efficacy of AI development; instead positioning implementation as inevitable and, provided an ethical framework is adopted, laudable. The ethical AI discourse acknowledges, and ostensibly seeks to move past, widely reported administrative failures involving new technologies. In actuality, this discourse works to make AI implementation a reality, ethical or not.",,
Ethics of Artificial Intelligence,The development of artificial intelligence raises many ethical questions.,Search,2019,225,Josip  Horvat,Research Library Issues,,10.29242/rli.299,https://doi.org/10.29242/rli.299,https://semanticscholar.org/paper/fe68fdd7af4e27d42fc336833fced0e217dca255,https://publications.arl.org/is-cacheable/1569012368450/rli299/~~FreeAttachments/rli299.pdf,"Summary There are many ethical questions relating the issue of developing an intelligent system. There is strong and increasing pressure to raise capabilities of the artificial intelligence at least to the human levelled intelligence as the ultimate goal. This essay describes possible paths of development of the artificial intelligence. It is discussed how this changes will affect our society and challenges that humanity will have to face. Principles, guideways and modern viewpoints are presented and confirmed with the statements of the renowned scientists and experts in the field of the artificial intelligence ethics.",,
Program good ethics into artificial intelligence,Concerns that artificial intelligence will pose a danger if it develops consciousness are misplaced.,Search,2016,15,Jim  Davies,Nature,,10.1038/538291a,https://doi.org/10.1038/538291a,https://semanticscholar.org/paper/3fb408fd4edd98552a8a9c9915fe8ec7d31a9147,http://www.nature.com:80/polopoly_fs/1.20821!/menu/main/topColumns/topLeftColumn/pdf/538291a.pdf,"Concerns that artificial intelligence will pose a danger if it develops consciousness are misplaced, says Jim Davies.",,
An artificial neural network approach for creating an ethical artificial agent,The development of autonomous robotic systems and intelligent artificial agents' capability has advanced dramatically.,Search,2009,21,"Ali Reza Honarvar, Nasser  Ghasem-Aghaee",2009 IEEE International Symposium on Computational Intelligence in Robotics and Automation - (CIRA),,10.1109/CIRA.2009.5423190,https://doi.org/10.1109/CIRA.2009.5423190,https://semanticscholar.org/paper/ccbba7f671c53c907843bd5d806669dd53982c37,,"Autonomous robotic systems and intelligent artificial agents' capability have advanced dramatically. Since the intelligent artificial agents have been developing more autonomous and human-like, the capability of them to make moral decisions becomes an important issue. In this work we developed an artificial neutral network which considered various effective factors for ethical assessment of an action to determine that if a behavior or an action is ethically permissible or not. We integrated this net to the BDI-Agent model as a part of its reasoning process to behave ethically in various environments.",,