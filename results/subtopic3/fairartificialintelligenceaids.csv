Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Think Your Artificial Intelligence Software Is Fair? Think Again,"Machine-learning software is also biased, sometimes in similar ways to humans, often in different ways.",Search,2019,14,"Rachel K.E. Bellamy, Kuntal  Dey, Michael  Hind, Samuel C. Hoffman, Stephanie  Houde, Kalapriya  Kannan, Pranay  Lohia, Sameep  Mehta, Aleksandra  Mojsilovic, Seema  Nagar, Karthikeyan Natesan Ramamurthy, John  Richards, Diptikalyan  Saha, Prasanna  Sattigeri, Moninder  Singh, Kush R. Varshney, Yunfeng  Zhang",IEEE Software,,10.1109/MS.2019.2908514,https://doi.org/10.1109/MS.2019.2908514,https://semanticscholar.org/paper/4d60f78b44f34a67a5ce6316d1c45c90a912db44,,"Today, machine-learning software is used to help make decisions that affect people's lives. Some people believe that the application of such software results in fairer decisions because, unlike humans, machine-learning software generates models that are not biased. Think again. Machine-learning software is also biased, sometimes in similar ways to humans, often in different ways. While fair model- assisted decision making involves more than the application of unbiased models-consideration of application context, specifics of the decisions being made, resolution of conflicting stakeholder viewpoints, and so forth-mitigating bias from machine-learning software is important and possible but difficult and too often ignored.",,
Artificial intelligence aids in discrete-event digital simulation modelling,Artificial-intelligence aids could help solve the problem of current digital simulation modeling being an expensive process.,Search,1987,7,"Ray J. Paul, Georgios I. Doukidis",,,10.1049/IP-D:19870046,https://doi.org/10.1049/IP-D:19870046,https://semanticscholar.org/paper/7e7862f9aec0f06aabf531e07f52222419de84a6,,"Discrete-event digital simulation modelling is an important and increasingly used technique for analysing and solving complex problems in business, industry and the public service. Computer-aided systems are under development to improve the efficiency of what is currently an expensive time-consuming process. In particular, problem formulation is slow and inexact, an art which improves with experience. Artificial-intelligence aids have been developed to help the analyst in collaboration with the decision maker to solve the problem. The first attempts were based on expert systems. Limitations with these systems led to the development of a natural language understanding system. The way in which the natural language understanding system undertakes the task of aiding problem formulation is described, as well as the structure of the system itself. The role that such a system plays in the overall modelling process is described, with emphasis on limitations of the current system and how these might be overcome in future developments.",,
AI Fairness 360: An extensible toolkit for detecting and mitigating algorithmic bias,Fairness is an increasingly important concern as machine learning models are used to support decision making.,Search,2019,113,"Rachel K. E. Bellamy, Kuntal  Dey, Michael  Hind, Samuel C. Hoffman, Stephanie  Houde, Kalapriya  Kannan, Pranay  Lohia, Jacquelyn A. Martino, Sameep  Mehta, Aleksandra  Mojsilovic, Seema  Nagar, Karthikeyan Natesan Ramamurthy, John T. Richards, Diptikalyan  Saha, Prasanna  Sattigeri, Moninder  Singh, Kush R. Varshney, Yunfeng  Zhang",IBM J. Res. Dev.,,10.1147/jrd.2019.2942287,https://doi.org/10.1147/jrd.2019.2942287,https://semanticscholar.org/paper/333671a5fbbf726f8819138f3670524ec0405726,,"Fairness is an increasingly important concern as machine learning models are used to support decision making in high-stakes applications such as mortgage lending, hiring, and prison sentencing. This article introduces a new open-source Python toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released under an Apache v2.0 license (

https://github.com/ibm/aif360

). The main objectives of this toolkit are to help facilitate the transition of fairness research algorithms for use in an industrial setting and to provide a common framework for fairness researchers to share and evaluate algorithms. The package includes a comprehensive set of fairness metrics for datasets and models, explanations for these metrics, and algorithms to mitigate bias in datasets and models. It also includes an interactive Web experience that provides a gentle introduction to the concepts and capabilities for line-of-business users, researchers, and developers to extend the toolkit with their new algorithms and improvements and to use it for performance benchmarking. A built-in testing infrastructure maintains code quality.",,
"AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias",Fairness is an increasingly important concern as machine learning models are used to support decision making.,Search,2018,316,"Rachel K. E. Bellamy, Kuntal  Dey, Michael  Hind, Samuel C. Hoffman, Stephanie  Houde, Kalapriya  Kannan, Pranay  Lohia, Jacquelyn  Martino, Sameep  Mehta, Aleksandra  Mojsilovic, Seema  Nagar, Karthikeyan Natesan Ramamurthy, John T. Richards, Diptikalyan  Saha, Prasanna  Sattigeri, Moninder  Singh, Kush R. Varshney, Yunfeng  Zhang",ArXiv,,,,https://semanticscholar.org/paper/c8541b1dc813f3a638d7acc79e5f972e77f3c5a7,,"Fairness is an increasingly important concern as machine learning models are used to support decision making in high-stakes applications such as mortgage lending, hiring, and prison sentencing. This paper introduces a new open source Python toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released under an Apache v2.0 license {this https URL). The main objectives of this toolkit are to help facilitate the transition of fairness research algorithms to use in an industrial setting and to provide a common framework for fairness researchers to share and evaluate algorithms.

The package includes a comprehensive set of fairness metrics for datasets and models, explanations for these metrics, and algorithms to mitigate bias in datasets and models. It also includes an interactive Web experience (this https URL) that provides a gentle introduction to the concepts and capabilities for line-of-business users, as well as extensive documentation, usage guidance, and industry-specific tutorials to enable data scientists and practitioners to incorporate the most appropriate tool for their problem into their work products. The architecture of the package has been engineered to conform to a standard paradigm used in data science, thereby further improving usability for practitioners. Such architectural design and abstractions enable researchers and developers to extend the toolkit with their new algorithms and improvements, and to use it for performance benchmarking. A built-in testing infrastructure maintains code quality.",,
Designing Algorithms to Increase Fairness in Artificial Intelligence,Artificial intelligence can be trained to behave impartially by sophisticated algorithmic and computational approaches.,Search,2018,,"Anil  Aswani, Matt  Olfat",,,,,https://semanticscholar.org/paper/20a815559967e15848aecb02955126bf945e7724,,"The increasing role of artificial intelligence (AI) to automate decision-making sparks concern about potential AI-based discrimination. Such bias is undesirable in the quest to minimize inequality, and legal regulations require that AI not discriminate against protected classes on the basis of gender, race, age, and the like. Exclusion of data on protected classes when training AI is one strategy to minimize prejudice. However, this is not only a naive approach to fairness, but also insufficient because AI systems can learn to use information on protected classes via other data [2]; for example, race can often be inferred from a home address. Consequently, more sophisticated algorithmic and computational approaches are necessary to ensure that AI behaves impartially. Such concerns about AI fairness are not merely theoretical. Researchers have observed several instances of biased data and prejudiced AI. When discriminatory behavior influences the data that trains AI, the resulting AI output often perpetuates this bias. For instance, doctors frequently undertreat pain in women as compared to men [3]. AI systems for pain management trained using such biased data can algorithmically preserve this gender discrimination. Social media algorithms provide further examples; in one situation, LinkedIn disproportionately advertised high-paying jobs to men. In another, Facebook’s algorithms displayed considerable racial prejudice in censorship [1]. The first step towards developing fair AI is to quantify fairness, for which investigators have proposed several definitions for supervised learning to date. Put simply, these definitions require that an individual’s membership in a protected class (e.g., gender) will not impact AI’s outcome (e.g., approval or disapproval of a loan application). One can tailor this process for the purpose of classification, where the goal is to construct a function h p : { , }  → − + 1 1 (known as a classifier) that uses a vector of descriptive features x p Î  , characterizing each individual to predict a binary outcome y ∈ − + { , } 1 1 for him/ herself. When an individual’s protected class z ∈ − + { , } 1 1 is binary, the notion of demographic parity [4] at level D requires that | [ ( ) | ]  h x z = + = + − 1 1 [ ( ) | ]| . h x z =+ = − ≤ 1 1 ∆ Intuitively, the probability of receiving a positive outcome from the classifier is independent of the protected class’s value. Other definitions of fairness—such as equal opportunity—also exist [5]. While there are many approaches for constructing accurate classifiers from training data, researchers have only recently begun",,
Towards Fairness Certification in Artificial Intelligence,Machine learning models incur the risk of amplifying prejudices and societal stereotypes by over associating protected attributes.,Search,2021,1,"Tatiana  Tommasi, Silvia  Bucci, Barbara  Caputo, Pietro  Asinari",ArXiv,,,,https://semanticscholar.org/paper/157246efaa0a667383cd78da0599231687368e0e,,"Thanks to the great progress of machine learning in the last years, several Artificial Intelligence (AI) techniques have been increasingly moving from the controlled research laboratory settings to our everyday life. The most simple examples are the spam filters that keep our email account in order, face detectors that help us when taking a portrait picture, online recommender systems that suggest which movie and clothing we might like, or interactive maps that navigate us towards our vacation home. Artificial intelligence is clearly supportive in many decision-making scenarios, but when it comes to sensitive areas such as health care, hiring policies, education, banking or justice, with major impact on individuals and society, it becomes crucial to establish guidelines on how to design, develop, deploy and monitor this technology. Indeed the decision rules elaborated by machine learning models are data-driven and there are multiple ways in which discriminatory biases can seep into data. Algorithms trained on those data incur the risk of amplifying prejudices and societal stereotypes by over associating protected attributes such as gender, ethnicity or disabilities with the prediction task.",,
An Overview of Artificial Intelligence-Based Teaching Aids.,Artificial intelligence research has contributed to the development of teaching systems.,Search,1982,1,P Kathie Groveston,,,,,https://semanticscholar.org/paper/e7b1bb76671c989d1d996fcaf1a43189e64b3a79,,"Abstract : This paper discusses dome of the ways that artificial intelligence research has contributed to the development of teaching systems. Two aspects of artificial intelligence will be covered: object oriented programming languages (languages which perform symbolic as well as numerical processing by sending messages to objects rather than calling procedures), and expert systems (computer programs which solve problems by using knowledge and procedures obtained from human experts).",,Review
How Fair AI Can Make Us Richer,"AI systems steer important parts of our lives if we get admitted to university, if we are hired, fired or promoted.",Search,2021,,Sandra  Wachter,European Data Protection Law Review,,10.21552/edpl/2021/3/5,https://doi.org/10.21552/edpl/2021/3/5,https://semanticscholar.org/paper/24aa2a3be2464b0f641207bd1f2886c180cb1dc1,https://edpl.lexxion.eu/data/article/17685/pdf/edpl_2021_03-006.pdf,"Sandra Wachter* We are all aware that artificial intelligence (AI) has now become an integral part of our lives. AI systems are behind mundane tasks such as displaying search results on Safari, preparing travel routs on Google and suggesting new music on Spotify. But algorithms also steer important parts of our lives: if we get admitted to university, if we are hired, fired or promoted, if we get insurance, social benefits or a loan, or even if we have to go to prison. Algorithms can touch almost every aspect of our lives.",,
FARF: A Fair and Adaptive Random Forests Classifier,"In practical application, there is a trade-off between accuracy and fairness that needs to be accounted for.",Search,2021,5,"Wenbin  Zhang, Albert  Bifet, Xiangliang  Zhang, Jeremy C. Weiss, Wolfgang  Nejdl",PAKDD,,10.1007/978-3-030-75765-6_20,https://doi.org/10.1007/978-3-030-75765-6_20,https://semanticscholar.org/paper/0ea312eece884fd96038b1a4739056452f3235db,http://arxiv.org/pdf/2108.07403,"As Artificial Intelligence (AI) is used in more applications, the need to consider and mitigate biases from the learned models has followed. Most works in developing fair learning algorithms focus on the offline setting. However, in many real-world applications data comes in an online fashion and needs to be processed on the fly. Moreover, in practical application, there is a trade-off between accuracy and fairness that needs to be accounted for, but current methods often have multiple hyper-parameters with non-trivial interaction to achieve fairness. In this paper, we propose a flexible ensemble algorithm for fair decision-making in the more challenging context of evolving online settings. This algorithm, called FARF (Fair and Adaptive Random Forests), is based on using online component classifiers and updating them according to the current distribution, that also accounts for fairness and a single hyperparameters that alters fairness-accuracy balance. Experiments on realworld discriminated data streams demonstrate the utility of FARF.",,
Deep fair models for complex data: Graphs labeling and explainable face recognition,Fairness is required in deep artificial intelligence to learn a data representation able to discard all information leading to unfair behavior.,Search,2021,2,"Danilo  Franco, Nicolò  Navarin, Michele  Donini, Davide  Anguita, Luca  Oneto",Neurocomputing,,10.1016/J.NEUCOM.2021.05.109,https://doi.org/10.1016/J.NEUCOM.2021.05.109,https://semanticscholar.org/paper/0eb33a1a6150b066ea063c61e539d5267a66764f,,"Abstract The central goal of Algorithmic Fairness is to develop AI-based systems which do not discriminate subgroups in the population with respect to one or multiple notions of inequity, knowing that data is often humanly biased. Researchers are racing to develop AI-based systems able to reach superior performance in terms of accuracy, increasing the risk of inheriting the human biases hidden in the data. An obvious tension exists between these two lines of research that are currently colliding due to increasing concerns regarding the widespread adoption of these systems and their ethical impact. The problem is even more challenging when the input data is complex (e.g. graphs, trees, or images) and deep uninterpretable models need to be employed to achieve satisfactory performance. In fact, it is required to develop a deep architecture to learn a data representation able, from one side, to be expressive enough to describe the data and lead to highly accurate models and, from the other side, to discard all the information which may lead to unfair behavior. In this work we measure fairness according to Demographic Parity, requiring the probability of the model decisions to be independent of the sensitive information. We investigate how to impose this constraint in the different layers of deep neural networks for complex data, with particular reference to deep networks for graph and face recognition. We present experiments on different real-world datasets, showing the effectiveness of our proposal both quantitatively by means of accuracy and fairness metrics and qualitatively by means of visual explanation.",,
From Aware to Fair: Tackling Bias in A.I,Artificial intelligence algorithms dominate our life and are with us nearly 24/7.,Search,2021,,"Anthony J. Kupecz, Zachary  Ives",,,,,https://semanticscholar.org/paper/c3977673e4799153fdc73a01e7e3499a732283ba,,"Within the past decade, there has been tremendous advancements in the field of Artificial Intelligence (AI). From recommendation systems and facial recognition, to social services and recruiting tools, AI algorithms dominate our life and are with us nearly 24/7. Despite the tremendous boon these technologies have been for the majority, they have the potential to be nightmares with long lasting consequences for the minority. As designers of these widespread algorithms, it has become increasingly important that we are aware of the biases and potential for discrimination in these technologies. At the same time, it is important to maintain accuracy within these systems. This paper will explore the nascent topic of algorithmic fairness by looking at the problem through the lens of classification tasks. We will foray into the concept of “fairness” and the different proposed definitions, and then compare and contrast proposed solutions. We will end on a discussion of the limitations surrounding this topic and offer recommendations for the future of this space.",,
Artificial Intelligence-based Assistants (AIA),"Artificial Intelligence-based Assistants (AIs) unlock business value through automating processes, intensifying customer interaction, reducing errors, and speeding up interactions.",Search,2020,,Rainer  Schmidt,,,,,https://semanticscholar.org/paper/2cebcd4441dad9aa56d95a507e9e2ee9ff8567c9,,"Artificial Intelligence (AI) has received much attention due to the recent progress in several technological areas such as image detection, translation, and decision support [1]. Established businesses and many start-up businesses are eagerly discussing how they can gain a competitive advantage from complementing their products, services and processes with AI. In fact, based on the research in the AI domain since several decades, a broad variety of promising application fields were suggested where AI might add business value. Meanwhile, applications are not limited to simple structured problems, but even applications higher complexities are feasible, which require higher levels of “intelligence”. To avoid discussions on the ambivalent notion of “intelligence”, it shall refer to tasks involving perception, processing, action and learning [2]. Many applications are possible along these activities, in particular a user’s interaction via natural language. AI-based assistants employ technologies such as natural language processing, predictive analytics, machine learning, as well as voice recognition and generation. They unlock business value through automating processes, intensifying customer interaction, reducing errors, and speeding up interactions to name a few [3]. In general, two main impacts may be observed [4]. First, virtual personal assistants and chatbots, such as Amazon Alexa and Google Home, enable the interaction of human beings with machines by voice, replacing standard human-computer interaction via mouse, keyboard, and screen of an application. Second, AIbased assistants replace human beings interfacing two application systems. These kinds of AI-based assistants are also subsumed under the term Robotic Process Automation (RPA) [5], handling interactions previously performed by humans to pair two application systems. The success of AI-based assistants may be described with the various offerings from the big tech providers (e.g. Alexa, Cortana, Siri) as well as numerous chatbots that created with the open-source development kits. For example, the Alexa universe already comprises 47’000 applications, which are referred to as “skills” [6]. This is also linked to a growth of application fields and interaction modes, which explains why assistant platforms are also recognized as generalpurpose technologies [7]. Following the understanding that information systems are socio-technical in nature, AI-based assistants should be framed as a step toward humanizing technology and work environments in the digital economy. This opens the stage for many research questions that shall be addressed in the mini track.",,
Software Development Support for AI Programs,AI programs can perform almost as well as human experts in the diagnosis of infectious diseases.,Search,1987,48,"C. V. Ramamoorthy, Shashi  Shekhar, Vijay K. Garg",Computer,,10.1109/MC.1987.1663354,https://doi.org/10.1109/MC.1987.1663354,https://semanticscholar.org/paper/e580b445cc9cd1f01afa4f6544d9c3a68e697ebb,,"Artificial intelligence is a growing branch of computer science that studies ways of enabling computers to do tasks that seem to require human intelligence. These tasks include game playing, expert problem solving, natural language understanding, and theorem proving. Many existing AI programs perform such tasks with varying degrees of success. Whereas a program that can understand natural language is still a dream, many chess-playing programs can beat expert human players. More successful AI programs include knowledge-based expert systems that are being applied to a wide spectrum of real-life problems from airline catering to oil exploration. These systems can acquire knowledge about a domain from a human expert and then use it to solve routine problems in that area. For example, expert systems can perform almost as well as human experts in the diagnosis of infectious diseases (MYCIN), finding the structure of chemical compounds (DENDRAL), and performing mathematical symbol manipulations (MACSYMA). These AI systems offer new capabilities to tackle several problems difficult to solve using the conventional algorithmic approach.",,
Egoistic and altruistic motivation: How to induce users' willingness to help for imperfect AI,Empathy and monetary reward are the strongest stimuli of users' willingness to help for an imperfect AI.,Search,2019,10,"Yeonjoo  Lee, Miyeon  Ha, Sujeong  Kwon, Yealin  Shim, Jinwoo  Kim",Comput. Hum. Behav.,,10.1016/J.CHB.2019.06.009,https://doi.org/10.1016/J.CHB.2019.06.009,https://semanticscholar.org/paper/cf2bd4757695da46ec423635b22138166055d428,,"Abstract Although artificial intelligence is a growing area of research, several problems remain. One such problem of particular importance is the low accuracy of predictions. This paper suggests that users' help is a practical approach to improve accuracy and it considers four factors that trigger users' willingness to help for an imperfect AI system. The two factors covered in Study 1 are utilitarian benefit based on egoistic motivation, and empathy based on altruistic motivation. In Study 2, utilitarian benefit is divided into explainable AI and monetary reward. The results indicate that two variables, namely empathy and monetary reward, have significant positive effects on willingness to help, and monetary reward is the strongest stimulus. In addition, explainable AI is shown to be positively associated with trust in AI. This study applies social studies of help motivation to the HCI field in order to induce users' willingness to help for an imperfect AI. The triggers of help motivation, empathy and monetary reward, can be utilized to induce the users’ voluntary engagement in the loop with an imperfect AI.",,
Strategic Best-Response Fairness in Fair Machine Learning Algorithms,Machine learning algorithms have become increasingly common and have affect many aspects of our life.,Search,2019,2,"Hajime  Shimao, Junpei  Komiyama, Warut  Khern-am-nuai, Karthik  Kannan",,,10.2139/ssrn.3389631,https://doi.org/10.2139/ssrn.3389631,https://semanticscholar.org/paper/8f4ee05a638812932c322702ed0438e90750b27c,,"Machine learning algorithms have become increasingly common and have affect many aspects of our life. However, because the objective of most of the standard, off-the-shelf machine learning algorithms is to maximize the prediction performance, the results produced by these algorithms could be discriminatory. The discrimination issue has gain the interest from both academic researchers and practitioners to develop machine learning algorithms that are fair. Even then, most such algorithms focus on decreasing the disparity in predictions of successful outcomes. However, these algorithms tend to ignore the strategic behavior of prediction subpopulations, resulting in disparity in the behavior of prediction subjects at equilibrium. One exception is those algorithms that use equalized odds as a fairness criterion which can decrease disparity in behavior. However, they cannot be used in many practical settings. We propose a new class of fair machine learning algorithms that alleviate disparity in prediction results, disparity in behavior of prediction subjects, and does not need to account for the sensitive variable explicitly. Our algorithm also complies with the notion of equal treatment and explainable AI, and can be applied to a wide variety of prediction tasks. We demonstrate the theoretical performance of our algorithm in the asymptotic scenario. In addition, we show the practical performance of the proposed algorithm by comparing its performance with that of other ordinary off-the-shelf algorithms and that of existing fair machine learning algorithms available in the IBM Fairness 360 suite.",,
Artificial intelligence for brain diseases: A systematic review,Artificial intelligence is a major branch of computer science that is fruitfully used for analyzing medical data and extracting meaningful relationships.,Search,2020,14,"Alice  Segato, Aldo  Marzullo, Francesco  Calimeri, Elena  De Momi",APL bioengineering,,10.1063/5.0011697,https://doi.org/10.1063/5.0011697,https://semanticscholar.org/paper/50a483975abba83f66b4d621f70f2d2128b93137,https://re.public.polimi.it/bitstream/11311/1150452/2/Manuscript.pdf,"Artificial intelligence (AI) is a major branch of computer science that is fruitfully used for analyzing complex medical data and extracting meaningful relationships in datasets, for several clinical aims. Specifically, in the brain care domain, several innovative approaches have achieved remarkable results and open new perspectives in terms of diagnosis, planning, and outcome prediction. In this work, we present an overview of different artificial intelligent techniques used in the brain care domain, along with a review of important clinical applications. A systematic and careful literature search in major databases such as Pubmed, Scopus, and Web of Science was carried out using “artificial intelligence” and “brain” as main keywords. Further references were integrated by cross-referencing from key articles. 155 studies out of 2696 were identified, which actually made use of AI algorithms for different purposes (diagnosis, surgical treatment, intra-operative assistance, and postoperative assessment). Artificial neural networks have risen to prominent positions among the most widely used analytical tools. Classic machine learning approaches such as support vector machine and random forest are still widely used. Task-specific algorithms are designed for solving specific problems. Brain images are one of the most used data types. AI has the possibility to improve clinicians' decision-making ability in neuroscience applications. However, major issues still need to be addressed for a better practical use of AI in the brain. To this aim, it is important to both gather comprehensive data and build explainable AI algorithms.",,Systematic Review