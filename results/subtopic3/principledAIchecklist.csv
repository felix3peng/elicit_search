Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
A Survey on Ethical Principles of AI and Implementations,"Ethical principles need to be combined with every stages of the AI lifecycle in order to ensure that the AI system is designed, implemented, and deployed in an ethical manner.",Search,2020,2,"Jianlong  Zhou, Fang  Chen, Adam  Berry, Mike  Reed, Shujia  Zhang, Siobhan  Savage",2020 IEEE Symposium Series on Computational Intelligence (SSCI),,10.1109/SSCI47803.2020.9308437,https://doi.org/10.1109/SSCI47803.2020.9308437,https://semanticscholar.org/paper/66a07e8609b74a0967828bb179e84444c2d312a8,https://opus.lib.uts.edu.au/bitstream/10453/146673/2/IEEE_ETHAI2020_ethicalAI_Survey.pdf,"AI has powerful capabilities in prediction, automation, planning, targeting, and personalisation. Generally, it is assumed that AI can enable machines to exhibit human-like intelligence, and is claimed to benefit to different areas of our lives. Since AI is fueled by data and is a distinct form of autonomous and self-learning agency, we are seeing increasing ethical concerns related to AI uses. In order to mitigate various ethical concerns, national and international organisations including governmental organisations, private sectors as well as research institutes have made extensive efforts by drafting ethical principles of AI, and having active discussions on ethics of AI within and beyond the AI community. This paper investigates these efforts with a focus on the identification of fundamental ethical principles of AI and their implementations. The review found that there is a convergence around limited principles and the most prevalent principles are transparency, justice and fairness, responsibility, non-maleficence, and privacy. The investigation suggests that ethical principles need to be combined with every stages of the AI lifecycle in the implementation to ensure that the AI system is designed, implemented and deployed in an ethical manner. Similar to ethical framework used in biomedical and clinical research, this paper suggests checklist-style questionnaires as benchmarks for the implementation of ethical principles of AI.",,Review
Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI,There is a growing consensus around eight key thematic trends in AI principles documents.,Search,2020,137,"Jessica  Fjeld, Nele  Achten, Hannah  Hilligoss, Adam  Nagy, Madhulika  Srikumar",SSRN Electronic Journal,,10.2139/ssrn.3518482,https://doi.org/10.2139/ssrn.3518482,https://semanticscholar.org/paper/58bb24b72fea6d0ce172bdaf9c2f16c2bd7649e9,https://dash.harvard.edu/bitstream/1/42160420/1/HLS%20White%20Paper%20Final_v3.pdf,"The rapid spread of artificial intelligence (AI) systems has precipitated a rise in ethical and human rights-based frameworks intended to guide the development and use of these technologies. Despite the proliferation of these ""AI principles,"" there has been little scholarly focus on understanding these efforts either individually or as contextualized within an expanding universe of principles with discernible trends.

To that end, this white paper and its associated data visualization compare the contents of thirty-six prominent AI principles documents side-by-side. This effort uncovered a growing consensus around eight key thematic trends: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. Underlying this “normative core,” our analysis examined the forty-seven individual principles that make up the themes, detailing notable similarities and differences in interpretation found across the documents. In sharing these observations, it is our hope that policymakers, advocates, scholars, and others working to maximize the benefits and minimize the harms of AI will be better positioned to build on existing efforts and to push the fractured, global conversation on the future of AI toward consensus.",,
Principles and business processes for responsible AI,Organizations must undertake risk assessment from the perspectives of other stakeholders.,Search,2019,25,Roger  Clarke,Comput. Law Secur. Rev.,,10.1016/J.CLSR.2019.04.007,https://doi.org/10.1016/J.CLSR.2019.04.007,https://semanticscholar.org/paper/9042677e67305726a4511ef3e9a7a00239af2a79,,"Abstract The first article in this series examined why the world wants controls over Artificial Intelligence (AI). This second article discusses how an organisation can manage AI responsibly, in order to protect its own interests, but also those of its stakeholders and society as a whole. A limited amount of guidance is provided by ethical analysis. A much more effective approach is to apply adapted forms of the established techniques of risk assessment and risk management. Critically, risk assessment needs to be undertaken not only with the organisation's own interests in focus, but also from the perspectives of other stakeholders. To underpin this new form of business process, a set of Principles for Responsible AI is presented, consolidating proposals put forward by a diverse collection of 30 organisations.",,
Principles of Artificial Intelligence,"The book ""Principles of Artificial Intelligence"" describes fundamental AI ideas that underlie applications such as natural language processing.",Search,1981,3812,Nils J. Nilsson,IEEE Transactions on Pattern Analysis and Machine Intelligence,,10.1109/tpami.1981.4767059,https://doi.org/10.1109/tpami.1981.4767059,https://semanticscholar.org/paper/affcf19551b01c4c8009d061750700d91c2f79e9,,"A classic introduction to artificial intelligence intended to bridge the gap between theory and practice, ""Principles of Artificial Intelligence"" describes fundamental AI ideas that underlie applications such as natural language processing, automatic programming, robotics, machine vision, automatic theorem proving, and intelligent data retrieval. Rather than focusing on the subject matter of the applications, the book is organized around general computational concepts involving the kinds of data structures used, the types of operations performed on the data structures, and the properties of the control strategies used. ""Principles of Artificial Intelligence""evolved from the author's courses and seminars at Stanford University and University of Massachusetts, Amherst, and is suitable for text use in a senior or graduate AI course, or for individual study.",,
A Unified Framework of Five Principles for AI in Society,"A new principle, explicability, is needed in addition to the core principles of ethical AI.",Search,2019,152,"Luciano  Floridi, Josh  Cowls",Issue 1,,10.1162/99608F92.8CD550D1,https://doi.org/10.1162/99608F92.8CD550D1,https://semanticscholar.org/paper/8499e44d42b12518495069a54ae4400baccb7546,https://assets.pubpub.org/ukqte8ry/c8d3cba5-8f10-4a00-894c-3a3b886ad844.pdf,"Artificial Intelligence (AI) is already having a major impact on society. As a result, many organizations have launched a wide range of initiatives to establish ethical principles for the adoption of socially beneficial AI. Unfortunately, the sheer volume of proposed principles threatens to overwhelm and confuse. How might this problem of ‘principle proliferation’ be solved? In this paper, we report the results of a fine-grained analysis of several of the highest-profile sets of ethical principles for AI. We assess whether these principles converge upon a set of agreed-upon principles, or diverge, with significant disagreement over what constitutes ‘ethical AI.’ Our analysis finds a high degree of overlap among the sets of principles we analyze. We then identify an overarching framework consisting of five core principles for ethical AI. Four of them are core principles commonly used in bioethics: beneficence, non-maleficence, autonomy, and justice. On the basis of our comparative analysis, we argue that a new principle is needed in addition: explicability, understood as incorporating both the epistemological sense of intelligibility (as an answer to the question ‘how does it work?’) and in the ethical sense of accountability (as an answer to the question: ‘who is responsible for the way it works?’). In the ensuing discussion, we note the limitations and assess the implications of this ethical framework for future efforts to create laws, rules, technical standards, and best practices for ethical AI in a wide range of contexts.KeywordsAccountability; Autonomy; Artificial Intelligence; Beneficence; Ethics; Explicability; Fairness; Intelligibility; Justice; Non-maleficence.",,
Four Principles of Explainable Artificial Intelligence,"Artificial intelligence systems can provide reasons for their outputs and processes, understandability for individual users, accurate reflection of processes, and conditions for operation.",Search,2020,13,"P. Jonathon Phillips, Carina A. Hahn, Peter C. Fontana, David A. Broniatowski, Mark A. Przybocki",,,10.6028/nist.ir.8312-draft,https://doi.org/10.6028/nist.ir.8312-draft,https://semanticscholar.org/paper/d1615484d8af03aef212b2764bca93d70ac9707c,https://doi.org/10.6028/nist.ir.8312,"We introduce four principles for explainable artificial intelligence (AI) that comprise fundamental properties for explainable AI systems. We propose that explainable AI systems deliver accompanying evidence or reasons for outcomes and processes; provide explanations that are understandable to individual users; provide explanations that correctly reflect the system’s process for generating the output; and that a system only operates under conditions for which it was designed and when it reaches sufficient confidence in its output. We have termed these four principles as explanation, meaningful, explanation accuracy, and knowledge limits, respectively. Through significant stakeholder engagement, these four principles were developed to encompass the multidisciplinary nature of explainable AI, including the fields of computer science, engineering, and psychology. Because one-sizefits-all explanations do not exist, different users will require different types of explanations. We present five categories of explanation and summarize theories of explainable AI. We give an overview of the algorithms in the field that cover the major classes of explainable algorithms. As a baseline comparison, we assess how well explanations provided by people follow our four principles. This assessment provides insights to the challenges of designing explainable AI systems.",,Review
The Role and Limits of Principles in AI Ethics: Towards a Focus on Tensions,AI ethics should focus on exploring the tensions that arise as principles are implemented in practice.,Search,2019,72,"Jess  Whittlestone, Rune  Nyrup, Anna  Alexandrova, Stephen  Cave",AIES,,10.1145/3306618.3314289,https://doi.org/10.1145/3306618.3314289,https://semanticscholar.org/paper/304f2d1cf97ac8fb071b5357e97691d64f4e8f6a,https://dl.acm.org/doi/pdf/10.1145/3306618.3314289,"The last few years have seen a proliferation of principles for AI ethics. There is substantial overlap between different sets of principles, with widespread agreement that AI should be used for the common good, should not be used to harm people or undermine their rights, and should respect widely held values such as fairness, privacy, and autonomy. While articulating and agreeing on principles is important, it is only a starting point. Drawing on comparisons with the field of bioethics, we highlight some of the limitations of principles: in particular, they are often too broad and high-level to guide ethics in practice. We suggest that an important next step for the field of AI ethics is to focus on exploring the tensions that inevitably arise as we try to implement principles in practice. By explicitly recognising these tensions we can begin to make decisions about how they should be resolved in specific cases, and develop frameworks and guidelines for AI ethics that are rigorous and practically relevant. We discuss some different specific ways that tensions arise in AI ethics, and what processes might be needed to resolve them.",,
Model Checking Human-Agent Collectives for Responsible AI,"Safety, controllability, and ethics are difficult to ensure in human-agent collectives.",Search,2019,3,"Dhaminda B. Abeywickrama, Corina  Cîrstea, Sarvapali D. Ramchurn",2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),,10.1109/RO-MAN46459.2019.8956429,https://doi.org/10.1109/RO-MAN46459.2019.8956429,https://semanticscholar.org/paper/a06b653d0303405cc4f7da4868cf4b628863697f,,"Humans and agents often need to work together and agree on collective decisions. Ensuring that autonomous systems work responsibly is complex especially when encountering dilemmas. This paper proposes a novel, systematic model checking approach to responsible decision making by a human-agent collective to ensure it is safe, controllable and ethical. Our approach, which is based on the MCMAS model checker, verifies the permissibility of an agent’s actions by checking the decision-making behaviour against the logical formulae specified for safety, controllability and ethical behaviour. The verification results through counterexamples and simulation results can provide a judgement, and an explanation to the AI engineer of the reasons actions are refused or allowed.",,
Recommended Methods for Using the 2020 NIST Principles for AI Explainability,"User Benefits, Societal Acceptance, Regulatory and Compliance, System Development, and Owner Benefits.",Search,2020,,"Mary  Quinn, Blake  Piper, James P. Bliss, David  Keever",2020 IEEE International Conference on Big Data (Big Data),,10.1109/BigData50022.2020.9377760,https://doi.org/10.1109/BigData50022.2020.9377760,https://semanticscholar.org/paper/7ee1501062bf3dfccdce7bb99bcc6ae041760953,,"In August 2020, the United States National Institute of Standards and Technology (NIST) published (NISTIR 8312) which promulgated for review four principles for Artificial Intelligence (AI) explainability to assist researchers and practitioners in the AI field. These four principles, defined in more detail in the NIST document, are Explanation, Meaningfulness, Explanation Accuracy, and Knowledge Limits. The principles were tied to five types of explainability: User Benefits, Societal Acceptance, Regulatory and Compliance, System Development, and Owner Benefits. The proposed approach is to engage knowledgeable researchers and practitioners to offer ideas congruent with the four principles and five types of explainability. In addition to more detailed frameworks and approaches within the bounds of NISTIR 8312, participants will examine the NIST propositions for completeness and sufficiency.",,Review
Actionable Principles for Artificial Intelligence Policy: Three Pathways,AI Ethics Principles are often not actioned in governmental policy.,Search,2021,9,Charlotte  Stix,Sci. Eng. Ethics,,10.1007/s11948-020-00277-3,https://doi.org/10.1007/s11948-020-00277-3,https://semanticscholar.org/paper/16dc267a80a87e81e6a8ec4ed8c5a020657dd7da,https://link.springer.com/content/pdf/10.1007/s11948-020-00277-3.pdf,"In the development of governmental policy for artificial intelligence (AI) that is informed by ethics, one avenue currently pursued is that of drawing on “AI Ethics Principles”. However, these AI Ethics Principles often fail to be actioned in governmental policy. This paper proposes a novel framework for the development of ‘Actionable Principles for AI’. The approach acknowledges the relevance of AI Ethics Principles and homes in on methodological elements to increase their practical implementability in policy processes. As a case study, elements are extracted from the development process of the Ethics Guidelines for Trustworthy AI of the European Commission’s “High Level Expert Group on AI”. Subsequently, these elements are expanded on and evaluated in light of their ability to contribute to a prototype framework for the development of 'Actionable Principles for AI'. The paper proposes the following three propositions for the formation of such a prototype framework: (1) preliminary landscape assessments; (2) multi-stakeholder participation and cross-sectoral feedback; and, (3) mechanisms to support implementation and operationalizability.",,
Unifying Principles and Metrics for Safe and Assistive AI,AI safety focuses on designing AI systems that allow humans to safely instruct and control AI systems.,Search,2021,4,Siddharth  Srivastava,AAAI,,,,https://semanticscholar.org/paper/967cba5849f93869655af8d3d8fda9b0a3304a1d,,"The prevalence and success of AI applications have been tempered by concerns about the controllability of AI systems about AI’s impact on the future of work. These concerns reflect two aspects of a central question: how would humans work with AI systems? While research on AI safety focuses on designing AI systems that allow humans to safely instruct and control AI systems, research on AI and the future of work focuses on the impact of AI on humans who may be unable to do so. This Blue Sky Ideas paper proposes a unifying set of declarative principles that enable a more uniform evaluation of arbitrary AI systems along multiple dimensions of the extent to which they are suitable for use by specific classes of human operators. It leverages recent AI research and the unique strengths of the field to develop human-centric principles for AI systems that address the concerns noted above.",,
"Review of ""Principles of Artificial Intelligence by Nils J. Nilsson"", Tioga Publishing Co.","Nils Nilsson's book, ""Principles of Artificial Intelligence"", aims to fill a gap between theory and practice.",Search,1980,3,Elaine  Kant,SGAR,,10.1145/1056447.1056452,https://doi.org/10.1145/1056447.1056452,https://semanticscholar.org/paper/4dc1b87fd521864e675dc0aae403edd0a56e11c9,,"Nils Nilsson's new book, (Principles of Artificial Intelligence) (Tioga Publishing Co., 1980) discusses some basic ideas underlying different applications of AI. The book, designed as a text for a senior or first-year graduate course, aims to fill a gap between theory and practice. It succeeds in building a good solid arch outward from the shore of theory, but only a few support beams anchor the bridge to the shore of practice.",,Review
A Misdirected Principle with a Catch: Explicability for AI,The property of requiring explicability should attach to a particular action or decision rather than the entity making that decision.,Search,2019,38,Scott  Robbins,Minds and Machines,,10.1007/s11023-019-09509-3,https://doi.org/10.1007/s11023-019-09509-3,https://semanticscholar.org/paper/d83b033956e352559778c42b8997408fc8979e91,https://link.springer.com/content/pdf/10.1007/s11023-019-09509-3.pdf,"There is widespread agreement that there should be a principle requiring that artificial intelligence (AI) be ‘explicable’. Microsoft, Google, the World Economic Forum, the draft AI ethics guidelines for the EU commission, etc. all include a principle for AI that falls under the umbrella of ‘explicability’. Roughly, the principle states that “for AI to promote and not constrain human autonomy, our ‘decision about who should decide’ must be informed by knowledge of how AI would act instead of us” (Floridi et al. in Minds Mach 28(4):689–707, 2018). There is a strong intuition that if an algorithm decides, for example, whether to give someone a loan, then that algorithm should be explicable. I argue here, however, that such a principle is misdirected. The property of requiring explicability should attach to a particular action or decision rather than the entity making that decision. It is the context and the potential harm resulting from decisions that drive the moral need for explicability—not the process by which decisions are reached. Related to this is the fact that AI is used for many low-risk purposes for which it would be unnecessary to require that it be explicable. A principle requiring explicability would prevent us from reaping the benefits of AI used in these situations. Finally, the explanations given by explicable AI are only fruitful if we already know which considerations are acceptable for the decision at hand. If we already have these considerations, then there is no need to use contemporary AI algorithms because standard automation would be available. In other words, a principle of explicability for AI makes the use of AI redundant.",,
From principles to practice: How can we make AI ethics measurable?,Organizations that develop and deploy AI systems should implement precepts of ethical AI development.,Search,2021,,William  Warby,,,,,https://semanticscholar.org/paper/6629598bf1d16983bdffa9cade2216088b6e94d6,,"are omnipresent. A growing number of guidelines for the ethical development of socalled arti cial intelligence (AI) have been put forward by stakeholders from the private sector, civil society, and the scienti c and policymaking spheres. The Bertelsmann Stiftung’s Algo.Rules are among this body of proposals. However, it remains unclear how organizations that develop and deploy AI systems should implement precepts of this kind. In cooperation with the nonpro t VDE standardssetting organization, we are seeking to bridge this gap with a new working paper that demonstrates how AI ethics principles can be put into practice.",,
Analytic formulation of the principle of increasing precision with decreasing intelligence for intelligent machines,"A three-level structure representing the organization, coordination and execution is necessary to implement hierarchically intelligent control on an intelligent machine.",Search,1989,192,George N. Saridis,Autom.,,10.1016/0005-1098(89)90016-2,https://doi.org/10.1016/0005-1098(89)90016-2,https://semanticscholar.org/paper/8e29ae4eb775af3886d5dae0090d099eabd28c33,,"Abstract Intelligent machines, like intelligent robots are capable of performing autonomously in uncertain environments, and have imposed new design requirements for modern engineers. New concepts, drawn from areas like artificial intelligence, operations research and control theory, are required in order to implement anthropomorphic tasks with minimum intervention of an operator. This work deals with the analytic formulation of the principle of increasing precision with decreasing intelligence; the fundamental principle of hierarchically intelligent control. A three-level structure representing the organization, coordination and execution has been developed as a probabilistic model of such a system and the approaches necessary to implement each one of them on an intelligent machine are discussed. The principle is derived also from a probabilistic model and can be expressed in terms of entropies. It is compatible with the current formulation of the hierarchically intelligent control problem, the mathematical programming solution of which minimizes the total entropy. The derivation and design of parallel architectures for artificial intelligence, like the Boltzmann machine is obtained from such formulation.",,
Signs for Ethical AI: A Route Towards Transparency,"Today, AI fuels some of the most significant economic and research institutions in the world.",Search,2020,1,"Dario  Garcia-Gasulla, Atia  Cort'es, Sergio  Alvarez-Napagao, Ulises  Cort'es",ArXiv,,,,https://semanticscholar.org/paper/a9666a839d6b5f144714e62d61477a25a45fdec1,,"Artificial Intelligence (AI) has recently raised to the point where it has a direct impact on the daily life of billions of people. This is the result of its application to sectors like finance, health, digital entertainment, transportation, security and advertisement. Today, AI fuels some of the most significant economic and research institutions in the world, and the impact of AI in the near future seems difficult to predict or even bound. In contrast to all this power, society remains mostly ignorant of the capabilities, requirements and standard practices of AI today. Society is becoming aware of the dangers that come with that ignorance, and is rightfully asking for solutions. To address this need, improving on current practices of interaction between people and AI systems, we propose a transparency scheme to be implemented on any AI system open to the public. The scheme is based on two main pillars: Data Privacy and AI Transparency. The first recognizes the relevance of data for AI and is supported by GDPR, the most important legislation on the topic. The second considers aspects of AI transparency yet to be regulated: AI capacity, purpose and source. Lacking legislation to build upon, we design this pillar based on fundamental ethical principles. For each of the two pillars, we define a three-level display. The first level is based on visual signs, inspired by traffic signs managing the interaction between people and cars, and designed for quick and universal interpretability. The second level uses a factsheet system, providing further detail while still abstracting the subject. The last level provides access to all available details. After detailing and exemplifying the proposed transparency scheme, we define a set of principles for creating transparent by design software, to be used during the integration of AI components on user-oriented services.",,