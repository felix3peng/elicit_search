Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Human-Centered Artificial Intelligence: Three Fresh Ideas,"A two-dimensional HCAI framework, a shift from emulating humans to empowering people, and a three-level governance structure can promote trustworthy HCAI systems.",Search,2020,32,Ben  Shneiderman,,,10.17705/1thci.00131,https://doi.org/10.17705/1thci.00131,https://semanticscholar.org/paper/454af1728ba52b16965f7d18fc9301d0ffb6d708,https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1136&context=thci,"Human-Centered AI (HCAI) is a promising direction for designing AI systems that support human self-efficacy, promote creativity, clarify responsibility, and facilitate social participation. These human aspirations also encourage consideration of privacy, security, environmental protection, social justice, and human rights. This commentary reverses the current emphasis on algorithms and AI methods, by putting humans at the center of systems design thinking, in effect, a second Copernican Revolution. It offers three ideas: (1) a two-dimensional HCAI framework, which shows how it is possible to have both high levels of human control AND high levels of automation, (2) a shift from emulating humans to empowering people with a plea to shift language, imagery, and metaphors away from portrayals of intelligent autonomous teammates towards descriptions of powerful tool-like appliances and tele-operated devices, and (3) a three-level governance structure that describes how software engineering teams can develop more reliable systems, how managers can emphasize a safety culture across an organization, and how industry-wide certification can promote trustworthy HCAI systems. These ideas will be challenged by some, refined by others, extended to accommodate new technologies, and validated with quantitative and qualitative research. They offer a reframe -a chance to restart design discussions for products and services -which could bring greater benefits to individuals, families, communities, businesses, and society.",,
Human-Centered AI through Scalable Visual Data Analytics,"Artificial intelligence can be made more accessible and interpretable through scalable, interactive, easy-to-learn data visualization tools.",Search,2020,,Minsuk  Kahng,,,,,https://semanticscholar.org/paper/c6ce7fd941de2b1b9863cc8e43bc73a004343e52,,"While artificial intelligence (AI) has led to major breakthroughs in many domains, understanding machine learning models remains a fundamental challenge. They are often used as ”black boxes,” which could be detrimental. How can we help people understand complex machine learning models, so that they can learn them more easily and use them more effectively? In this talk, I present my research that makes AI more accessible and interpretable, through a novel human-centered approach, by creating novel data visualization tools that are scalable, interactive, and easy to learn and to use. I present my work in two interrelated topics. (1) Visualization for Industry-scale Models: I present how to scale up interactive visualization tools for industry-scale deep learning models that use large datasets. I describe how the ActiVis system helps Facebook data scientists interpret deep neural network models by visually exploring activation flows. ActiVis is patent-pending, and has been deployed on Facebook’s ML platform. (2) Interactive Understanding of Complex Models: I show how visualization helps novices interactively learn complex concepts of deep learning models. I describe how I developed GAN Lab, a visual education system for Generative Adversarial Networks (GANs), one of the most popular, but hard-to-understand models. GAN Lab has been open-sourced in collaboration with Google Brain and used by over 30,000 people from 140 countries. I conclude with my vision to make AI more human-centered, to promote actionability for AI, stimulate a stronger ethical AI workforce, and foster healthy impacts of AI on broader society. Monday, April 1, 2019, 10:00 am Planetarium E300 MSC Computer Science Emory University",,
How to center AI on humans,AI can be human-centered by emulating human intelligence such that it can center its activity and reasoning on its human users.,Search,2020,1,"Frank  Dignum, Virginia  Dignum",NeHuAI@ECAI,,,,https://semanticscholar.org/paper/001d4ec84341de6c75a3ef4fffc6b77409979818,,"In this position paper we investigate what it means for AI to be human-centered. Although many organisations and researchers by now have given requirements for human-centeredness, such as: transparancy, respect for human autonomy, fairness and accountability, this does little to indicate how the AI techniques should be designed in order to be human-centered. In this paper we argue that human-centered AI involves a shift from AI emulating intelligent human tasks, to emulating human intelligence such that we capture enough social intelligence in order for the AI system to be able to center its activity and reasoning on its human users.",,
Human-Centered Artificial Intelligence and Machine Learning,AI systems must be designed with awareness that they are part of a larger system consisting of humans.,Search,2019,67,Mark O. Riedl,Human Behavior and Emerging Technologies,,10.1002/HBE2.117,https://doi.org/10.1002/HBE2.117,https://semanticscholar.org/paper/1fccba11583dc9e1030713d61bd65e9e9990e39f,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/hbe2.117,"Humans are increasingly coming into contact with artificial intelligence and machine learning systems. Human-centered artificial intelligence is a perspective on AI and ML that algorithms must be designed with awareness that they are part of a larger system consisting of humans. We lay forth an argument that human-centered artificial intelligence can be broken down into two aspects: (1) AI systems that understand humans from a sociocultural perspective, and (2) AI systems that help humans understand them. We further argue that issues of social responsibility such as fairness, accountability, interpretability, and transparency.",,
Reinvigorating the Discourse on Human-Centered Artificial Intelligence in Educational Technologies,"The development and implementation of AI-driven approaches in education involve several privacies, ethics, and morality challenges.",Search,2021,1,"André  Renz, Gergana  Vladova",Technology Innovation Management Review,,10.22215/TIMREVIEW/1438,https://doi.org/10.22215/TIMREVIEW/1438,https://semanticscholar.org/paper/920ff37009ca389fae86d2165b6f5975d81f227a,https://timreview.ca/sites/default/files/article_PDF/TIMReview_2021_May%20-%201_1.pdf,"The increasing relevance of artificial intelligence (AI) applications in various domains has led to high expectations of benefits, ranging from precision, efficiency, and optimization to the completion of routine or time-consuming tasks. Particularly in the field of education, AI applications promise immense innovation potential. A central focus in this field is on analyzing and evaluating learner characteristics to derive learning profiles and create individualized learning environments. The development and implementation of such AI-driven approaches are related to learners' data, and thus involves several privacies, ethics, and morality challenges. In this paper, we introduce the concept of human-centered AI, and consider how an AI system can be developed in line with human values without posing risks to humanity. Because the education market is in the early stages of incorporating AI into educational tools, we believe that this is the right time to raise awareness about the use of principles that foster human-centered values and help in building responsible, ethical, and value-oriented AI.",,
Human-Centered AI,AI systems require the primary users to gain appropriate levels of trust.,Search,2021,4,"Hollen  Barmer, Rachel  Dzombak, Matthew  Gaston, Vijaykumar  Palat, Frank  Redner, Carol  Smith, Tanisha  Smith",,,10.1184/R1/16560183.V1,https://doi.org/10.1184/R1/16560183.V1,https://semanticscholar.org/paper/264b9b136889da3b4d7e50ef58c77678b35dc3e0,,"We identify three specific areas of focus to advance human-centered AI:• Designers and systems must understand the context of use and sense changes over time: Successful AI Engineering depends on the team’s ability to identify and articulate the desired system outcome and understand human and contextual factors affecting the outcome. The system itself must be able to learn when shifts in context have occurred. What are the best ways to maintain clarity around operational intent and mechanisms for adapting and evolving systems based on dynamic contexts and user needs? • Development of tools, processes, and practices to scope and facilitate human-machine teaming: Implementation of AI systems entails high levels of interdependence between human and machine. Adoption of AI systems requires the primary users to interact with and understand systems, gaining appropriate levels of trust. Every AI system needs to be designed to recognize boundaries and unfamiliar scenarios, and to provide transparency regarding its limitations. • Methods, mechanisms, and mindsets to engage in critical oversight: AI systems learn through data and observations, rather than being explicitly programmed for a deterministic outcome. Critical and reflective oversight by organizations, teams, and individuals that create and use AI systems is needed to uphold ethical principles and proactively consider the risks of bias, misuse, abuse, and unintended consequences through design, development, and ongoing deployment.For each area, we identify ongoing work as well and challenges and opportunities in developing and deploying AI systems with confidence.",,
Human-centered artificial intelligence in education: Seeing the invisible through the visible,"The rise of artificial intelligence requires understanding of how it can improve, educate, and train humans.",Search,2021,14,"Stephen J.H. Yang, Hiroaki  Ogata, Tatsunori  Matsui, Nian-Shing  Chen",Comput. Educ. Artif. Intell.,,10.1016/J.CAEAI.2021.100008,https://doi.org/10.1016/J.CAEAI.2021.100008,https://semanticscholar.org/paper/8a90ab1c8336d99048e16d5ce3e0148da7cf1371,https://repository.kulib.kyoto-u.ac.jp/dspace/bitstream/2433/261148/1/j.caeai.2021.100008.pdf,"Abstract The inevitable rise and development of artificial intelligence (AI) was not a sudden occurrence. The greater the effect that AI has on humans, the more pressing the need is for us to understand it. This paper addresses research on the use of AI to evaluate new design methods and tools that can be leveraged to advance AI research, education, policy, and practice to improve the human condition. AI has the potential to educate, train, and improve the performance of humans, making them better at their tasks and activities. The use of AI can enhance human welfare in numerous respects, such as through improving the productivity of food, health, water, education, and energy services. However, the misuse of AI due to algorithm bias and a lack of governance could inhibit human rights and result in employment, gender, and racial inequality. We envision that AI can evolve into human-centered AI (HAI), which refers to approaching AI from a human perspective by considering human conditions and contexts. Most current discussions on AI technology focus on how AI can enable human performance. However, we explore AI can also inhibit the human condition and advocate for an in-depth dialog between technology- and humanity-based researchers to improve understanding of HAI from various perspectives.",,
Human-centered Explainable AI: Towards a Reflective Sociotechnical Approach,"A reflective sociotechnical approach is advocated in AI systems to understand ""who"" the human is.",Search,2020,22,"Upol  Ehsan, Mark O. Riedl",HCI,,10.1007/978-3-030-60117-1_33,https://doi.org/10.1007/978-3-030-60117-1_33,https://semanticscholar.org/paper/2c9d71966e1e8a527a392bbe28aa53f8e0918755,http://arxiv.org/pdf/2002.01092,"Explanations--a form of post-hoc interpretability--play an instrumental role in making systems accessible as AI continues to proliferate complex and sensitive sociotechnical systems. In this paper, we introduce Human-centered Explainable AI (HCXAI) as an approach that puts the human at the center of technology design. It develops a holistic understanding of ""who"" the human is by considering the interplay of values, interpersonal dynamics, and the socially situated nature of AI systems. In particular, we advocate for a reflective sociotechnical approach. We illustrate HCXAI through a case study of an explanation system for non-technical end-users that shows how technical advancements and the understanding of human factors co-evolve. Building on the case study, we lay out open research questions pertaining to further refining our understanding of ""who"" the human is and extending beyond 1-to-1 human-computer interactions. Finally, we propose that a reflective HCXAI paradigm-mediated through the perspective of Critical Technical Practice and supplemented with strategies from HCI, such as value-sensitive design and participatory design--not only helps us understand our intellectual blind spots, but it can also open up new design and research spaces.",,
A Design Language for Human-Centered AI,,Search,2020,,Abhay  Agarwal,,,,,https://semanticscholar.org/paper/44a7f1ebb55f832eb121e99e8efda6693921a60e,,"Standard Notation has built human-centered AI for some of the worlds leading companies and innovators. In this talk, we introduce ‘Lingua Franca’, our design language for human-centered AI. Lingua Franca is the culmination of Standard Notation’s work designing AI solutions for companies spanning industries, from finance to insurance, logistics, asset tracking, consumer apps, data science tools, and deep technology. Lingua Franca includes a step-by-step design process that can be adopted by any company seeking to transform their digital strategy around human-centered AI, through a set of tools and techniques that include problem definition, ideation, iterative design, data exploration, and ethics. We start by describing human-centered AI for those new to it. We then describe how AI technology has consistently failed to be human-centered, by placing other values above those of its users. We then outline Lingua Franca, and how to integrate its ideas into your organization or team in order to create technology that is more empathetic, ethical, interpretable, and ultimately more value-aligned with humans.",,
"Tutorial: Human-Centered AI: Reliable, Safe and Trustworthy",AI algorithms are combined with human-centered thinking to make Human-Centered AI.,Search,2021,,Ben  Shneiderman,IUI Companion,,10.1145/3397482.3453994,https://doi.org/10.1145/3397482.3453994,https://semanticscholar.org/paper/77891ecacb567308c7ee8f117b8ffd5634d61e0f,,"This 3-hour tutorial proposes a new synthesis, in which Artificial Intelligence (AI) algorithms are combined with human-centered thinking to make Human-Centered AI (HCAI). This approach combines research on AI algorithms with user experience design methods to shape technologies that amplify, augment, empower, and enhance human performance. Researchers and developers for HCAI systems value meaningful human control, putting people first by serving human needs, values, and goals.",,
Human-Centered AI for Data Science: A Systematic Approach,AI techniques can be built to automate some parts of the data science workflow.,Search,2021,,"Dakuo  Wang, Xiaojuan  Ma, April Yi Wang",ArXiv,,,,https://semanticscholar.org/paper/e40548c93b4c60ef66f7acd6bd8a64291a72c53e,,"Human-Centered AI (HCAI) refers to the research effort that aims to design and implement AI techniques to support various human tasks, while taking human needs into consideration and preserving human control. In this short position paper, we illustrate how we approach HCAI using a series of research projects around Data Science (DS) works as a case study. The AI techniques built for supporting DS works are collectively referred to as AutoML systems, and their goals are to automate some parts of the DS workflow. We illustrate a three-step systematical research approach (i.e., explore, build, and integrate) and four practical ways of implementation for HCAI systems. We argue that our work is a cornerstone towards the ultimate future of Human-AI Collaboration for DS and beyond, where AI and humans can take complementary and indispensable roles to achieve a better outcome and experience.",,
"Toward Responsible, Human-Centered AI in EdTech",The education market is in the early stages of incorporating AI into educational tools.,Search,2020,,André  Renz,,,,,https://semanticscholar.org/paper/426a342b4617a8ef1cfbbb9f9dfa4a7a52bfd0bf,,"The increasing relevance of artificial intelligence (AI) applications in various domains has led to high expectations of benefits ranging from precision, efficiency, and optimization to the completion of routine or time-consuming tasks. Particularly in the field of education, there exist a multitude of yet-to-beanswered questions and challenges: How can the privacy of students be maintained? What will be AI’s long-term effects on teachers’ roles? What are the ethical and social consequences? In this paper, we introduce the concept of human-centered AI, rethinking how an AI system can be developed in line with human values and without posing risks to humanity. As the education market is in the early stages of incorporating AI into educational tools, we believe that this is the right time to create awareness about the use of principles that foster humancentered values and help in building a responsible, ethical, and value-oriented AI.",,
Towards Human Centered Ambient Intelligence,,Search,2008,4,"Thomas  Plötz, Christian  Kleine-Cosack, Gernot A. Fink",AmI,,10.1007/978-3-540-89617-3_3,https://doi.org/10.1007/978-3-540-89617-3_3,https://semanticscholar.org/paper/9fca45ef14d33b4c4736740f07cdfce1904e5133,,"In this paper we present a novel approach to the integration of humans into AmI environments. The key aspect of the concept which we call human centered Ami is a dynamic and active user model which creates a virtual doppelganger of the user on software level. This agent not only complies to the specific characteristics of humans but directly affects and triggers environmental activities. In fact the user's persona and behavior is mapped to system level. Utilizing this doppelganger we introduce the integration of the users' capabilities and skills into the functionality of the environment. Human services enrich intelligent environments and allow to overcome the ""all-or-nothing"" dilemma which we identified in conventional approaches. The concept of human centered AmI is put into effect within the perception-oriented intelligent environment FINCA. Results of a Wizard-of-Oz experiment with real users show the benefits of the presented approach.",,
"Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy",,Search,2020,105,Ben  Shneiderman,Int. J. Hum. Comput. Interact.,,10.1080/10447318.2020.1741118,https://doi.org/10.1080/10447318.2020.1741118,https://semanticscholar.org/paper/e49f67fa5c946ad24afcf59699a9cacf1ca53924,http://arxiv.org/pdf/2002.04087,"ABSTRACT Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The methods of HCAI are more likely to produce designs that are Reliable, Safe & Trustworthy (RST). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.",,
Interactive Human Centered Artificial Intelligence: A Definition and Research Challenges,,Search,2020,7,Albrecht  Schmidt,AVI,,10.1145/3399715.3400873,https://doi.org/10.1145/3399715.3400873,https://semanticscholar.org/paper/5267f3927eeaf45ed6c8340f07c34ff986474c84,,"Artificial Intelligence (AI) has become the buzzword of the last decade. Advances so far have been largely technical with a focus on machine learning (ML). Only recently have we begun seeing a shift towards focusing on the human aspects of artificial intelligence, centered on the narrow view of making AI interactive and explainable. In this paper I suggest a definition for ""Interactive Human Centered Artificial Intelligence and outline the required properties. Staying in control is essential for humans to feel safe and have self-determination. Hence, we need to find ways for humans to understand AI based systems and means to allow human control and oversight. In our work, we argue that levels of abstractions and granularity of control are a general solution to this. Furthermore, it is essential that we make explicit why we want AI and what are the goals of AI research and development. We need to state the properties that we expect of future intelligent systems and who will benefit from a system or service. For me, AI and ML are very much comparable to raw materials (like stone, iron, or bronze). Historical periods are named after these materials as they fundamentally changed what humans can build and what tools humans can engineer. Hence, I argue that in the AI age we need to shift the focus from the material (e.g. the AI algorithms, as there will be plenty of material) towards the tools and infrastructures that are enabled which are beneficial to humans. It is apparent that AI will allow the automation of mental routine tasks and that it will extend our ability to perceive the world and foresee events. For me, the central question is how to create these tools for amplifying the human mind without compromising human values.",,
"Human-Centered Artificial Intelligence: Trusted, Reliable & Safe.",,Search,2020,2,Ben  Shneiderman,,,,,https://semanticscholar.org/paper/e0b2bfdfcc251747538004be479f3914d0932316,,"Well-designed technologies that offer high levels of human control and high levels of computer automation can increase human performance, leading to wider adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies how to (1) design for high levels of human control and high levels of computer automation so as to increase human performance, (2) understand the situations in which full human control or full computer control are necessary, and (3) avoid the dangers of excessive human control or excessive computer control. The new goal of HCAI is more likely to produce designs that are Trusted, Reliable & Safe (TRS). Achieving these goals will dramatically increase human performance, while supporting human self-efficacy, mastery, creativity, and responsibility.",,