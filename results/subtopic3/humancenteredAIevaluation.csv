Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
On Design and Evaluation of Human-centered Explainable AI systems,"Viewing explanations can help establish rapport, confidence, and understanding between the AI agent and the user.",Search,2019,5,Upol  Ehsan,,,,,https://semanticscholar.org/paper/224b00003cdaa9f698be41520a3164d67d47951f,,"AsAI systems become ubiquitous in our lives, the human side of the equation needs careful investigation. The challenges of designing and evaluating ""black-boxed"" AI systems depends crucially on who the human is in the loop. Explanations, viewed as a form of post-hoc interpretability, can help establish rapport, confidence, and understanding between the AI agent and the user, especially when it comes to understanding failures and unexpected AI behavior. To effectively design and evaluate explanation generation systems, we need deeper end-to-end investigations of incorporating fully-realized AI agents and automated explanation generation systems into user studies. In this paper, we present a case study that focuses on how non-expert users perceive different styles of automatically generated rationales by an AI agent along the dimensions of confidence, humanlike-ness, adequate justification, and understandability. We summarize our results and provide a desiderata of research questions yet to be addressed.",,
A Survey of Human‐Centered Evaluations in Human‐Centered Machine Learning,Visual analytics systems integrate interactive visualizations and machine learning to enable expert users to solve complex analysis tasks.,Search,2021,6,"F.  Sperrle, M.  El‐Assady, G.  Guo, R.  Borgo, D. Horng  Chau, A.  Endert, D.  Keim",Comput. Graph. Forum,,10.1111/cgf.14329,https://doi.org/10.1111/cgf.14329,https://semanticscholar.org/paper/76dc15232628e3b5e3ddd5dc8a1b5ad1ef2bf4f6,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/cgf.14329,"Visual analytics systems integrate interactive visualizations and machine learning to enable expert users to solve complex analysis tasks. Applications combine techniques from various fields of research and are consequently not trivial to evaluate. The result is a lack of structure and comparability between evaluations. In this survey, we provide a comprehensive overview of evaluations in the field of human‐centered machine learning. We particularly focus on human‐related factors that influence trust, interpretability, and explainability. We analyze the evaluations presented in papers from top conferences and journals in information visualization and human‐computer interaction to provide a systematic review of their setup and findings. From this survey, we distill design dimensions for structured evaluations, identify evaluation gaps, and derive future research opportunities.",,Systematic Review
Human-centered artificial intelligence in education: Seeing the invisible through the visible,"The rise of artificial intelligence requires understanding of how it can improve, educate, and train humans.",Search,2021,14,"Stephen J.H. Yang, Hiroaki  Ogata, Tatsunori  Matsui, Nian-Shing  Chen",Comput. Educ. Artif. Intell.,,10.1016/J.CAEAI.2021.100008,https://doi.org/10.1016/J.CAEAI.2021.100008,https://semanticscholar.org/paper/8a90ab1c8336d99048e16d5ce3e0148da7cf1371,https://repository.kulib.kyoto-u.ac.jp/dspace/bitstream/2433/261148/1/j.caeai.2021.100008.pdf,"Abstract The inevitable rise and development of artificial intelligence (AI) was not a sudden occurrence. The greater the effect that AI has on humans, the more pressing the need is for us to understand it. This paper addresses research on the use of AI to evaluate new design methods and tools that can be leveraged to advance AI research, education, policy, and practice to improve the human condition. AI has the potential to educate, train, and improve the performance of humans, making them better at their tasks and activities. The use of AI can enhance human welfare in numerous respects, such as through improving the productivity of food, health, water, education, and energy services. However, the misuse of AI due to algorithm bias and a lack of governance could inhibit human rights and result in employment, gender, and racial inequality. We envision that AI can evolve into human-centered AI (HAI), which refers to approaching AI from a human perspective by considering human conditions and contexts. Most current discussions on AI technology focus on how AI can enable human performance. However, we explore AI can also inhibit the human condition and advocate for an in-depth dialog between technology- and humanity-based researchers to improve understanding of HAI from various perspectives.",,
Operationalizing Human-Centered Perspectives in Explainable AI,"The discourse of Explainable AI (XAI) has been predominantly focused on algorithm-centered approaches, suffering from gaps in meeting user needs.",Search,2021,7,"Upol  Ehsan, Philipp  Wintersberger, Q. Vera Liao, Martina  Mara, Marc  Streit, Sandra  Wachter, Andreas  Riener, Mark O. Riedl",CHI Extended Abstracts,,10.1145/3411763.3441342,https://doi.org/10.1145/3411763.3441342,https://semanticscholar.org/paper/310bec02ca79f537f6854f76b991f94ebde70f3a,,"The realm of Artificial Intelligence (AI)’s impact on our lives is far reaching – with AI systems proliferating high-stakes domains such as healthcare, finance, mobility, law, etc., these systems must be able to explain their decision to diverse end-users comprehensibly. Yet the discourse of Explainable AI (XAI) has been predominantly focused on algorithm-centered approaches, suffering from gaps in meeting user needs and exacerbating issues of algorithmic opacity. To address these issues, researchers have called for human-centered approaches to XAI. There is a need to chart the domain and shape the discourse of XAI with reflective discussions from diverse stakeholders. The goal of this workshop is to examine how human-centered perspectives in XAI can be operationalized at the conceptual, methodological, and technical levels. Encouraging holistic (historical, sociological, and technical) approaches, we put an emphasis on “operationalizing”, aiming to produce actionable frameworks, transferable evaluation methods, concrete design guidelines, and articulate a coordinated research agenda for XAI.",,
Human-centered Artificial Intelligence: A Multidimensional Approach towards Real World Evidence,An iterative methodology using hermeneutics outlines the need for a forward-thinking approach to deal with Real World Evidence.,Search,2019,3,"Bettina  Schneider, Petra Maria Asprion, Frank  Grimberg",ICEIS,,10.5220/0007715503810390,https://doi.org/10.5220/0007715503810390,https://semanticscholar.org/paper/f831bf2857fe27c3211f602f2839dec59222f251,http://pdfs.semanticscholar.org/603b/6573fa4f30d51652c687e3a6ace0bf6d3c01.pdf,"This study indicates the significance of a human-centered perspective in the analysis and interpretation of Real World Data. As an exemplary use-case, the construct of perceived ‘Health-related Quality of Life’ is chosen to show, firstly, the significance of Real World Data and, secondly, the associated ‘Real World Evidence’. We settled on an iterative methodology and used hermeneutics for a detailed literature analysis to outline the relevance and the need for a forward-thinking approach to deal with Real World Evidence in the life science and health care industry. The novelty of the study is its focus on a human-centered artificial intelligence, which can be achieved by using ‘System Dynamics’ modelling techniques. The outcome – a human-centered ‘Indicator Set’ can be combined with results from data-driven, AI-based analytics. With this multidimensional approach, human intelligence and artificial intelligence can be intertwined towards an enriched Real World Evidence. The developed approach considers three perspectives – the elementary, the algorithmic and – as novelty – the human-centered evidence. As conclusion, we claim that Real World Data are more valuable and applicable to achieve patient-centricity and personalization if the human-centered perspective is considered ‘by design’.",,
Evaluation metrics and methodologies for user-centered evaluation of intelligent systems,Collecting and analyzing data from analysts in an instrumented environment can inform ideas about the processes that analysts use.,Search,2006,23,"Jean  Scholtz, Emile L. Morse, Michelle Potts Steves",Interact. Comput.,,10.1016/j.intcom.2006.08.014,https://doi.org/10.1016/j.intcom.2006.08.014,https://semanticscholar.org/paper/0fbe31ffec62e93790cc30d3322f91013597ab6b,,"In the past four years, we have worked with several research programs that were developing intelligent software for use by intelligence analysts. Our involvement in these programs was to develop the metrics and methodologies for assessing the impact on users; in this case, on intelligence analysts. In particular, we focused on metrics to evaluate how much the intelligent systems contribute to the users' tasks and what the cost is to the user in terms of workload and process deviations. In this paper, we describe the approach used. We started with two types of preliminary investigations - first, collecting and analyzing data from analysts working in an instrumented environment for a period of 2 years, and second, developing and conducting formative evaluations of research software. The long-term studies informed our ideas about the processes that analysts use and provided potential metrics in an environment without intelligent software tools. The formative evaluations helped us to define sets of application-specific metrics. Finally, we conducted assessments during and after technology insertions. We describe the metrics and methodologies used in each of these activities, along with the lessons learned.",,
Human-centered AI: The role of Human-centered Design Research in the development of AI,Artificial Intelligence has the tremendous potential to produce progress and innovation in society.,Search,2020,12,Jan  Auernhammer,,,10.21606/drs.2020.282,https://doi.org/10.21606/drs.2020.282,https://semanticscholar.org/paper/647e53dbfa26c84eb4908ed67855b167da79398f,https://dl.designresearchsociety.org/cgi/viewcontent.cgi?article=1178&context=drs-conference-papers,"Artificial Intelligence has the tremendous potential to produce progress and innovation in society. Designing AI for people has been expressed as essential for societal well-being and the common good. However, human-centered is often used generically without any commitment to a philosophy or overarching approach. This paper outlines different philosophical perspectives and several Human-centered Design approaches and discusses their contribution to the development of Artificial Intelligence. The paper argues that humanistic design research should play a vital role in the pan-disciplinary collaboration with technologists and policymakers to mitigate the impact of AI. Ultimately, Human-centered Artificial Intelligence incorporates involving people and designing Artificial Intelligence systems for people through a genuine human-centered philosophy and approach.",,
Human-centered Explainable AI: Towards a Reflective Sociotechnical Approach,A reflective sociotechnical approach is advocated in AI evaluation for understanding the human factors.,Search,2020,22,"Upol  Ehsan, Mark O. Riedl",HCI,,10.1007/978-3-030-60117-1_33,https://doi.org/10.1007/978-3-030-60117-1_33,https://semanticscholar.org/paper/2c9d71966e1e8a527a392bbe28aa53f8e0918755,http://arxiv.org/pdf/2002.01092,"Explanations--a form of post-hoc interpretability--play an instrumental role in making systems accessible as AI continues to proliferate complex and sensitive sociotechnical systems. In this paper, we introduce Human-centered Explainable AI (HCXAI) as an approach that puts the human at the center of technology design. It develops a holistic understanding of ""who"" the human is by considering the interplay of values, interpersonal dynamics, and the socially situated nature of AI systems. In particular, we advocate for a reflective sociotechnical approach. We illustrate HCXAI through a case study of an explanation system for non-technical end-users that shows how technical advancements and the understanding of human factors co-evolve. Building on the case study, we lay out open research questions pertaining to further refining our understanding of ""who"" the human is and extending beyond 1-to-1 human-computer interactions. Finally, we propose that a reflective HCXAI paradigm-mediated through the perspective of Critical Technical Practice and supplemented with strategies from HCI, such as value-sensitive design and participatory design--not only helps us understand our intellectual blind spots, but it can also open up new design and research spaces.",,
Reinvigorating the Discourse on Human-Centered Artificial Intelligence in Educational Technologies,"The development of AI-driven approaches in education involves several privacies, ethics, and morality challenges.",Search,2021,1,"André  Renz, Gergana  Vladova",Technology Innovation Management Review,,10.22215/TIMREVIEW/1438,https://doi.org/10.22215/TIMREVIEW/1438,https://semanticscholar.org/paper/920ff37009ca389fae86d2165b6f5975d81f227a,https://timreview.ca/sites/default/files/article_PDF/TIMReview_2021_May%20-%201_1.pdf,"The increasing relevance of artificial intelligence (AI) applications in various domains has led to high expectations of benefits, ranging from precision, efficiency, and optimization to the completion of routine or time-consuming tasks. Particularly in the field of education, AI applications promise immense innovation potential. A central focus in this field is on analyzing and evaluating learner characteristics to derive learning profiles and create individualized learning environments. The development and implementation of such AI-driven approaches are related to learners' data, and thus involves several privacies, ethics, and morality challenges. In this paper, we introduce the concept of human-centered AI, and consider how an AI system can be developed in line with human values without posing risks to humanity. Because the education market is in the early stages of incorporating AI into educational tools, we believe that this is the right time to raise awareness about the use of principles that foster human-centered values and help in building responsible, ethical, and value-oriented AI.",,
How to center AI on humans,AI emulating human intelligence involves a shift from emulating intelligent human tasks to emulating human intelligence.,Search,2020,1,"Frank  Dignum, Virginia  Dignum",NeHuAI@ECAI,,,,https://semanticscholar.org/paper/001d4ec84341de6c75a3ef4fffc6b77409979818,,"In this position paper we investigate what it means for AI to be human-centered. Although many organisations and researchers by now have given requirements for human-centeredness, such as: transparancy, respect for human autonomy, fairness and accountability, this does little to indicate how the AI techniques should be designed in order to be human-centered. In this paper we argue that human-centered AI involves a shift from AI emulating intelligent human tasks, to emulating human intelligence such that we capture enough social intelligence in order for the AI system to be able to center its activity and reasoning on its human users.",,
AAAI FSS-19: Human-Centered AI: Trustworthiness of AI Models and Data Proceedings,"AI systems must be trustworthy, integrated, and yield trustworthy predictions to be widely accepted.",Search,2020,,"Florian  Buettner, John  Piorkowski, Ian  McCulloh, Ulli  Waltinger",ArXiv,,,,https://semanticscholar.org/paper/ba7c0198fb3ef7e233a342239c5a12af1c73c636,,"To facilitate the widespread acceptance of AI systems guiding decision-making in real-world applications, it is key that solutions comprise trustworthy, integrated human-AI systems. Not only in safety-critical applications such as autonomous driving or medicine, but also in dynamic open world systems in industry and government it is crucial for predictive models to be uncertainty-aware and yield trustworthy predictions. Another key requirement for deployment of AI at enterprise scale is to realize the importance of integrating human-centered design into AI systems such that humans are able to use systems effectively, understand results and output, and explain findings to oversight committees.

While the focus of this symposium was on AI systems to improve data quality and technical robustness and safety, we welcomed submissions from broadly defined areas also discussing approaches addressing requirements such as explainable models, human trust and ethical aspects of AI.",,
Human-Centered Artificial Intelligence and Machine Learning,AI systems must be designed with awareness that they are part of a larger system consisting of humans.,Search,2019,67,Mark O. Riedl,Human Behavior and Emerging Technologies,,10.1002/HBE2.117,https://doi.org/10.1002/HBE2.117,https://semanticscholar.org/paper/1fccba11583dc9e1030713d61bd65e9e9990e39f,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/hbe2.117,"Humans are increasingly coming into contact with artificial intelligence and machine learning systems. Human-centered artificial intelligence is a perspective on AI and ML that algorithms must be designed with awareness that they are part of a larger system consisting of humans. We lay forth an argument that human-centered artificial intelligence can be broken down into two aspects: (1) AI systems that understand humans from a sociocultural perspective, and (2) AI systems that help humans understand them. We further argue that issues of social responsibility such as fairness, accountability, interpretability, and transparency.",,
Human-Centered Artificial Intelligence: Three Fresh Ideas,,Search,2020,32,Ben  Shneiderman,,,10.17705/1thci.00131,https://doi.org/10.17705/1thci.00131,https://semanticscholar.org/paper/454af1728ba52b16965f7d18fc9301d0ffb6d708,https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1136&context=thci,"Human-Centered AI (HCAI) is a promising direction for designing AI systems that support human self-efficacy, promote creativity, clarify responsibility, and facilitate social participation. These human aspirations also encourage consideration of privacy, security, environmental protection, social justice, and human rights. This commentary reverses the current emphasis on algorithms and AI methods, by putting humans at the center of systems design thinking, in effect, a second Copernican Revolution. It offers three ideas: (1) a two-dimensional HCAI framework, which shows how it is possible to have both high levels of human control AND high levels of automation, (2) a shift from emulating humans to empowering people with a plea to shift language, imagery, and metaphors away from portrayals of intelligent autonomous teammates towards descriptions of powerful tool-like appliances and tele-operated devices, and (3) a three-level governance structure that describes how software engineering teams can develop more reliable systems, how managers can emphasize a safety culture across an organization, and how industry-wide certification can promote trustworthy HCAI systems. These ideas will be challenged by some, refined by others, extended to accommodate new technologies, and validated with quantitative and qualitative research. They offer a reframe -a chance to restart design discussions for products and services -which could bring greater benefits to individuals, families, communities, businesses, and society.",,
"AI Evaluation: past, present and future",AI systems are becoming more complex and unpredictable.,Search,2014,24,José  Hernández-Orallo,ArXiv,,,,https://semanticscholar.org/paper/8f2d78fb9293eac038a6a431d23ca5a18df7bfb4,,"Artificial intelligence develops techniques and systems whose performance must be evaluated on a regular basis in order to certify and foster progress in the discipline. We will describe and critically assess the different ways AI systems are evaluated. We first focus on the traditional task-oriented evaluation approach. We see that black-box (behavioural evaluation) is becoming more and more common, as AI systems are becoming more complex and unpredictable. We identify three kinds of evaluation: Human discrimination, problem benchmarks and peer confrontation. We describe the limitations of the many evaluation settings and competitions in these three categories and propose several ideas for a more systematic and robust evaluation. We then focus on a less customary (and challenging) ability-oriented evaluation approach, where a system is characterised by its (cognitive) abilities, rather than by the tasks it is designed to solve. We discuss several possibilities: the adaptation of cognitive tests used for humans and animals, the development of tests derived from algorithmic information theory or more general approaches under the perspective of universal psychometrics.",,
Toward the human – Centered approach. A revised model of individual acceptance of AI,The current academic debate is overly concerned by the impact that future AI will have on business and society.,Search,2021,1,"Manlio  Del Giudice, Veronica  Scuotto, Beatrice  Orlando, Mario  Mustilli",Human Resource Management Review,,10.1016/j.hrmr.2021.100856,https://doi.org/10.1016/j.hrmr.2021.100856,https://semanticscholar.org/paper/8b08e549fe4c88b32c31b988ac97adf74d1bf63d,,"Abstract The aim of the study is to understand how humans' acceptance of Artificial Intelligences (AIs) affects human resource management (HRM). To this end, we propose an original conceptual framework based on the idea of a sustainable growth driven by the interplay between AI and HRM. Current academic debate is overly concerned by the impact that future AI will have on business and society. One of the central aspects of the conversation is whether or not AI will replace humans in value-added activities. The study remarks that humanoids are an amplificator of human potential, in light of a human-centered approach. In this vein, present work reconceptualizes the tenets of society 5.0 by considering the category of “innovation ventura”, the evolution of the innovative enterprise in the next AI landscape.",,
Human-Centered AI,"AI systems require critical and reflective oversight to uphold ethical principles and proactively consider the risks of bias, misuse, abuse, and unintended consequences.",Search,2021,4,"Hollen  Barmer, Rachel  Dzombak, Matthew  Gaston, Vijaykumar  Palat, Frank  Redner, Carol  Smith, Tanisha  Smith",,,10.1184/R1/16560183.V1,https://doi.org/10.1184/R1/16560183.V1,https://semanticscholar.org/paper/264b9b136889da3b4d7e50ef58c77678b35dc3e0,,"We identify three specific areas of focus to advance human-centered AI:• Designers and systems must understand the context of use and sense changes over time: Successful AI Engineering depends on the team’s ability to identify and articulate the desired system outcome and understand human and contextual factors affecting the outcome. The system itself must be able to learn when shifts in context have occurred. What are the best ways to maintain clarity around operational intent and mechanisms for adapting and evolving systems based on dynamic contexts and user needs? • Development of tools, processes, and practices to scope and facilitate human-machine teaming: Implementation of AI systems entails high levels of interdependence between human and machine. Adoption of AI systems requires the primary users to interact with and understand systems, gaining appropriate levels of trust. Every AI system needs to be designed to recognize boundaries and unfamiliar scenarios, and to provide transparency regarding its limitations. • Methods, mechanisms, and mindsets to engage in critical oversight: AI systems learn through data and observations, rather than being explicitly programmed for a deterministic outcome. Critical and reflective oversight by organizations, teams, and individuals that create and use AI systems is needed to uphold ethical principles and proactively consider the risks of bias, misuse, abuse, and unintended consequences through design, development, and ongoing deployment.For each area, we identify ongoing work as well and challenges and opportunities in developing and deploying AI systems with confidence.",,