Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Responsible AI Challenges in End-to-end Machine Learning,Responsible AI must be easy to deploy and actionable.,Search,2021,,"Steven Euijong Whang, Ki Hyun Tae, Yuji  Roh, Geon  Heo",ArXiv,,,,https://semanticscholar.org/paper/0233cd95dd0bc327dd72a14d60216c98021250ab,,"Responsible AI is becoming critical as AI is widely used in our everyday lives. Many companies that deploy AI publicly state that when training a model, we not only need to improve its accuracy, but also need to guarantee that the model does not discriminate against users (fairness), is resilient to noisy or poisoned data (robustness), is explainable, and more. In addition, these objectives are not only relevant to model training, but to all steps of end-to-end machine learning, which include data collection, data cleaning and validation, model training, model evaluation, and model management and serving. Finally, responsible AI is conceptually challenging, and supporting all the objectives must be as easy as possible. We thus propose three key research directions towards this vision – depth, breadth, and usability – to measure progress and introduce our ongoing research. First, responsible AI must be deeply supported where multiple objectives like fairness and robust must be handled together. To this end, we propose FR-Train, a holistic framework for fair and robust model training in the presence of data bias and poisoning. Second, responsible AI must be broadly supported, preferably in all steps of machine learning. Currently we focus on the data pre-processing steps and propose Slice Tuner, a selective data acquisition framework for training fair and accurate models, and MLClean, a data cleaning framework that also improves fairness and robustness. Finally, responsible AI must be usable where the techniques must be easy to deploy and actionable. We propose FairBatch, a batch selection approach for fairness that is effective and simple to use, and Slice Finder, a model evaluation tool that automatically finds problematic slices. We believe we scratched the surface of responsible AI for end-to-end machine learning and suggest research challenges moving forward.",,
Responsible Artificial Intelligence (AI) for Value Formation and Market Performance in Healthcare: the Mediating Role of Patient’s Cognitive Engagement,The healthcare sector has been at the forefront of the adoption of artificial intelligence technologies.,Search,2021,11,"Pradeep  Kumar, Yogesh K. Dwivedi, Ambuj  Anand",Information systems frontiers : a journal of research and innovation,,10.1007/s10796-021-10136-6,https://doi.org/10.1007/s10796-021-10136-6,https://semanticscholar.org/paper/8eaeda4885475764277a056c37e034be2e46ccd2,https://link.springer.com/content/pdf/10.1007/s10796-021-10136-6.pdf,"The Healthcare sector has been at the forefront of the adoption of artificial intelligence (AI) technologies. Owing to the nature of the services and the vulnerability of a large section of end-users, the topic of responsible AI has become the subject of widespread study and discussion. We conduct a mixed-method study to identify the constituents of responsible AI in the healthcare sector and investigate its role in value formation and market performance. The study context is India, where AI technologies are in the developing phase. The results from 12 in-depth interviews enrich the more nuanced understanding of how different facets of responsible AI guide healthcare firms in evidence-based medicine and improved patient centered care. PLS-SEM analysis of 290 survey responses validates the theoretical framework and establishes responsible AI as a third-order factor. The 174 dyadic data findings also confirm the mediation mechanism of the patient’s cognitive engagement with responsible AI-solutions and perceived value, which leads to market performance.",,
Responsibility and Artificial Intelligence,Responsibility is necessary for the development of frameworks for responsible artificial intelligence.,Search,2020,4,Virginia  Dignum,,,10.1093/oxfordhb/9780190067397.013.12,https://doi.org/10.1093/oxfordhb/9780190067397.013.12,https://semanticscholar.org/paper/faf748f8f38d48f2ef310e9e6f55ed277dcbebbf,,"This chapter explores the concept of responsibility in artificial intelligence (AI). Being fundamentally tools, AI systems are fully under the control and responsibility of their owners or users. However, their potential autonomy and capability to learn require that design considers accountability, responsibility, and transparency principles in an explicit and systematic manner. The main concern of Responsible AI is thus the identification of the relative responsibility of all actors involved in the design, development, deployment, and use of AI systems. Firstly, society must be prepared to take responsibility for AI impact. Secondly, Responsible AI implies the need for mechanisms that enable AI systems to act according to ethics and human values. Lastly, Responsible AI is about participation. It is necessary to understand how different people work with and live with AI technologies across cultures in order to develop frameworks for responsible AI.",,
Responsible AI Tutorial,A key aspect to making AI responsible is to have a development pipeline that can promote reproducibility of results and manage the lineage of data and ML models.,Search,2022,,"Dr Mukta Paliwal, Dattaraj  Rao, Amogh Kamat Tarcar",COMAD/CODS,,10.1145/3493700.3493769,https://doi.org/10.1145/3493700.3493769,https://semanticscholar.org/paper/04b7d3004cdf971ea05803fbe39c25de561afcc5,,"There is rapid technical progress and widespread adoption of Artificial Intelligence (AI) based products and workflows influencing many aspects of human and business activities like banking, healthcare, advertising and many more. Although accuracy of AI models is undoubtedly the most important factor considered while deploying AI based products, there is urgent need to understand how AI can be designed to operate responsibly. Responsible AI is a framework that each software developing organization needs to adapt to build customer trust in the transparency, accountability, fairness, and security of deployed AI solutions. At the same time a key aspect to making AI responsible is to have a development pipeline that can promote reproducibility of results and manage the lineage of data and ML models. This tutorial will throw light on these aspects of Responsible AI with a working example demonstrating the concept. The intent of the tutorial will be to equip the audience with enough knowledge of the concepts along with code to gain appreciation for the importance of building Responsible AI.",,
Principles and business processes for responsible AI,A risk assessment approach is required to manage AI responsibly.,Search,2019,25,Roger  Clarke,Comput. Law Secur. Rev.,,10.1016/J.CLSR.2019.04.007,https://doi.org/10.1016/J.CLSR.2019.04.007,https://semanticscholar.org/paper/9042677e67305726a4511ef3e9a7a00239af2a79,,"Abstract The first article in this series examined why the world wants controls over Artificial Intelligence (AI). This second article discusses how an organisation can manage AI responsibly, in order to protect its own interests, but also those of its stakeholders and society as a whole. A limited amount of guidance is provided by ethical analysis. A much more effective approach is to apply adapted forms of the established techniques of risk assessment and risk management. Critically, risk assessment needs to be undertaken not only with the organisation's own interests in focus, but also from the perspectives of other stakeholders. To underpin this new form of business process, a set of Principles for Responsible AI is presented, consolidating proposals put forward by a diverse collection of 30 organisations.",,
Software Engineering Methods for Responsible Artificial Intelligence,An engineering process model can support ethical considerations throughout the software development life-cycle.,Search,2021,,Zahoor Ul Islam,AAMAS,,10.5555/3463952.3464248,https://doi.org/10.5555/3463952.3464248,https://semanticscholar.org/paper/40a6c6adf5f8a0cffcf0c36e1963d6324add2705,,"In order to ensure responsible Artificial intelligence (AI) applications engineering, we need to make sure that the development of AI systems is mindful of the consequences for individuals and societies. By anticipating the consequences of the design choices, reflecting upon the problem being solved by engaging all stakeholders and taking appropriate actions to ensure openness and the system’s social, legal, and ethical acceptability. This research aims to develop an engineering process model by which ethical considerations can be addressed throughout the AI systems’ software development life-cycle. The design methodological framework engineered in this PhD research will support aligning system goals with key ethical values by providing explicit values analysis and interpretation mechanisms, formal representation of ethical values, mechanisms for stakeholders participation in handling ethical deliberation, and providing support for governance and compliance mechanisms.",,
Toward an Understanding of Responsible Artificial Intelligence Practices,There is an urgently need to understand how AI can be designed to operate responsibly and act in a manner meeting stakeholders’ expectations and applicable regulations.,Search,2020,16,"Yichuan  Wang, Mengran  Xiong, Hossein  Olya",HICSS,,10.24251/hicss.2020.610,https://doi.org/10.24251/hicss.2020.610,https://semanticscholar.org/paper/6f62e85aa4034e206caa2482e90c349c954e21fb,http://eprints.whiterose.ac.uk/162719/8/Toward%20an%20Understanding%20of%20Responsible%20Artificial%20Intelligence%20Practices.pdf,"Artificial Intelligence (AI) is influencing all aspects of human and business activities nowadays. Although potential benefits emerged from AI technologies have been widely discussed in many current literature, there is an urgently need to understand how AI can be designed to operate responsibly and act in a manner meeting stakeholders’ expectations and applicable regulations. We seek to fill the gap by exploring the practices of responsible AI and identifying the potential benefits when implementing responsible AI practices. In this study, 10 responsible AI cases were selected from different industries to better understand the use of responsible AI in practices. Four responsible AI practices are identified, including governance, ethically design solutions, risk control and training and education and five strategies for firms who are considering to adopt responsible AI practices are recommended.",,
Towards Responsible Artificial Intelligence in Long-term Care: A Scoping Review on Practical Approaches.,There is limited empirical evidence detailing how responsible AI innovation is addressed in context.,Search,2021,,"Dirk R M Lukkien, Henk Herman Nap, Hendrik P Buimer, Alexander  Peine, Wouter P C Boon, Johannes C F Ket, Mirella M N Minkman, Ellen H M Moors",The Gerontologist,,10.1093/geront/gnab180,https://doi.org/10.1093/geront/gnab180,https://semanticscholar.org/paper/a2adc42d39d81e6cdb5b32c45451c42fd3aa3427,https://academic.oup.com/gerontologist/advance-article-pdf/doi/10.1093/geront/gnab180/42216937/gnab180.pdf,"BACKGROUND AND OBJECTIVES

Artificial intelligence (AI) is widely positioned to become a key element of intelligent technologies used in the long-term care (LTC) for older adults. The increasing relevance and adoption of AI has encouraged debate over the societal and ethical implications of introducing and scaling AI. This scoping review investigates how the design and implementation of AI technologies in LTC is addressed responsibly: so called responsible innovation (RI).

RESEARCH DESIGN AND METHODS

We conducted a systematic literature search in five electronic databases using concepts related to LTC, AI and RI. We then performed a descriptive and thematic analysis to map the key concepts, types of evidence and gaps in the literature.

RESULTS

After reviewing 3,339 papers, 25 papers were identified that met our inclusion criteria. From this literature, we extracted three overarching themes: user-oriented AI innovation; framing AI as a solution to RI issues; and context-sensitivity. Our results provide an overview of measures taken and recommendations provided to address responsible AI innovation in LTC.

DISCUSSION AND IMPLICATIONS

The review underlines the importance of the context of use when addressing responsible AI innovation in LTC. However, limited empirical evidence actually details how responsible AI innovation is addressed in context. Therefore, we recommend expanding empirical studies on RI at the level of specific AI technologies and their local contexts of use. Also, we call for more specific frameworks for responsible AI innovation in LTC to flexibly guide researchers and innovators. Future frameworks should clearly distinguish between RI processes and outcomes.",,Review
Responsible AI and Its Stakeholders,All stakeholders involved in the development of AI are responsible for their systems.,Search,2020,3,"Gabriel  Lima, Meeyoung  Cha",ArXiv,,,,https://semanticscholar.org/paper/1d2eac19d1bd75d9d9f2afc919c2612b819c4ac2,,"Responsible Artificial Intelligence (AI) proposes a framework that holds all stakeholders involved in the development of AI to be responsible for their systems. It, however, fails to accommodate the possibility of holding AI responsible per se, which could close some legal and moral gaps concerning the deployment of autonomous and self-learning systems. We discuss three notions of responsibility (i.e., blameworthiness, accountability, and liability) for all stakeholders, including AI, and suggest the roles of jurisdiction and the general public in this matter.",,
Software Engineering for Responsible AI: An Empirical Study and Operationalised Patterns,AI ethics principles and guidelines are typically high-level and do not provide concrete guidance on how to design and develop responsible AI systems.,Search,2021,1,"Qinghua  Lu, Liming  Zhu, Xiwei  Xu, Jon  Whittle, David  Douglas, Conrad  Sanderson",ArXiv,,,,https://semanticscholar.org/paper/6a03b02e61b447ce1456624853d7accfd24a2711,,"Although artificial intelligence (AI) is solving real-world challenges and transforming industries, there are serious concerns about its ability to behave and make decisions in a responsible way. Many AI ethics principles and guidelines for responsible AI have been recently issued by governments, organisations, and enterprises. However, these AI ethics principles and guidelines are typically high-level and do not provide concrete guidance on how to design and develop responsible AI systems. To address this shortcoming, we first present an empirical study where we interviewed 21 scientists and engineers to understand the practitioners’ perceptions on AI ethics principles and their implementation. We then propose a template that enables AI ethics principles to be operationalised in the form of concrete patterns and suggest a list of patterns using the newly created template. These patterns provide concrete, operationalised guidance that facilitate the development of responsible AI systems.",,
Responsible AI for Digital Health: a Synthesis and a Research Agenda,"Issues regarding ethical, transparent, and accountable AI in health raise moral and ethical consequences.",Search,2021,11,"Cristina  Trocin, Patrick  Mikalef, Zacharoula  Papamitsiou, Kieran  Conboy",Information Systems Frontiers,,10.1007/s10796-021-10146-4,https://doi.org/10.1007/s10796-021-10146-4,https://semanticscholar.org/paper/758289be073e7d4e6be6e6e4a7f937ef48ae81bd,https://link.springer.com/content/pdf/10.1007/s10796-021-10146-4.pdf,"Responsible AI is concerned with the design, implementation and use of ethical, transparent, and accountable AI technology in order to reduce biases, promote fairness, equality, and to help facilitate interpretability and explainability of outcomes, which are particularly pertinent in a healthcare context. However, the extant literature on health AI reveals significant issues regarding each of the areas of responsible AI, posing moral and ethical consequences. This is particularly concerning in a health context where lives are at stake and where there are significant sensitivities that are not as pertinent in other domains outside of health. This calls for a comprehensive analysis of health AI using responsible AI concepts as a structural lens. A systematic literature review supported our data collection and sampling procedure, the corresponding analysis, and extraction of research themes helped us provide an evidence-based foundation. We contribute with a systematic description and explanation of the intellectual structure of Responsible AI in digital health and develop an agenda for future research.",,Review
Role of Risks in the Development of Responsible Artificial Intelligence in the Digital Healthcare Domain,Artificial intelligence in the healthcare field raises some concerns related to privacy and ethical aspects.,Search,2021,1,"Shivam  Gupta, Shampy  Kamboj, Surajit  Bag",Information Systems Frontiers,,10.1007/s10796-021-10174-0,https://doi.org/10.1007/s10796-021-10174-0,https://semanticscholar.org/paper/a5340e0005d70f836a64be27ce720775c6aac79c,,"The use of artificial intelligence (AI) in the healthcare field is gaining popularity. However, it also raises some concerns related to privacy and ethical aspects that require the development of a responsible AI framework. The principle of responsible AI states that artificial intelligence-based systems should be considered a part of composite societal and technological systems. This study attempts to establish whether AI risks in digital healthcare are positively associated with responsible AI. The moderating effect of perceived trust and perceived privacy risks is also examined. The theoretical model was based on perceived risk theory. Perceived risk theory is important in the context of this study, as risks related to uneasiness and uncertainty can be expected in the development of responsible AI due to the volatile nature of intelligent applications. Our research provides some interesting findings which are presented in the discussion section.",,
Responsible AI: A Primer for the Legal Community,The data-driven and often black box nature of these systems does not absolve organizations from the social responsibility.,Search,2020,,"Ilana  Golbin, Anand S. Rao, Ali  Hadjarian, Daniel  Krittman",2020 IEEE International Conference on Big Data (Big Data),,10.1109/BigData50022.2020.9377738,https://doi.org/10.1109/BigData50022.2020.9377738,https://semanticscholar.org/paper/7d6cd81f02876c8bdd3c75582a73734339fdd711,,"Artificial intelligence (AI) is increasingly being adopted for automation and decision-making tasks across all industries, public sector, and law. Applications range from hiring and credit limit decisions, to loan and healthcare claim approvals, to criminal sentencing, and even the selective provision of information by social media companies to different groups of viewers. The increased adoption of AI, affecting so many aspects of our daily lives, highlights the potential risks around automated decision making and the need for better governance and ethical standards when deploying such systems. In response to that need, governments, states, municipalities, private sector organizations, and industry groups around the world have drafted hundreds, perhaps even thousands at this point - of new, regulatory proposals and guidelines; many already in effect and more on the way. The data-driven and often black box nature of these systems does not absolve organizations from the social responsibility or increasingly commonplace regulatory requirements to confirm they work as intended and are deployed in a responsible manner, lest they run the risk of reputational damage, regulatory fines, and/or legal action. The legal community should have a good understanding of the responsible development and deployment of artificial intelligence in order to inform, translate, and advise on the legal implications of AI systems.",,
Responsible Artificial Intelligence: Designing Ai for Human Values,Artificial intelligence is increasingly affecting our lives in smaller or greater ways.,Search,2017,55,Virginia  Dignum,,,,,https://semanticscholar.org/paper/c9fd2a6b240caf3d18f641d5956e71cbd29930e3,,"Artificial intelligence (AI) is increasingly affecting our lives in smaller or greater ways. In order to ensure that systems will uphold human values, design methods are needed that incorporate ethical principles and address societal concerns. In this paper, we explore the impact of AI in the case of the expected effects on the European labor market, and propose the accountability, responsibility and transparency (ART) design principles for the development of AI systems that are sensitive to human values.",,
Responsible AI—Two Frameworks for Ethical Design Practice,The difficulty in moving from principles to practice is a challenge for the implementation of ethical guidelines.,Search,2020,28,"Dorian  Peters, Karina  Vold, Diana  Robinson, Rafael A. Calvo",IEEE Transactions on Technology and Society,,10.1109/TTS.2020.2974991,https://doi.org/10.1109/TTS.2020.2974991,https://semanticscholar.org/paper/3193cbc9ff8a6fe9b308d7075704d5dc43accc93,https://ieeexplore.ieee.org/ielx7/8566059/8995808/09001063.pdf,"In 2019, the IEEE launched the P7000 standards projects intended to address ethical issues in the design of autonomous and intelligent systems. This move came amidst a growing public concern over the unintended consequences of artificial intelligence (AI), compounded by the lack of an anticipatory process for attending to ethical impact within professional practice. However, the difficulty in moving from principles to practice presents a significant challenge to the implementation of ethical guidelines. Herein, we describe two complementary frameworks for integrating ethical analysis into engineering practice to help address this challenge. We then provide the outcomes of an ethical analysis informed by these frameworks, conducted within the specific context of Internet-delivered therapy in digital mental health. We hope both the frameworks and analysis can provide tools and insights, not only for the context of digital healthcare but also for data-enabled and intelligent technology development more broadly.",,
Responsible AI,AI can be a powerful tool to address global challenges and to help people lead better lives.,Search,2021,1,Ben  Shneiderman,Commun. ACM,,10.1145/3445973,https://doi.org/10.1145/3445973,https://semanticscholar.org/paper/dd8216b7c6329d7931ed5ad842263e960d15397d,,Recommendations for increasing the benefits of artificial intelligence technologies.,,