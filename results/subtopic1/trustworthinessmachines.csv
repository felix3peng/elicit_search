Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
"Trustworthy Machine Learning: Past, Present, and Future","Machine-learning algorithms, especially deep neural networks, are being used in diverse domains where trustworthiness is a concern.",Search,2021,,Somesh  Jha,AsiaCCS,,10.1145/3433210.3460015,https://doi.org/10.1145/3433210.3460015,https://semanticscholar.org/paper/dc61605f0b7feb3f560118dbd280e5a6f4a4c939,,"Fueled by massive amounts of data, models produced by machine-learning (ML) algorithms, especially deep neural networks (DNNs), are being used in diverse domains where trustworthiness is a concern, including automotive systems, finance, healthcare, natural language processing, and malware detection. Of particular concern is the use of ML algorithms in cyber-physical systems (CPS), such as self-driving cars and aviation, where an adversary can cause serious consequences. Interest in this area of research has simply exploded. In this work, we will cover the state-of-the-art in trustworthy machine learning, and then cover some interesting future trends.",,
Technologies for Trustworthy Machine Learning: A Survey in a Socio-Technical Context,"Technologies that support building trustworthy machine-learning systems require knowledge in fair, explainable, auditable, and safety & security properties.",Search,2020,3,"Ehsan  Toreini, Mhairi  Aitken, Kovila P. L. Coopamootoo, Karen  Elliott, Vladimiro  González-Zelaya, Paolo  Missier, Magdalene  Ng, Aad van Moorsel",ArXiv,,,,https://semanticscholar.org/paper/5f34f91329e15d855fe9e08069c4c556c3e66f7f,,"Concerns about the societal impact of AI-based services and systems has encouraged governments and other organisations around the world to propose AI policy frameworks to address fairness, accountability, transparency and related topics. To achieve the objectives of these frameworks, the data and software engineers who build machine-learning systems require knowledge about a variety of relevant supporting tools and techniques. In this paper we provide an overview of technologies that support building trustworthy machine learning systems, i.e., systems whose properties justify that people place trust in them. We argue that four categories of system properties are instrumental in achieving the policy objectives, namely fairness, explainability, auditability and safety & security (FEAS). We discuss how these properties need to be considered across all stages of the machine learning life cycle, from data collection through run-time model inference. As a consequence, we survey in this paper the main technologies with respect to all four of the FEAS properties, for data-centric as well as model-centric stages of the machine learning system life cycle. We conclude with an identification of open research problems, with a particular focus on the connection between trustworthy machine learning technologies and their implications for individuals and society.",,Review
The relationship between trust in AI and trustworthy machine learning technologies,Trustworthiness technologies can support the required qualities of machines that require trust.,Search,2020,50,"Ehsan  Toreini, Mhairi  Aitken, Kovila  Coopamootoo, Karen  Elliott, Carlos Gonzalez Zelaya, Aad van Moorsel",FAT*,,10.1145/3351095.3372834,https://doi.org/10.1145/3351095.3372834,https://semanticscholar.org/paper/bd4cf5a6987ef0f39b7e4e88d59b3a3365abcc70,http://arxiv.org/pdf/1912.00782,"To design and develop AI-based systems that users and the larger public can justifiably trust, one needs to understand how machine learning technologies impact trust. To guide the design and implementation of trusted AI-based systems, this paper provides a systematic approach to relate considerations about trust from the social sciences to trustworthiness technologies proposed for AI-based services and products. We start from the ABI+ (Ability, Benevolence, Integrity, Predictability) framework augmented with a recently proposed mapping of ABI+ on qualities of technologies that support trust. We consider four categories of trustworthiness technologies for machine learning, namely these for Fairness, Explainability, Auditability and Safety (FEAS) and discuss if and how these support the required qualities. Moreover, trust can be impacted throughout the life cycle of AI-based systems, and we therefore introduce the concept of Chain of Trust to discuss trustworthiness technologies in all stages of the life cycle. In so doing we establish the ways in which machine learning technologies support trusted AI-based systems. Finally, FEAS has obvious relations with known frameworks and therefore we relate FEAS to a variety of international 'principled AI' policy and technology frameworks that have emerged in recent years.",,
Trustworthy Voting: From Machine to System,"The electronic voting approach incorporates a trustworthy process, simplified procedures, and built-in redundant safeguards that prevent tampering.",Search,2009,28,"Nathanael  Paul, Andrew S. Tanenbaum",Computer,,10.1109/MC.2009.169,https://doi.org/10.1109/MC.2009.169,https://semanticscholar.org/paper/dd75b2fcb8b5117acc2121a47ac74eee9a87303b,,"The authors describe an electronic voting approach that takes a system view, incorporating a trustworthy process based on open source software, simplified procedures, and built-in redundant safeguards that prevent tampering.",,
Trustworthy AI,The pursuit of responsible AI raises the ante on both the trustworthy computing and formal methods communities.,Search,2021,7,Jeannette M. Wing,Commun. ACM,,10.1145/3448248,https://doi.org/10.1145/3448248,https://semanticscholar.org/paper/33cf9b4d6c76f988380b1adff2c06c30010f93d3,https://dl.acm.org/doi/pdf/10.1145/3448248,The pursuit of responsible AI raises the ante on both the trustworthy computing and formal methods communities.,,
Trustworthiness of Autonomous Systems,Transdisciplinary research is needed to develop trustworthy autonomous systems.,Search,2018,17,S. Kate Devitt,CDC 2018,,10.1007/978-3-319-64816-3_9,https://doi.org/10.1007/978-3-319-64816-3_9,https://semanticscholar.org/paper/d84e786286b6afa167ca016a01cf0d8e408df76e,https://link.springer.com/content/pdf/10.1007%2F978-3-319-64816-3_9.pdf,"Effective robots and autonomous systems must be trustworthy. This chapter examines models of trustworthiness from a philosophical and empirical perspective to inform the design and adoption of autonomous systems. Trustworthiness is a property of trusted agents or organisations that engenders trust in other agent or organisations. Trust is a complex phenomena defined differently depending on the discipline. This chapter aims to bring different approaches under a single framework for investigation with three sorts of questions: Who or what is trustworthy? –metaphysics. How do we know who or what is trustworthy? –epistemology. What factors influence what or who should we trust? –normativity. A two-component model of trust is used that incorporates competence (skills, reliability and experience) and integrity (motives, honesty and character). It is supposed that human levels of competence yield the highest trust whereas trust is reduced at sub-human and super-human levels. The threshold for trustworthiness of an agent or organisation in a particular context is a function of their relationship with the truster and potential impacts of decisions. Building trustworthy autonomous systems requires obeying the norms of logic, rationality and ethics under pragmatic constraints–even though there is disagreement on these principles by experts. Autonomous systems may need sophisticated social identities including empathy and reputational concerns to build human-like trust relationships. Ultimately transdisciplinary research drawing on metaphysical, epistemological and normative human and machine theories of trust are needed to design trustworthy autonomous systems for adoption.",,
Toward trustworthy software systems,The choice of a component architecture greatly influences the resulting software systems' nonfunctional properties.,Search,2006,137,"Wilhelm  Hasselbring, Ralf H. Reussner",Computer,,10.1109/MC.2006.142,https://doi.org/10.1109/MC.2006.142,https://semanticscholar.org/paper/dc436f4d1591410ade952f8116093539d678c33d,,"Organizations such as Microsoft's Trusted Computing Group and Sun Microsystems' Liberty Alliance are currently leading the debate on ""trustworthy computing."" However, these and other initiatives primarily focus on security, and trustworthiness depends on many other attributes. To address this problem, the University of Oldenburg's TrustSoft Graduate School aims to provide a holistic view of trustworthiness in software - one that considers system construction, evaluation/analysis, and certification - in an interdisciplinary setting. Component technology is the foundation of our research program. The choice of a component architecture greatly influences the resulting software systems' nonfunctional properties. We are developing new methods for the rigorous design of trustworthy software systems with predictable, provable, and ultimately legally certifiable system properties. We are well aware that it is impossible to build completely error-free complex software systems. We therefore complement fault-prevention and fault-removal techniques with fault-tolerance methods that introduce redundancy and diversity into software systems. Quantifiable attributes such as availability, reliability, and performance call for analytical prediction models, which require empirical studies for calibration and validation. To consider the legal aspects of software certification and liability, TrustSoft integrates the disciplines of computer science and computer law.",,
Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence,The reliability of CPS can be assessed automatically in real time using machine learning.,Search,2021,81,"Zhihan  Lv, Yang  Han, Amit Kumar Singh, Gunasekaran  Manogaran, Haibin  Lv",IEEE Transactions on Industrial Informatics,,10.1109/TII.2020.2994747,https://doi.org/10.1109/TII.2020.2994747,https://semanticscholar.org/paper/79086f67c5d7413a05305478b1b38781588ed19d,,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.",,
Analyzing trustworthiness of virtual machines in data-intensive cloud computing,Software attestation and heartbeat messages can be used to evaluate the current status of virtual machines in cloud computing.,Search,2014,1,"Dipen  Contractor, Dhiren R. Patel","2014 Twelfth Annual International Conference on Privacy, Security and Trust",,10.1109/PST.2014.6890967,https://doi.org/10.1109/PST.2014.6890967,https://semanticscholar.org/paper/9901abf74c0d3481ba21627057cf38ecc28713ac,,"Data-intensive cloud computing offers an abstraction of high availability, usability, and efficiency while processing petabytes of data. As individual users do not have sole control on cloud resources, it may lead to concerns regarding the trustworthiness of the resources used. In this paper, we propose a trustworthiness analysis framework that adapts software attestation mechanisms and heartbeat messages to evaluate the current status of virtual machine in cloud computing to know trustworthiness of the resources.",,
Can We Make Sense of the Notion of Trustworthy Technology?,The notion of trustworthy technology cannot be applied to intelligent systems that interact with users.,Search,2010,15,"Pj Philip Nickel, Mpm  Franssen, Peter  Kroes",,,10.1007/S12130-010-9124-6,https://doi.org/10.1007/S12130-010-9124-6,https://semanticscholar.org/paper/ef09b69b766c58be03bff209ad544f996467a12a,https://link.springer.com/content/pdf/10.1007%2Fs12130-010-9124-6.pdf,"In this paper we raise the question whether technological artifacts can properly speaking be trusted or said to be trustworthy. First, we set out some prevalent accounts of trust and trustworthiness and explain how they compare with the engineer’s notion of reliability. We distinguish between pure rational-choice accounts of trust, which do not differ in principle from mere judgments of reliability, and what we call “motivation-attributing” accounts of trust, which attribute specific motivations to trustworthy entities. Then we consider some examples of technological entities that are, at first glance, best suited to serve as the objects of trust: intelligent systems that interact with users, and complex socio-technical systems. We conclude that the motivation-attributing concept of trustworthiness cannot be straightforwardly applied to these entities. Any applicable notion of trustworthy technology would have to depart significantly from the full-blown notion of trustworthiness associated with interpersonal trust.",,
Trustworthy Computing and Services,Software makers' quality assurance budgets are increasing but program failures happen quite often.,Search,2012,8,"Yuyu  Yuan, Xu  Wu, Yueming  Lu",Communications in Computer and Information Science,,10.1007/978-3-642-35795-4,https://doi.org/10.1007/978-3-642-35795-4,https://semanticscholar.org/paper/9d3de039ed75d1fb7843a97d39fdc4a47ad4eb03,,"Software controls an increasing number of complex technical systems, ranging from Internet-based e-health and e-government applications to embedded control systems in factories, cars, and aircrafts. Even though the quality assurance budgets of software makers are increasing, program failures happen quite often. The successful deployment of software systems depends on the extent to which we can justifiably trust them. Academia, government, and industry have conducted several efforts with the aim of providing a view of trustworthiness in software from system construction, evaluation and analysis. This paper investigates the previous and present activities that have been performed to achieve software trustworthiness and suggests some guidelines for future activities. The proposed approach uses the novel behaviouristic model for verifying software trustworthiness based on scenarios of interactions between the software and its users and environment [1].",,
Trustworthy systems revisited,Pervasive problems in information systems require cooperative social efforts to prevent.,Search,2006,1,Peter G. Neumann,CACM,,10.1145/1113034.1113065,https://doi.org/10.1145/1113034.1113065,https://semanticscholar.org/paper/c653c278ef974bd6044a8273e53f48c21bd846e5,,"S ystem trustworthiness is in essence a logical basis for confidence that a system will predictably satisfy its critical requirements, including information security, reliability, human safety, fault tolerance, and survivability in the face of wide ranges of adversities (such as malfunctions , deliberate attacks, and natural causes). Our lives increasingly depend on critical national infrastructures that depend in varying degrees on the dependable behavior of computer-communication resources, including the Internet and many of its attached computer systems. Unless certain information system resources are trustworthy, our critical systems are at serious risk from failures and subver-sions. Unfortunately, for many of the key application domains, the existing information infrastructures are lacking in trustworthiness. For example, power grids, air-traffic control, high-integrity electronic voting systems, the emerging DoD Global Information Grid, the national infra-structures, and many collaborative and competitive Internet-based applications all need systems that are more trustworthy than we have today. In this column, we have frequently considered risks associated with such systems and what is needed to make them more trustworthy. This month's column takes a higher-level and more intuitive view by considering analogies with our natural environ-ment—expectations for which are rather similar to expectations for trustworthy information systems. For example, pure air and uncontaminated water are vital, as are the social systems that ensure them. Although poorly chosen analogies can be misleading , the analogy with our natural environment seems quite apt. Each of the following bulleted items is applicable to both trustworthy information systems and natural environments. • Their critical importance is generally underappre-ciated until something goes fundamentally wrong—after which undoing the damage can be very difficult if not impossible. • Problems can result from natural circumstances, equipment failures, human errors, malicious activity , or a combination of these and other factors. • Dangerous contaminants may emerge and propagate, often unobserved. Some of these may remain unde-tected for relatively long periods of time, whereas others can have immediately obvious consequences. • Your well-being may be dramatically impeded, but there is not much you as an individual can do about aspects that are pervasive—perhaps international or even global in scope. • Detection, remediation, and prevention require cooperative social efforts, such as public health and sanitation efforts, as well as technological means. • Up-front preventive measures can result in significant savings and increases in human well-being, ameliorating major problems later on. • Once something has gone recognizably wrong, countermeasures are typically fruitless—too …",,
Trustworthiness Attributes and Metrics for Engineering Trusted Internet-Based Software Systems,The notion of trustworthiness is subject to individual interpretation and preference.,Search,2013,35,"Nazila Gol Mohammadi, Sachar  Paulus, Mohamed  Bishr, Andreas  Metzger, Holger  Könnecke, Sandro  Hartenstein, Thorsten  Weyer, Klaus  Pohl",CLOSER,,10.1007/978-3-319-11561-0_2,https://doi.org/10.1007/978-3-319-11561-0_2,https://semanticscholar.org/paper/8458fc0ecbc37aa30756cbc4c9d4d708475ccf58,,"Trustworthiness of Internet-based software systems, apps, services and platform is a key success factor for their use and acceptance by organizations and end-users. The notion of trustworthiness, though, is subject to individual interpretation and preference, e.g., organizations require confidence about how their business critical data is handled whereas end-users may be more concerned about usability. As one main contribution, we present an extensive list of software quality attributes that contribute to trustworthiness. Those software quality attributes have been identified by a systematic review of the research literature and by analyzing two real-world use cases. As a second contribution, we sketch an approach for systematically deriving metrics to measure the trustworthiness of software system. Our work thereby contributes to better understanding which software quality attributes should be considered and assured when engineering trustworthy Internet-based software systems.",,Systematic Review
Trustworthiness in Software Environments,"Health monitoring, string kernels, commercial tools, design considerations, and semantic exploitation are involved in establishing and monitoring system trustworthiness.",Search,2009,1,"John  Harauz, Jeffrey M. Voas, George F. Hurlburt",IT Professional,,10.1109/MITP.2009.111,https://doi.org/10.1109/MITP.2009.111,https://semanticscholar.org/paper/8c3ef9cbefe096f675c73a505c79f8553fc0269b,,"This article examines several approaches to establishing and monitoring system trustworthiness. In particular, we explore health monitoring, string kernels, available commercial tools, design considerations, and the semantic exploitation of environmental artifacts.",,
Trustworthiness in Peer-to-Peer Systems,The trustworthiness of an acquaintance peer in P2P systems is defined in terms of multiple parameters.,Search,2015,1,"Shota  Nakahira, Shigenari  Nakamura, Tomoya  Enokido, Makoto  Takizawa",2015 18th International Conference on Network-Based Information Systems,,10.1109/NBiS.2015.97,https://doi.org/10.1109/NBiS.2015.97,https://semanticscholar.org/paper/6172806552fe0d48132bf5e787e15741d4b6f807,,"A peer-to-peer (P2P) system is composed of peer processes (peers) interconnected in overlay networks. A peer has to communicate only with acquaintance peers due to the scalability and autonomy of the P2P system. A peer can collect information on objects distributed in P2P systems through communicating with the acquaintance peers. Peers may hold obsolete information and be faulty. Hence, a peer has to collect information from trustworthy acquaintance peers. The trustworthiness of an acquaintance peer is defined in terms of multiple parameters like response time and number of correct replies. It is difficult to obtain the trustworthiness due to the complex calculation of multiple parameter. In this paper, we discuss trustworthiness of an acquaintance peer in Fuzzy logics.",,
Trustworthiness Management in the Social Internet of Things,The integration of social networking concepts into the Internet of things has led to the Social Internet of Things (SIoT).,Search,2014,346,"Michele  Nitti, Roberto  Girau, Luigi  Atzori",IEEE Transactions on Knowledge and Data Engineering,,10.1109/TKDE.2013.105,https://doi.org/10.1109/TKDE.2013.105,https://semanticscholar.org/paper/5a97f384f7614848bcee66a5865bdd32dbf4e1ac,,"The integration of social networking concepts into the Internet of things has led to the Social Internet of Things (SIoT) paradigm, according to which objects are capable of establishing social relationships in an autonomous way with respect to their owners with the benefits of improving the network scalability in information/service discovery. Within this scenario, we focus on the problem of understanding how the information provided by members of the social IoT has to be processed so as to build a reliable system on the basis of the behavior of the objects. We define two models for trustworthiness management starting from the solutions proposed for P2P and social networks. In the subjective model each node computes the trustworthiness of its friends on the basis of its own experience and on the opinion of the friends in common with the potential service providers. In the objective model, the information about each node is distributed and stored making use of a distributed hash table structure so that any node can make use of the same information. Simulations show how the proposed models can effectively isolate almost any malicious nodes in the network at the expenses of an increase in the network traffic for feedback exchange.",,
Towards Trustworthy Kiosk Computing,"A personal mobile device can establish trust on a public computing device, or kiosk, prior to revealing personal information to that kiosk.",Search,2007,30,"Scott  Garriss, Romó  Sailer, Stefan  Berger, Reiner  Sailer, Leendert van Doorn, Xiaolan  Zhang",Eighth IEEE Workshop on Mobile Computing Systems and Applications,,10.1109/HotMobile.2007.14,https://doi.org/10.1109/HotMobile.2007.14,https://semanticscholar.org/paper/66dc7f3e6ea08ffcb45bb512e2302872cff4dbdf,,"We present a system in which a user leverages a personal mobile device to establish trust on a public computing device, or kiosk, prior to revealing personal information to that kiosk. We have designed and implemented a protocol by which the mobile device determines the identity and integrity of the software running on the kiosk. A similar protocol simultaneously allows a kiosk owner to verify that the kiosk is running only approved software. Our system combines a number of emerging security technologies, including the Trusted Platform Module, the Integrity Measurement Architecture, and new support in times86 processors for establishing a dynamic root of trust. In ongoing work, we plan to use virtual machines to support the important case where the user wishes to run personal software on the kiosk. We are also continuing to explore several open issues we have identified surrounding trust in a kiosk scenario.",,
Towards Trustworthy Kiosk Computing,"A mobile device establishes trust on a public computing device, or kiosk, prior to revealing personal information to that kiosk.",Search,2007,24,"Scott  Garriss, R.  Sailer, R.  Caceres, L. van Doorn, S.  Berger, Xiaolan  Zhang",,,10.1109/HOTMOBILE.2007.19,https://doi.org/10.1109/HOTMOBILE.2007.19,https://semanticscholar.org/paper/12c2f6bb84760a4e287db28773d858aee9c95cdf,,"We present a system in which a user leverages a personal mobile device to establish trust on a public computing device, or kiosk, prior to revealing personal information to that kiosk. We have designed and implemented a protocol by which the mobile device determines the identity and integrity of the software running on the kiosk. A similar protocol simultaneously allows a kiosk owner to verify that the kiosk is running only approved software. Our system combines a number of emerging security technologies, including the Trusted Platform Module, the Integrity Measurement Architecture, and new support in times86 processors for establishing a dynamic root of trust. In ongoing work, we plan to use virtual machines to support the important case where the user wishes to run personal software on the kiosk. We are also continuing to explore several open issues we have identified surrounding trust in a kiosk scenario.",,
Trustworthy AI in the Age of Pervasive Computing and Big Data,"Trust in AI is intrinsically linked to the ethics of algorithms, the ethics of data, or the ethics of practice.",Search,2020,15,"Abhishek  Kumar, Tristan  Braud, Sasu  Tarkoma, Pan  Hui",2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops),,10.1109/percomworkshops48775.2020.9156127,https://doi.org/10.1109/percomworkshops48775.2020.9156127,https://semanticscholar.org/paper/f92cedfdf08f7c92ddefebd06fa763d7a8359c1f,http://repository.ust.hk/ir/bitstream/1783.1-101388/1/neutral-ai.pdf,"The era of pervasive computing has resulted in countless devices that continuously monitor users and their environment, generating an abundance of user behavioural data. Such data may support improving the quality of service, but may also lead to adverse usages such as surveillance and advertisement. In parallel, Artificial Intelligence (AI) systems are being applied to sensitive fields such as healthcare, justice, or human resources, raising multiple concerns on the trustworthiness of such systems. Trust in AI systems is thus intrinsically linked to ethics, including the ethics of algorithms, the ethics of data, or the ethics of practice. In this paper, we formalise the requirements of trustworthy AI systems through an ethics perspective. We specifically focus on the aspects that can be integrated into the design and development of AI systems. After discussing the state of research and the remaining challenges, we show how a concrete use-case in smart cities can benefit from these methods.",,
Research and implementation of a role-based trustworthiness mechanism for IaaS,A role-based trustworthiness mechanism ensures that the different roles in an infrastructure as a service architecture are trusted.,Search,2012,2,"Xu  Wu, Xiaqing  Xie, Chunwen  Li",2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems,,10.1109/CCIS.2012.6664419,https://doi.org/10.1109/CCIS.2012.6664419,https://semanticscholar.org/paper/7e05580c91f040709ce7eea47d582c7aab727e23,,"Despite the advantages brought by cloud computing, security issues have emerged as one of the most significant barrier to faster and more widespread adoption of it. Therefore, this paper focused on the trustworthiness of infrastructure as a service (IaaS) and proposed a role-based trustworthiness mechanism to ensure that the different roles in IaaS architecture are trusted. What's more, this paper also considered the interactions between different roles in cloud environment and designed relevant validation protocols. Our experiments also show that this trustworthiness mechanism is practical in terms of performance.",,
A learning model for trustworthiness of context-awareness services,A context-awareness service needs some assurance that the information received is trustworthy.,Search,2005,19,"Markus C. Huebscher, Julie A. McCann",Third IEEE International Conference on Pervasive Computing and Communications Workshops,,10.1109/PERCOMW.2005.7,https://doi.org/10.1109/PERCOMW.2005.7,https://semanticscholar.org/paper/a074ba67aa510ff9bcbef7c82627d426f5b6e359,http://spiral.imperial.ac.uk/bitstream/10044/1/6024/1/Learningservices.pdf,"When ubiquitous computing devices access a context-awareness service, such as a location service, they need some assurance that the quality of the information received is trustworthy. However, the trustworthiness of a service cannot be determined by the service itself but must be decided externally to the service. Furthermore, the trustworthiness of a service provider may be dynamic, depending on current environmental conditions. We propose a learning model that uses binary positive/negative feedback from service consumers and cross-validation with other service providers to adjust the dynamic trustworthiness of a service provider.",,
An Efficient Attestation for Trustworthiness of Computing Platform,Remote attestation is a focus research in Trusted Computing.,Search,2006,26,"Xiaoyong  Li, Chang-xiang  Shen, Xiao-Dong  Zuo",2006 International Conference on Intelligent Information Hiding and Multimedia,,10.1109/IIH-MSP.2006.48,https://doi.org/10.1109/IIH-MSP.2006.48,https://semanticscholar.org/paper/1d95c96d9ecd36e1d70d1e264c84d73bbf685ef9,,"Remote attestation is a focus research in Trusted Computing. There are some attestation approaches suggested such as configuration based or property based attestation, but these suggestions have a few fatal deficiencies to overcome, e.g., leakage of platform configuration privacy or hard to define trustworthiness related properties, etc.. To solve these problems, this paper presents a system behavior based attestation model which try to determine the trust state of attesting platform from its system trustworthiness related behaviors. The new attestation model has advantages of privacy protection and high feasibility. In addition, system behavior based attestation can also be used to effectively constrain impacts caused by malicious code such as Trojan and virus which are common in today¿s organization business systems.",,
A subjective model for trustworthiness evaluation in the social Internet of Things,A node's trustworthiness is computed based on its own experience and the opinions of common friends with potential service providers.,Search,2012,147,"Michele  Nitti, Roberto  Girau, Luigi  Atzori, Antonio  Iera, Giacomo  Morabito","2012 IEEE 23rd International Symposium on Personal, Indoor and Mobile Radio Communications - (PIMRC)",,10.1109/pimrc.2012.6362662,https://doi.org/10.1109/pimrc.2012.6362662,https://semanticscholar.org/paper/03d32c3226b58feb3bcf0a2d0b24684220224e2e,https://iris.unica.it/bitstream/11584/105601/1/A%20Subjective%20Model%20for%20Trustworthiness%20Evaluation%20in%20the%20Social%20Internet%20of%20Things.pdf,"The integration of social networking concepts into the Internet of Things (IoT) has led to the so called Social Internet of Things (SIoT) paradigm, according to which the objects are capable of establishing social relationships in an autonomous way with respect to their owners. The benefits are those of improving scalability in information/service discovery when the SIoT is made of huge numbers of heterogeneous nodes, similarly to what happens with social networks among humans. In this paper we focus on the problem of understanding how the information provided by the other members of the SIoT has to be processed so as to build a reliable system on the basis of the behavior of the objects. We define a subjective model for the management of trustworthiness which builds upon the solutions proposed for P2P networks. Each node computes the trustworthiness of its friends on the basis of its own experience and on the opinion of the common friends with the potential service providers. We employ a feedback system and we combine the credibility and centrality of the nodes to evaluate the trust level. Preliminary simulations show the benefits of the proposed model towards the isolation of almost any malicious node in the network.",,
Software Behavior Based Trustworthiness Attestation For Computing Platform,A software behavior based attestation model can determine the trust state of an attesting platform from its system trust-related behaviors.,Search,2007,18,Shen  Chang-xiang,,,,,https://semanticscholar.org/paper/86535922063884a7c71a292afee462b38afdbceb,,"With a prevalence of pervasive computing, especially cloud computing , the software is at the core and play a vital role. This advance the security problem, so software trust is drawing increasing attention. Therefore, we need a unified trust relationship model between entities, which captures both the needs of the traditional computing world and the world of pervasive computing where the continuum of trust is based on identity, physical context or a combination of both. Here, we presents a software behavior based attestation model which try to determine the trust state of attesting platform from its system trust related behaviors. The new attestation model has advantages of privacy protection and high feasibility. In addition, it can also help to control and limit the impacts of security accidents such as malicious code in system. This paper also proposes a trust framework for service oriented application and displays its formalization model. It is useful for designing trust and reliable system and helpful for software developer's analysis and validation of the application. Index Terms—Trusted formal definition, Trusted computing, Software behavior, Trusted attestation",,