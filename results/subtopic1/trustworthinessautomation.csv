Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
Trustworthy Laboratory Automation,"Sustainability, trust, and authenticity can be ensured in laboratory automation by an automated digital signing process.",Search,2014,2,"Jan  Potthoff, Dominic  Lütjohann, Nicole  Jung",DBKDA 2014,,,,https://semanticscholar.org/paper/905488d862f4dcf4020d728c84b33a0b2f182cc5,,"To ensure the quality of scientific data, the integrity and authenticity of the data has to be guaranteed. Due to the significance of the primary data, the integrity and authenticity of research data have to be ensured with their generation. Special measurement devices offer this possibility by an automated digital signing process. Unfortunately, these devices are rare. Therefore, a generic software application which is shown in this paper has been implemented. Furthermore, the solution has been adjusted to an existing laboratory automation system which is depicted as well. The combination of a new, web-based Laboratory Information and Management System (LIMS) with a new protocol for an authentication of electronic data shows that the establishment of an automated collection of secure data can be realized even without disturbing the researcher. Keywords-integrity and authenticity; sustainability; trustworthy data generation; data management",,
Designing Trustworthy Automation,Safety-critical domains require appropriate calibration of operator trust in automation.,Search,2015,1,Arathi  Sethumadhavan,,,10.1177/1064804615609923,https://doi.org/10.1177/1064804615609923,https://semanticscholar.org/paper/a704b808e1d8db9ea36400f73f576bb1c73ed7a4,,"From self-learning thermostats to agricultural vehicles to baggagescreening systems, automation is becoming an integral part of modern life. In safety-critical domains, automation offers incredible benefits by improving the accuracy of complex tasks. Because automation failures are inevitable, appropriate calibration of operator trust in automation is integral for the optimal performance of human– automation teams. Trust in automation is affected by several factors, such as automation reliability, operator workload and selfconfidence, task difficulty and novelty, consequences of automation misses, and automation display format and content. Trust is therefore a multidimensional concept. So what can be done to appropriately calibrate operator trust level on automation?",,
Trust in Automation A Literature Review,Increasingly complex autonomous systems require the human operator to appropriately calibrate their trust in the automation.,Search,2018,7,"Bronwyn  French, Andreas  Duenser, Andrew  Heathcote",,,,,https://semanticscholar.org/paper/92f07d3d1356307decb6e97382ad884d0f62668d,,"Increasingly complex autonomous systems require the human operator to appropriately calibrate their trust in the automation in order to achieve performance and safety goals. Although humanautomation trust has been shown to be similar in many respects to human-human trust, precisely defining and measuring trust in automation has proved to be one of the greatest challenges facing research in this area. This report reviews literature pertaining to trust in automated systems to provide an integrated summary of the major theoretical and empirical work in the field to date.",,Review
Trust in Automation: Designing for Appropriate Reliance,People rely on automation appropriately if they trust in it.,Search,2004,1655,"John D. Lee, Katrina A. See",Hum. Factors,,10.1518/hfes.46.1.50.30392,https://doi.org/10.1518/hfes.46.1.50.30392,https://semanticscholar.org/paper/7dd86508438657ac7a704a5d952a2a4422808975,http://www.engineering.uiowa.edu/~csl/publications/pdf/leesee04.pdf,"Automation is often problematic because people fail to rely upon it appropriately. Because people respond to technology socially, trust influences reliance on automation. In particular, trust guides reliance when complexity and unanticipated situations make a complete understanding of the automation impractical. This review considers trust from the organizational, sociological, interpersonal, psychological, and neurological perspectives. It considers how the context, automation characteristics, and cognitive processes affect the appropriateness of trust. The context in which the automation is used influences automation performance and provides a goal-oriented perspective to assess automation characteristics along a dimension of attributional abstraction. These characteristics can influence trust through analytic, analogical, and affective processes. The challenges of extrapolating the concept of trust in people to trust in automation are discussed. A conceptual model integrates research regarding trust in automation and describes the dynamics of trust, the role of context, and the influence of display characteristics. Actual or potential applications of this research include improved designs of systems that require people to manage imperfect automation.",,Review
Trust in Automation: Designing for Appropriate Reliance,People rely on automation appropriately if they trust in it.,Search,2004,1361,"John D. Lee, Katrina A. See",,,10.1518/hfes.46.1.50_30392,https://doi.org/10.1518/hfes.46.1.50_30392,https://semanticscholar.org/paper/da7118242082ff14ee89cac4df938bc470c3bfd9,https://journals.sagepub.com/doi/pdf/10.1518/hfes.46.1.50_30392,"Automation is often problematic because people fail to rely upon it appropriately. Because people respond to technology socially, trust influences reliance on automation. In particular, trust guides reliance when complexity and unanticipated situations make a complete understanding of the automation impractical. This review considers trust from the organizational, sociological, interpersonal, psychological, and neurological perspectives. It considers how the context, automation characteristics, and cognitive processes affect the appropriateness of trust. The context in which the automation is used influences automation performance and provides a goal-oriented perspective to assess automation characteristics along a dimension of attributional abstraction. These characteristics can influence trust through analytic, analogical, and affective processes. The challenges of extrapolating the concept of trust in people to trust in automation are discussed. A conceptual model integrates research regarding trust in automation and describes the dynamics of trust, the role of context, and the influence of display characteristics. Actual or potential applications of this research include improved designs of systems that require people to manage imperfect automation.",,Review
Trust in Automation,"dispositional trust, situational trust, and learned trust.",Search,2015,751,"Kevin  Hoff, Masooda  Bashir",Human factors,,10.1177/0018720814547570,https://doi.org/10.1177/0018720814547570,https://semanticscholar.org/paper/95d66e12bb9116c3e98c7d422decd6b5c74769dc,,"Objective: We systematically review recent empirical research on factors that influence trust in automation to present a three-layered trust model that synthesizes existing knowledge. Background: Much of the existing research on factors that guide human-automation interaction is centered around trust, a variable that often determines the willingness of human operators to rely on automation. Studies have utilized a variety of different automated systems in diverse experimental paradigms to identify factors that impact operators’ trust. Method: We performed a systematic review of empirical research on trust in automation from January 2002 to June 2013. Papers were deemed eligible only if they reported the results of a human-subjects experiment in which humans interacted with an automated system in order to achieve a goal. Additionally, a relationship between trust (or a trust-related behavior) and another variable had to be measured. All together, 101 total papers, containing 127 eligible studies, were included in the review. Results: Our analysis revealed three layers of variability in human–automation trust (dispositional trust, situational trust, and learned trust), which we organize into a model. We propose design recommendations for creating trustworthy automation and identify environmental conditions that can affect the strength of the relationship between trust and reliance. Future research directions are also discussed for each layer of trust. Conclusion: Our three-layered trust model provides a new lens for conceptualizing the variability of trust in automation. Its structure can be applied to help guide future research and develop training interventions and design procedures that encourage appropriate trust.",,Systematic Review
Trust4App: Automating Trustworthiness Assessment of Mobile Applications,"Smartphones need to access and utilize potentially sensitive data, which can pose a serious threat to users' security and privacy.",Search,2018,6,"Sheikh Mahbub Habib, Nikolaos  Alexopoulos, Md Monirul Islam, Jens  Heider, Stephen  Marsh, Max  Mühlhäuser","2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)",,10.1109/TrustCom/BigDataSE.2018.00029,https://doi.org/10.1109/TrustCom/BigDataSE.2018.00029,https://semanticscholar.org/paper/803c71fb7f234f3772aac69337e6f29d56247311,,"Smartphones have become ubiquitous in our everyday lives, providing diverse functionalities via millions of applications (apps) that are readily available. To achieve these functionalities, apps need to access and utilize potentially sensitive data, stored in the user's device. This can pose a serious threat to users' security and privacy, when considering malicious or underskilled developers. While application marketplaces, like Google Play store and Apple App store, provide factors like ratings, user reviews, and number of downloads to distinguish benign from risky apps, studies have shown that these metrics are not adequately effective. The security and privacy health of an application should also be considered to generate a more reliable and transparent trustworthiness score. In order to automate the trustworthiness assessment of mobile applications, we introduce the Trust4App framework, which not only considers the publicly available factors mentioned above, but also takes into account the Security and Privacy (S&P) health of an application. Additionally, it considers the S&P posture of a user, and provides an holistic personalized trustworthiness score. While existing automatic trustworthiness frameworks only consider trustworthiness indicators (e.g. permission usage, privacy leaks) individually, Trust4App is, to the best of our knowledge, the first framework to combine these indicators. We also implement a proof-of-concept realization of our framework and demonstrate that Trust4App provides a more comprehensive, intuitive and actionable trustworthiness assessment compared to existing approaches.",,Review
The role of trust in automation reliance,"Viewing an automated aid make errors decreases trust in the aid, unless an explanation is provided regarding why the aid might err.",Search,2003,783,"Mary T. Dzindolet, Scott A. Peterson, Regina A. Pomranky, Linda G. Pierce, Hall P. Beck",Int. J. Hum. Comput. Stud.,,10.1016/S1071-5819(03)00038-7,https://doi.org/10.1016/S1071-5819(03)00038-7,https://semanticscholar.org/paper/b0e89da3eb67767b63ca5c23c233238f70263ae7,,"A recent and dramatic increase in the use of automation has not yielded comparable improvements in performance. Researchers have found human operators often underutilize (disuse) and overly rely on (misuse) automated aids (Parasuraman and Riley, 1997). Three studies were performed with Cameron University students to explore the relationship among automation reliability, trust, and reliance. With the assistance of an automated decision aid, participants viewed slides of Fort Sill terrain and indicated the presence or absence of a camouflaged soldier. Results from the three studies indicate that trust is an important factor in understanding automation reliance decisions. Participants initially considered the automated decision aid trustworthy and reliable. After observing the automated aid make errors, participants distrusted even reliable aids, unless an explanation was provided regarding why the aid might err. Knowing why the aid might err increased trust in the decision aid and increased automation reliance, even when the trust was unwarranted. Our studies suggest a need for future research focused on understanding automation use, examining individual differences in automation reliance, and developing valid and reliable self-report measures of trust in automation.",,
Automata-based trustworthiness analysis method for business process,A business process definition method requires a dynamic semantics to enhance the trustworthiness of business processes.,Search,2011,,"Guangzhi  Dong, Junfei  Liu, Jian  Wang, Lanying  Song",2011 International Conference on E-Business and E-Government (ICEE),,10.1109/ICEBEG.2011.5886798,https://doi.org/10.1109/ICEBEG.2011.5886798,https://semanticscholar.org/paper/952084254357de6418c616acc979e625b95b965f,,"For enhancing the trustworthiness of business processes, a business process definition method is given and a kind of dynamic semantics is appointed to this business process definition. The dynamic semantics is expressed as a finite state automata. According to the dynamic semantics, algorithms are proposed to analyze the trustworthiness of the business processes.",,
Automated Trustworthiness Management for Database Software Components,Component trust management functions can monitor the trustworthy operation of components.,Search,2007,1,"Reijo  Savola, Jorma  Palo",2007 4th IEEE Consumer Communications and Networking Conference,,10.1109/CCNC.2007.242,https://doi.org/10.1109/CCNC.2007.242,https://semanticscholar.org/paper/59d06e83f326234d4ca4ca27f7656d79358e7984,,"Component-based software architectures are being used more and more often in industry, creating new kinds of dynamic business relationships between the integrators and their partners in developing the components. In this kind of business it is especially important to ensure that both the components and the co-operation partners are trustworthy. One method of component trust management is to include in the software architecture functions that take care of loading and updating the components, and monitor their trustworthy operation. We introduce a novel trust management framework for the middleware layer and demonstrate its functionality using embedded software components. We explain the functionality of our trust management system and demonstrate its application in managing software components and utilizing database services for both management of component properties and delivery of new components from trusted sources.",,
Trusting Automation: Designing for Responsivity and Resilience.,Automation responsivity and the ability to resolve conflicting goals may be more relevant than reliability and reliance for advancing system design.,Search,2021,8,"Erin K Chiou, John D Lee",Human factors,,10.1177/00187208211009995,https://doi.org/10.1177/00187208211009995,https://semanticscholar.org/paper/9f7511fb851d5cdafbfdf61de06acb09e3a4b2c7,,"OBJECTIVE

This paper reviews recent articles related to human trust in automation to guide research and design for increasingly capable automation in complex work environments.

BACKGROUND

Two recent trends-the development of increasingly capable automation and the flattening of organizational hierarchies-suggest a reframing of trust in automation is needed.

METHOD

Many publications related to human trust and human-automation interaction were integrated in this narrative literature review.

RESULTS

Much research has focused on calibrating human trust to promote appropriate reliance on automation. This approach neglects relational aspects of increasingly capable automation and system-level outcomes, such as cooperation and resilience. To address these limitations, we adopt a relational framing of trust based on the decision situation, semiotics, interaction sequence, and strategy. This relational framework stresses that the goal is not to maximize trust, or to even calibrate trust, but to support a process of trusting through automation responsivity.

CONCLUSION

This framing clarifies why future work on trust in automation should consider not just individual characteristics and how automation influences people, but also how people can influence automation and how interdependent interactions affect trusting automation. In these new technological and organizational contexts that shift human operators to co-operators of automation, automation responsivity and the ability to resolve conflicting goals may be more relevant than reliability and reliance for advancing system design.

APPLICATION

A conceptual model comprising four concepts-situation, semiotics, strategy, and sequence-can guide future trust research and design for automation responsivity and more resilient human-automation systems.",,Review
Automating the Evaluation of Trustworthiness,A potential trustor can use an implementation to evaluate the potential trustee's trustworthiness.,Search,2021,,"Marc  Sel, Chris J. Mitchell",TrustBus,,10.1007/978-3-030-86586-3_2,https://doi.org/10.1007/978-3-030-86586-3_2,https://semanticscholar.org/paper/89b871acca977719e6c49f8f7720af7edfef85f0,,"Digital services have a significant impact on the lives of many people and organisations. Trust influences decisions regarding potential service providers, and continues to do so once a service provider has been selected. There is no globally accepted model to describe trust in the context of digital services, nor to evaluate the trustworthiness of entities. We present a formal framework to partially fill this gap. It is based on four building blocks: a data model, rulebooks, trustworthiness evaluation functions and instance data. An implementation of this framework can be used by a potential trustor to evaluate the trustworthiness of a potential trustee.",,
Trustworthy Human-Centered Automation Through Explainable AI and High-Fidelity Simulation,Developing explainable AI and high-fidelity simulation enables shared expectations between autonomous systems and humans.,Search,2020,2,"Bradley  Hayes, Michael  Moniz",AHFE,,10.1007/978-3-030-51064-0_1,https://doi.org/10.1007/978-3-030-51064-0_1,https://semanticscholar.org/paper/d59e02b072628ce304e154d12804ffcc9f18d4de,,"As we become more competent developers of artificially intelligent systems, the level of deployment and associated implicit trust in these systems will increase in kind. While this is an attractive concept, with an already-demonstrated capability to positively disrupt industries around the world, it remains a dangerous premise that demands attention and intentional resource allocation to ensure that these systems’ behaviors match our expectations. Until we can develop explainable AI techniques or high-fidelity simulators to enable us to examine the models’ underlying logic for the situations we intend to utilize them in, it will be irresponsible to place our trust in their ability to act on our behalf. In this work we describe and provide guidelines for ongoing efforts in using novel explainable AI techniques and high-fidelity simulation to help establish shared expectations between autonomous systems and the humans who interact with them, discussing collaborative robotics and cybersecurity domains.",,
Trustworthiness of Autonomous Systems,Transdisciplinary research is needed to design trustworthy autonomous systems.,Search,2018,17,S. Kate Devitt,CDC 2018,,10.1007/978-3-319-64816-3_9,https://doi.org/10.1007/978-3-319-64816-3_9,https://semanticscholar.org/paper/d84e786286b6afa167ca016a01cf0d8e408df76e,https://link.springer.com/content/pdf/10.1007%2F978-3-319-64816-3_9.pdf,"Effective robots and autonomous systems must be trustworthy. This chapter examines models of trustworthiness from a philosophical and empirical perspective to inform the design and adoption of autonomous systems. Trustworthiness is a property of trusted agents or organisations that engenders trust in other agent or organisations. Trust is a complex phenomena defined differently depending on the discipline. This chapter aims to bring different approaches under a single framework for investigation with three sorts of questions: Who or what is trustworthy? –metaphysics. How do we know who or what is trustworthy? –epistemology. What factors influence what or who should we trust? –normativity. A two-component model of trust is used that incorporates competence (skills, reliability and experience) and integrity (motives, honesty and character). It is supposed that human levels of competence yield the highest trust whereas trust is reduced at sub-human and super-human levels. The threshold for trustworthiness of an agent or organisation in a particular context is a function of their relationship with the truster and potential impacts of decisions. Building trustworthy autonomous systems requires obeying the norms of logic, rationality and ethics under pragmatic constraints–even though there is disagreement on these principles by experts. Autonomous systems may need sophisticated social identities including empathy and reputational concerns to build human-like trust relationships. Ultimately transdisciplinary research drawing on metaphysical, epistemological and normative human and machine theories of trust are needed to design trustworthy autonomous systems for adoption.",,
Trust and Automation in Verification Tools,Verification tools can be both trusted and automated.,Search,2008,23,Natarajan  Shankar,ATVA,,10.1007/978-3-540-88387-6_3,https://doi.org/10.1007/978-3-540-88387-6_3,https://semanticscholar.org/paper/a11f03fc879aac7dd7a127a622b76e555431300c,,"On the one hand, we would like verification tools to feature powerful automation, but on the other hand, we also want to be able to trust the results with a high degree of confidence. The question of trust in verification tools has been debated for a long time. One popular way of achieving trust in verification tools is through proof generation. However, proof generation could hamstring both the functionality and the efficiency of the automation that can be built into these tools. We argue that trust need not be achieved at the expense of automation, and outline a lightweight approach where the results of untrusted verifiers are checked by a trusted offline checker. The trusted checker is a verified reference kernel that contains a satisfiability solver to support the robust and efficient checking of untrusted tools.",,
Trustworthy AI,The pursuit of responsible AI raises the ante on both the trustworthy computing and formal methods communities.,Search,2021,7,Jeannette M. Wing,Commun. ACM,,10.1145/3448248,https://doi.org/10.1145/3448248,https://semanticscholar.org/paper/33cf9b4d6c76f988380b1adff2c06c30010f93d3,https://dl.acm.org/doi/pdf/10.1145/3448248,The pursuit of responsible AI raises the ante on both the trustworthy computing and formal methods communities.,,
Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence,An automatic online assessment method for the reliability of CPS was proposed to carry out online analysis and assessment.,Search,2021,81,"Zhihan  Lv, Yang  Han, Amit Kumar Singh, Gunasekaran  Manogaran, Haibin  Lv",IEEE Transactions on Industrial Informatics,,10.1109/TII.2020.2994747,https://doi.org/10.1109/TII.2020.2994747,https://semanticscholar.org/paper/79086f67c5d7413a05305478b1b38781588ed19d,,"The intelligent industrial environment developed with the support of the new generation network cyber-physical system (CPS) can realize the high concentration of information resources. In order to carry out the analysis and quantification for the reliability of CPS, an automatic online assessment method for the reliability of CPS is proposed in this article. It builds an evaluation framework based on the knowledge of machine learning, designs an online rank algorithm, and realizes the online analysis and assessment in real time. The preventive measures can be taken timely, and the system can operate normally and continuously. Its reliability has been greatly improved. Based on the credibility of the Internet and the Internet of Things, a typical CPS control model based on the spatiotemporal correlation detection model is analyzed to determine the comprehensive reliability model analysis strategy. Based on this, in this article, we propose a CPS trusted robust intelligent control strategy and a trusted intelligent prediction model. Through the simulation analysis, the influential factors of attack defense resources and the dynamic process of distributed cooperative control are obtained. CPS defenders in the distributed cooperative control mode can be guided and select the appropriate defense resource input according to the CPS attack and defense environment.",,
Requirements for Trustworthy Artificial Intelligence - A Review,"The field of algorithmic decision-making, particularly Artificial Intelligence (AI), has been drastically changing.",Search,2020,8,"Davinder  Kaur, Suleyman  Uslu, Arjan  Durresi",NBiS,,10.1007/978-3-030-57811-4_11,https://doi.org/10.1007/978-3-030-57811-4_11,https://semanticscholar.org/paper/ab7f6628cbbafae1ce994929af2482efbd092d61,https://scholarworks.iupui.edu/bitstream/1805/28055/1/Kaur2020Requirements-AAM.pdf,"The field of algorithmic decision-making, particularly Artificial Intelligence (AI), has been drastically changing. With the availability of a massive amount of data and an increase in the processing power, AI systems have been used in a vast number of high-stake applications. So, it becomes vital to make these systems reliable and trustworthy. Different approaches have been proposed to make theses systems trustworthy. In this paper, we have reviewed these approaches and summarized them based on the principles proposed by the European Union for trustworthy AI. This review provides an overview of different principles that are important to make AI trustworthy.",,Review
Trustworthiness Management in the Social Internet of Things,The integration of social networking concepts into the Internet of things has led to the Social Internet of Things (SIoT).,Search,2014,346,"Michele  Nitti, Roberto  Girau, Luigi  Atzori",IEEE Transactions on Knowledge and Data Engineering,,10.1109/TKDE.2013.105,https://doi.org/10.1109/TKDE.2013.105,https://semanticscholar.org/paper/5a97f384f7614848bcee66a5865bdd32dbf4e1ac,,"The integration of social networking concepts into the Internet of things has led to the Social Internet of Things (SIoT) paradigm, according to which objects are capable of establishing social relationships in an autonomous way with respect to their owners with the benefits of improving the network scalability in information/service discovery. Within this scenario, we focus on the problem of understanding how the information provided by members of the social IoT has to be processed so as to build a reliable system on the basis of the behavior of the objects. We define two models for trustworthiness management starting from the solutions proposed for P2P and social networks. In the subjective model each node computes the trustworthiness of its friends on the basis of its own experience and on the opinion of the friends in common with the potential service providers. In the objective model, the information about each node is distributed and stored making use of a distributed hash table structure so that any node can make use of the same information. Simulations show how the proposed models can effectively isolate almost any malicious nodes in the network at the expenses of an increase in the network traffic for feedback exchange.",,
Research and implementation of a role-based trustworthiness mechanism for IaaS,A role-based trustworthiness mechanism can ensure that the different roles in an infrastructure as a service architecture are trusted.,Search,2012,2,"Xu  Wu, Xiaqing  Xie, Chunwen  Li",2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems,,10.1109/CCIS.2012.6664419,https://doi.org/10.1109/CCIS.2012.6664419,https://semanticscholar.org/paper/7e05580c91f040709ce7eea47d582c7aab727e23,,"Despite the advantages brought by cloud computing, security issues have emerged as one of the most significant barrier to faster and more widespread adoption of it. Therefore, this paper focused on the trustworthiness of infrastructure as a service (IaaS) and proposed a role-based trustworthiness mechanism to ensure that the different roles in IaaS architecture are trusted. What's more, this paper also considered the interactions between different roles in cloud environment and designed relevant validation protocols. Our experiments also show that this trustworthiness mechanism is practical in terms of performance.",,
Managing Trustworthiness in Component-based Embedded Systems,Trustworthiness evaluation is a Trustors-parameterisable function.,Search,2007,29,"Gabriele  Lenzini, Andrew  Tokmakoff, Johan  Muskens",Electron. Notes Theor. Comput. Sci.,,10.1016/j.entcs.2006.08.038,https://doi.org/10.1016/j.entcs.2006.08.038,https://semanticscholar.org/paper/6a7e0690ac420b9dfab79f0dae9d1a852afdce45,,"Component-based systems use software components to achieve their overall high-level functionality which, in turn, may be extended by initiating the download of new components. This action may detrimentally affect the system's overall dependability and security characteristics. We address the problem of the enhancement of dependability and security for component-based embedded systems that run, for example, in consumer and embedded electronics devices. We propose a Trustworthiness Management Framework which, while acting on the behalf of components (Trustors), supervises the system's existing Trustor-Trustee relationships and preserves the overall system level of dependability and security. This is achieved by monitoring quality metrics on the components behaviours, by periodically evaluating their trustworthiness, and (when applicable) by controlling them. This paper focuses on the trustworthiness evaluation process offered by the Trustworthiness Management Framework. Trustworthiness evaluation is seen as a Trustors-parameterisable function. Trustworthiness is expressed with a triple of values: compliance, benignity and stability. The first measures the degree to which a component satisfies the Trustor's requirement; the second and third express the expected belief that, resp. , the components will continue to be compliant and the component's behavioural qualities will remain stable. Trustworthiness is used by the Trustworthiness Manager Framework to make control decisions to regulate the system's overall dependability and security characteristics. Keywords: component-based systems, trustworthiness evaluation, trustworthiness management architecture, dependability and security.",,
Compliance based Trustworthiness Calculation Mechanism in Cloud Environment,A compliance-based trustworthiness calculation mechanism can be used to evaluate the trustworthiness of service providers in a cloud environment.,Search,2014,18,"Jagpreet  Sidhu, Sarbjeet  Singh",EUSPN/ICTH,,10.1016/j.procs.2014.08.066,https://doi.org/10.1016/j.procs.2014.08.066,https://semanticscholar.org/paper/b90868ba4f692fca7d733917f94a3d73435dc03f,,"Establishing trust is one of the most challenging issues in emerging cloud computing area. It is becoming increasingly complex for cloud users to make distinction (with respect to trustworthiness) among service providers offering similar kinds of services. There must be some mechanisms in the hands of users to determine trustworthiness of service providers so that they can select service providers with confidence and with some degree of assurance that service provider will not behave unpredictably or maliciously. Though various approaches exist to form trust between service providers and users, little work has been done in the area of forming trust based on compliance of QoS parameters which have been promised in SLA. In this paper an attempt has been made to design and simulate a mechanism to calculate trustworthiness of service providers based on their compliance to promised SLA parameters. The model has been simulated in MATLAB. The validation has been done using synthetic data set. Validation results show that approach is workable and can be used to evaluate trustworthiness of service providers in a cloud environment.",,
Trustworthiness Attributes and Metrics for Engineering Trusted Internet-Based Software Systems,"Trustworthiness, though, is subject to individual interpretation and preference.",Search,2013,35,"Nazila Gol Mohammadi, Sachar  Paulus, Mohamed  Bishr, Andreas  Metzger, Holger  Könnecke, Sandro  Hartenstein, Thorsten  Weyer, Klaus  Pohl",CLOSER,,10.1007/978-3-319-11561-0_2,https://doi.org/10.1007/978-3-319-11561-0_2,https://semanticscholar.org/paper/8458fc0ecbc37aa30756cbc4c9d4d708475ccf58,,"Trustworthiness of Internet-based software systems, apps, services and platform is a key success factor for their use and acceptance by organizations and end-users. The notion of trustworthiness, though, is subject to individual interpretation and preference, e.g., organizations require confidence about how their business critical data is handled whereas end-users may be more concerned about usability. As one main contribution, we present an extensive list of software quality attributes that contribute to trustworthiness. Those software quality attributes have been identified by a systematic review of the research literature and by analyzing two real-world use cases. As a second contribution, we sketch an approach for systematically deriving metrics to measure the trustworthiness of software system. Our work thereby contributes to better understanding which software quality attributes should be considered and assured when engineering trustworthy Internet-based software systems.",,Systematic Review
"Trustworthiness in IoT – A Standards Gap Analysis on Security, Data Protection and Privacy","The goal of research and standardisation for security, privacy, and data protection in IoT is to establish a solid technical and regulatory foundation.",Search,2019,5,"Nader S. Labib, Matthias R. Brust, Grégoire  Danoy, Pascal  Bouvry",2019 IEEE Conference on Standards for Communications and Networking (CSCN),,10.1109/CSCN.2019.8931393,https://doi.org/10.1109/CSCN.2019.8931393,https://semanticscholar.org/paper/99b094558854fa4e1b3ab573c987a938fe9daf86,,"With the emergence of new digital trends like Internet of Things (IoT), more industry actors and technical committees pursue research in utilising such technologies as they promise a better and optimised management, improved energy efficiency and a better quality living through a wide array of value-added services. However, as sensing, actuation, communication and control become increasingly more sophisticated, such promising data-driven systems generate, process, and exchange larger amounts of security-critical and privacy-sensitive data, which makes them attractive targets of attacks. In turn this affirms the importance of trustworthiness in IoT and emphasises the need of a solid technical and regulatory foundation. The goal of this paper is to first introduce the concept of trustworthiness in IoT, its main pillars namely, security, privacy and data protection, and then analyse the state-of-the-art in research and standardisation for each of these subareas. Throughout the paper, we develop and refer to Unmanned Aerial Vehicles (UAVs) as a promising value-added service example of mobile IoT devices. The paper then presents a thorough gap analysis and concludes with recommendations for future work.",,