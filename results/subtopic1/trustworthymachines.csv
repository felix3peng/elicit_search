Paper title,Takeaway from abstract,Source,Year,Citations,Authors,Journal,Influential citations,DOI,DOI URL,Semantic Scholar URL,PDF,Abstract,Takeaway suggests yes/no,Study type
"Trustworthy Machine Learning: Past, Present, and Future","Machine-learning algorithms, especially deep neural networks, are being used in diverse domains where trustworthiness is a concern.",Search,2021,,Somesh  Jha,AsiaCCS,,10.1145/3433210.3460015,https://doi.org/10.1145/3433210.3460015,https://semanticscholar.org/paper/dc61605f0b7feb3f560118dbd280e5a6f4a4c939,,"Fueled by massive amounts of data, models produced by machine-learning (ML) algorithms, especially deep neural networks (DNNs), are being used in diverse domains where trustworthiness is a concern, including automotive systems, finance, healthcare, natural language processing, and malware detection. Of particular concern is the use of ML algorithms in cyber-physical systems (CPS), such as self-driving cars and aviation, where an adversary can cause serious consequences. Interest in this area of research has simply exploded. In this work, we will cover the state-of-the-art in trustworthy machine learning, and then cover some interesting future trends.",,
Can We Trust Machines? The Role of Trust in Technological Environments,Machines can be trusted on terms they are trustworthy.,Search,2020,2,Adriano  Fabris,"Studies in Applied Philosophy, Epistemology and Rational Ethics",,10.1007/978-3-030-44018-3_9,https://doi.org/10.1007/978-3-030-44018-3_9,https://semanticscholar.org/paper/b7415a498fcd03b654d1312d37a8421966d32406,,"In this paper, I will deal with trust in technological devices. Nowadays, we are led to trust AI machines, extending the notion of “trust” to our relationship with such devices. After reviewing different forms of trust and showing that trust is inextricably linked with a sort of fear, this paper will try to relate all this to the ethical judgement we can form about what machines “do” as well as about the machines themselves. Prompted by this, the paper will discuss the case of a recent attempt made by the EU at working out ethical guidelines for a trustworthy AI. To conclude, it will try to answer the above question—can we trust machines? –and accurately define on what terms they can be trusted.",,Review
Technologies for Trustworthy Machine Learning: A Survey in a Socio-Technical Context,"Technologies that support building trustworthy machine learning systems require knowledge in fair, explainable, auditable, and safe & secure properties.",Search,2020,3,"Ehsan  Toreini, Mhairi  Aitken, Kovila P. L. Coopamootoo, Karen  Elliott, Vladimiro  González-Zelaya, Paolo  Missier, Magdalene  Ng, Aad van Moorsel",ArXiv,,,,https://semanticscholar.org/paper/5f34f91329e15d855fe9e08069c4c556c3e66f7f,,"Concerns about the societal impact of AI-based services and systems has encouraged governments and other organisations around the world to propose AI policy frameworks to address fairness, accountability, transparency and related topics. To achieve the objectives of these frameworks, the data and software engineers who build machine-learning systems require knowledge about a variety of relevant supporting tools and techniques. In this paper we provide an overview of technologies that support building trustworthy machine learning systems, i.e., systems whose properties justify that people place trust in them. We argue that four categories of system properties are instrumental in achieving the policy objectives, namely fairness, explainability, auditability and safety & security (FEAS). We discuss how these properties need to be considered across all stages of the machine learning life cycle, from data collection through run-time model inference. As a consequence, we survey in this paper the main technologies with respect to all four of the FEAS properties, for data-centric as well as model-centric stages of the machine learning system life cycle. We conclude with an identification of open research problems, with a particular focus on the connection between trustworthy machine learning technologies and their implications for individuals and society.",,Review
Machine to Machine Trust in the IoT Era,(1) pairwise similarity based feedback credibility and (2) threshold-controlled trust propagation.,Search,2016,17,"Ling  Liu, Margaret  Loper, Yusuf  Özkaya, Abdurrahman  Yasar, Emre  Yigitoglu",TRUST@AAMAS,,,,https://semanticscholar.org/paper/73aed4bdace4a7fe4248df78a0f0d3f97c043469,,"Machine to machine communications are at the center stage of the Internet of things (IoT). Connecting the physical world with the digital world not only creates new opportunities for innovation and discovery, but also opens doors for misuse and abuse. This paper argues that reputation based trust can be an effective countermeasure for securing machine-to-machine communications. We propose to establish machine-to-machine trust by taking into account both transaction/interaction service behaviors and feedback rating behaviors in the presence of bogus transactions and dishonest feedbacks. Our machine-to-machine trust model, called M2MTrust, introduces two novel trust metrics: (1) pairwise similarity based feedback credibility and (2) threshold-controlled trust propagation. We compute the direct trust from machine A to machine B by utilizing their pairwise rating similarity as the weight to the normalized aggregate of ratings that A has given to B. Our direct trust computation model can effectively constrain malicious nodes to gain direct trusts from dishonest feedback ratings by leveraging feedback credibility. Furthermore, our threshold-controlled trust propagation mechanism can successfully block the trust propagation from good nodes to malicious nodes. We conduct extensive experiments using simulation and real datasets and the experimental results show that M2MTrust significantly outperforms other trust metrics in terms of both attack resilience and performance in the presence of dishonest feedbacks and sparse feedback ratings against four representative attack models.",,
Trust in social machines: the challenges,The notions of trust often used in social machines research are imported from agent-based computing.,Search,2012,14,Kieron  O'Hara,,,,,https://semanticscholar.org/paper/68fb0224d56458915a291dde069fb16a606a8da2,,"The World Wide Web has ushered in a new generation of applications constructively linking people and computers to create what have been called ‘social machines.’ The ‘components’ of these machines are people and technologies. It has long been recognised that for people to participate in social machines, they have to trust the processes. However, the notions of trust often used tend to be imported from agent-based computing, and may be too formal, objective and selective to describe human trust accurately. This paper applies a theory of human trust to social machines research, and sets out some of the challenges to system designers.",,
Processor Architecture for Trustworthy Computers,"Computer architects need to design more trustworthy computers that protect a user’s information, computations and communications from attacks by malicious adversaries.",Search,2005,,Ruby B. Lee,Asia-Pacific Computer Systems Architecture Conference,,10.1007/11572961_1,https://doi.org/10.1007/11572961_1,https://semanticscholar.org/paper/9cc4b3082377ac27f268849e78eb09118971abb7,,"We propose that computer architects need to design more trustworthy computers that protect a user’s information, computations and communications from attacks by malicious adversaries. This is in addition to providing current engineering goals of higher performance, lower cost, lower power consumption and smaller footprint.",,
Trustworthy Voting: From Machine to System,"The electronic voting approach incorporates a trustworthy process, simplified procedures, and built-in redundant safeguards that prevent tampering.",Search,2009,28,"Nathanael  Paul, Andrew S. Tanenbaum",Computer,,10.1109/MC.2009.169,https://doi.org/10.1109/MC.2009.169,https://semanticscholar.org/paper/dd75b2fcb8b5117acc2121a47ac74eee9a87303b,,"The authors describe an electronic voting approach that takes a system view, incorporating a trustworthy process based on open source software, simplified procedures, and built-in redundant safeguards that prevent tampering.",,
Trusting your computer to be trusted,The Trusted Computing Group aims to make sure a computer is working to a specified expectation of behavior.,Search,2005,4,Stephen  Mason,,,10.1016/S1361-3723(05)00146-6,https://doi.org/10.1016/S1361-3723(05)00146-6,https://semanticscholar.org/paper/6305a869d0c79b38d4ee7214d7cf9b50a72e8c95,,"The spread of ‘trust’ is unstoppable… The Trusted Computing Group is a movement from the most formidable software and hardware manufacturers in the world to develop an architecture that would improve the underlying security of computers. The Trusted Computing Group aims to make sure a computer is working to a specified expectation of behaviour. This would apply to the problem of malicious code, for example. Malicious code makes a computer behave differently to the expected normality so cannot be hidden. The measurement of such changes in behaviour is done by a Trusted Platform Module, which is implicity trusted and is the core of the trusted computing architecture. Sound too good to be true? Some commentators believe these security benefits could come at a price, which may include digital rights management or privacy compromise. Stephen Mason believes that the implications of Trusted Computing are profound and there are serious concerns, which must be addressed before the technology become ubiquitous, which it is well on the way to becoming. It is axiomatic that computers are not to be trusted. As a tool, they are capable of improving our lives. However, beneficial as computers may be, they are also unsafe. The dangers are obvious, although what you consider is a threat will depend on your perspective. Application software vendors do not always receive licence fees for all of their software running on every computer. Users have to buy anti-virus solutions to protect their computers from attack by malicious code. Owners of secrets have to take precautions to prevent the unauthorized use or theft of sensitive data. Musicians, actresses and authors want to be properly remunerated for their creativity. The range of problems associated with the misuse of computers is manifest, and once a computer is linked into a network, the risks increase considerably.",,
Trustworthy AI,The pursuit of responsible AI raises the ante on both the trustworthy computing and formal methods communities.,Search,2021,7,Jeannette M. Wing,Commun. ACM,,10.1145/3448248,https://doi.org/10.1145/3448248,https://semanticscholar.org/paper/33cf9b4d6c76f988380b1adff2c06c30010f93d3,https://dl.acm.org/doi/pdf/10.1145/3448248,The pursuit of responsible AI raises the ante on both the trustworthy computing and formal methods communities.,,
The road to trustworthy systems,"Computer systems are routinely deployed in life- and mission-critical situations, yet their safety, security or dependability can in most cases not be assured to the degree warranted by the application.",Search,2010,14,"Gernot  Heiser, June  Andronick, Kevin  Elphinstone, Gerwin  Klein, Ihor  Kuz, Leonid  Ryzhyk",STC '10,,10.1145/1867635.1867638,https://doi.org/10.1145/1867635.1867638,https://semanticscholar.org/paper/5fc3fcbe1c14473acfcf28cff29064076a16f5d3,,"Computer systems are routinely deployed in life- and mission-critical situations, yet their security, safety or dependability can in most cases not be assured to the degree warranted by the application. In other words, trusted computer systems are rarely really trustworthy.

We believe that this is highly unsatisfactory, and have embarked on a large research program aimed at bringing reality in line with expectations. In this paper we describe NICTA's research agenda for achieving true trustworthiness in systems. We report on what has been achieved to date, and what our plans are for the next 3-5 years.",,
Trustworthy and personalized computing on public kiosks,Personalized kiosks can be established with a delay to increase the trust in data privacy.,Search,2008,105,"Scott  Garriss, Ramón  Cáceres, Stefan  Berger, Reiner  Sailer, Leendert van Doorn, Xiaolan  Zhang",MobiSys '08,,10.1145/1378600.1378623,https://doi.org/10.1145/1378600.1378623,https://semanticscholar.org/paper/beafabdbd7df228bbdd2a3bb5a463d5869b84983,,"Many people desire ubiquitous access to their personal computing environments. We present a system in which a user leverages a personal mobile device to establish trust in a public computing device, or kiosk, prior to resuming her environment on the kiosk. We have designed a protocol by which the mobile device determines the identity and integrity of all software loaded on the kiosk, in order to inform the user whether the kiosk is trustworthy. Our system exploits emerging hardware security technologies, namely the Trusted Platform Module and new support in x86 processors for establishing a dynamic root of trust. We have demonstrated the viability of our approach by implementing and evaluating our system on commodity hardware. Through a brief survey, we found that respondents are generally willing to endure a delay in exchange for an increased assurance of data privacy, and that the delay incurred by our unoptimized prototype is close to the range tolerable to the respondents. We have focused on allowing the user to personalize a kiosk by running her own virtual machine there. However, our work is generally applicable to establishing trust on public computing devices before revealing any sensitive information to those devices.",,
How trustworthy is trusted computing?,The problem of data security is made worse because users are working with sensitive information more often.,Search,2003,38,Steven J. Vaughan-Nichols,Computer,,10.1109/MC.2003.1185209,https://doi.org/10.1109/MC.2003.1185209,https://semanticscholar.org/paper/6d731499b4dae0b1cfb7511ad93c43b9b7926f5c,,"One of the biggest issues facing computer technology today is data security. The problem has gotten worse because users are working with sensitive information more often, while the number of threats is growing and hackers are developing new types of attacks. Because of this, many technology experts advocate development of trusted computing (TC) systems that integrate data security into their core operations, rather than implementing it via add-on applications. The paper discusses cryptographic trusted computing and trusted computing initiatives.",,
Trustworthy pervasive computing: the hard security problems,"Pervasive computing environments present unique challenges that require a fundamental reexamination of how to build large-scale, trustworthy, distributed systems.",Search,2004,48,Kumar  Ranganathan,"IEEE Annual Conference on Pervasive Computing and Communications Workshops, 2004. Proceedings of the Second",,10.1109/PERCOMW.2004.1276916,https://doi.org/10.1109/PERCOMW.2004.1276916,https://semanticscholar.org/paper/570ae020f434f5f8f8568e84b4a65b8a2eb1bb68,,"We examine five security problems that are barriers to mainstream pervasive computing. These are: device authentication, privacy, trust management, device assurance, recourse, and availability. We argue that the trust, security, and privacy issues inherent in pervasive computing environments present unique challenges that require a fundamental reexamination of how to build large-scale, trustworthy, distributed systems.",,
Toward trustworthy software systems,"Component technology, rigorous design methods, predictable, provable, legally certifiable system properties, error-free claims are impossible.",Search,2006,137,"Wilhelm  Hasselbring, Ralf H. Reussner",Computer,,10.1109/MC.2006.142,https://doi.org/10.1109/MC.2006.142,https://semanticscholar.org/paper/dc436f4d1591410ade952f8116093539d678c33d,,"Organizations such as Microsoft's Trusted Computing Group and Sun Microsystems' Liberty Alliance are currently leading the debate on ""trustworthy computing."" However, these and other initiatives primarily focus on security, and trustworthiness depends on many other attributes. To address this problem, the University of Oldenburg's TrustSoft Graduate School aims to provide a holistic view of trustworthiness in software - one that considers system construction, evaluation/analysis, and certification - in an interdisciplinary setting. Component technology is the foundation of our research program. The choice of a component architecture greatly influences the resulting software systems' nonfunctional properties. We are developing new methods for the rigorous design of trustworthy software systems with predictable, provable, and ultimately legally certifiable system properties. We are well aware that it is impossible to build completely error-free complex software systems. We therefore complement fault-prevention and fault-removal techniques with fault-tolerance methods that introduce redundancy and diversity into software systems. Quantifiable attributes such as availability, reliability, and performance call for analytical prediction models, which require empirical studies for calibration and validation. To consider the legal aspects of software certification and liability, TrustSoft integrates the disciplines of computer science and computer law.",,
Hardware-security technologies for industrial IoT: TrustZone and security controller,The smart service use case for industrial maintenance scenarios requires a secured execution environment.,Search,2015,38,"Christian M. Lesjak, Daniel M. Hein, Johannes  Winter",IECON 2015 - 41st Annual Conference of the IEEE Industrial Electronics Society,,10.1109/IECON.2015.7392493,https://doi.org/10.1109/IECON.2015.7392493,https://semanticscholar.org/paper/2b9bde72e515da3f12279c59b8510fbac5b70b1d,,"The transition from product-centric to service-centric business models presents a major challenge to industrial automation and manufacturing systems. This transition increases Machine-to-Machine connectivity among industrial devices, industrial controls systems, and factory floor devices. While initiatives like Industry 4.0 or the Industrial Internet Consortium motivate this transition, the emergence of the Internet of Things and Cyber Physical Systems are key enablers. However, automated and autonomous processes require trust in the communication entities and transferred data. Therefore, we study how to secure a smart service use case for industrial maintenance scenarios. In this use case, equipment needs to securely transmit its status information to local and remote recipients. We investigate and compare two security technologies that provide isolation and a secured execution environment: ARM TrustZone and a Security Controller. To compare these technologies we design and implement a device snapshot authentication system. Our results indicate that the TrustZone based approach promises greater flexibility and performance, but only the Security Controller strongly protects against physical attacks. We argue that the best technology actually depends on the use case and propose a hybrid approach that maximizes security for high-security industrial applications. We believe that the insights we gained will help introducing advanced security mechanisms into the future Industrial Internet of Things.",,
Trusting Trusted Hardware: Towards a Formal Model for Programmable Secure Coprocessors,Trusted hardware requires a formal model to prove its security in the face of complex problems and solutions.,Search,1998,48,"Sean W. Smith, Vernon  Austel",USENIX Workshop on Electronic Commerce,,,,https://semanticscholar.org/paper/0d3ca9174d6d64351d1007fba494b73f6ab2ce8d,,"Secure coprocessors provide a foundation for many exciting electronic commerce applications, as previous work [20, 21] has demonstrated. As our recent work [6, 13, 14] has explored, building a high-end secure coprocessor that can be easily programmed and deployed by a wide range of third parties can be an important step toward realizing this promise. But this step requires trusting trusted hardware-and achieving this trust can be difficult in the face of a problem and solution space that can be surprisingly complex and subtle.

Formal methods provide one means to express, verify, and analyze such solutions (and would be required for such a solution to be certified at FIPS 140-1 Level 4). This paper discusses our current efforts to apply these principles to the architecture of our secure coprocessor. We present formal statements of the security goals our architecture needs to provide; we argue for correctness by enumerating the architectural properties from which these goals can be proven; we argue for conciseness by showing how eliminating properties causes the goals to fail; but we discuss how simpler versions of the architecture can satisfy weaker security goals.

We view this work as the beginning of developing formal models to address the trust challenges arising from using trusted hardware for electronic commerce.",,
The challenges and opportunities of artificial intelligence in implementing trustworthy robotics and autonomous systems,"Robots should provide high quality of services, with the four key properties that make it trust, i.e. they must be robust for any health issues, safe for any matters in their surrounding environments, secure for any threats from cyber spaces, and trusted for human-machine interaction.",Search,2020,3,"Hongmei  He, J.  Gray, Angelo  Cangelosi, Q.  Meng, T. M. McGinnity, J.  Mehnen",,,,,https://semanticscholar.org/paper/3e130750bc9d95e12b4194b67137d89da0f87a07,,"Effective Robots and Autonomous Systems (RAS) must be trustworthy. Trust is essential in designing autonomous and semi-autonomous technologies, because “No trust, no use”. RAS should provide high quality of services, with the four key properties that make it trust, i.e. they must be (i) robust for any health issues, (ii) safe for any matters in their surrounding environments, (iii) secure for any threats from cyber spaces, and (iv) trusted for human-machine interaction. We have thoroughly analysed the challenges in implementing the trustworthy RAS in respects of the four properties, and addressed the power of AI in improving the trustworthiness of RAS. While we put our eyes on the beneﬁts that AI brings to human, we should realise the potential risks that could be caused by AI. The new concept of human-centred AI will be the core in implementing the trustworthy RAS. This review could provide a brief reference for the research on AI for trustworthy RAS.",,Review
Opening the software engineering toolbox for the assessment of trustworthy AI,Software engineering and testing practices can be used for the assessment of trustworthy AI.,Search,2020,2,"Mohit Kumar Ahuja, Mohamed-Bachir  Belaid, Pierre  Bernab'e, Mathieu  Collet, Arnaud  Gotlieb, Chhagan  Lal, Dusica  Marijan, Sagar  Sen, Aizaz  Sharif, Helge  Spieker",NeHuAI@ECAI,,,,https://semanticscholar.org/paper/3b0ff6bd000e9c615d024614343f2c1cf12bf124,,"Trustworthiness is a central requirement for the acceptance and success of human-centered artificial intelligence (AI). To deem an AI system as trustworthy, it is crucial to assess its behaviour and characteristics against a gold standard of Trustworthy AI, consisting of guidelines, requirements, or only expectations. While AI systems are highly complex, their implementations are still based on software. The software engineering community has a long-established toolbox for the assessment of software systems, especially in the context of software testing. In this paper, we argue for the application of software engineering and testing practices for the assessment of trustworthy AI. We make the connection between the seven key requirements as defined by the European Commission's AI high-level expert group and established procedures from software engineering and raise questions for future work.",,
M2M-REP: Reputation system for machines in the internet of things,A reputation system can evaluate the trustworthiness of machines by utilizing the feedback collected from users of the machines.,Search,2018,20,"Muhammad Ajmal Azad, Samiran  Bag, Feng  Hao, Khaled  Salah",Comput. Secur.,,10.1016/j.cose.2018.07.014,https://doi.org/10.1016/j.cose.2018.07.014,https://semanticscholar.org/paper/229dee667b60b1916018a77dbf2f97b4c7dbec29,https://eprint.ncl.ac.uk/fulltext.aspx?url=249698/C6A46B2F-7225-4933-9E40-A30D952BFA39.pdf&pub_id=249698,"Abstract In the age of IoT (Internet of Things), Machine-to-Machine (M2M) communication has gained significant popularity over the last few years. M2M communication systems may have a large number of autonomous connected devices that provide services without human involvement. Interacting with compromised, infected and malicious machines can bring damaging consequences in the form of network outage, machine failure, data integrity, and financial loss. Hence, users first need to evaluate the trustworthiness of machines prior to interacting with them. This can be realized by using a reputation system, which evaluates the trustworthiness of machines by utilizing the feedback collected from the users of the machines. The design of a reliable reputation system for the distributed M2M communication network should preserve user privacy and have low computation and communication overheads. To address these challenges, we propose an M2M-REP System (Machine to Machine REPutation), a privacy-preserving reputation system for evaluating the trustworthiness of autonomous machines in the M2M network. The system computes global reputation scores of machines while maintaining privacy of the individual participant score by using secure multi-party computation techniques. The M2M-REP system ensures correctness, security and privacy properties under the malicious adversarial model, and allows public verifiability without relying on a centralized trusted system. We implement a prototype of our system and evaluate the system performance in terms of the computation and bandwidth overhead.",,
Towards trustworthy computing systems: taking microkernels to the next level,Microkernels are the best approach for delivering truly trustworthy computer systems in the foreseeable future.,Search,2007,99,"Gernot  Heiser, Kevin  Elphinstone, Ihor  Kuz, Gerwin  Klein, Stefan M. Petters",OPSR,,10.1145/1278901.1278904,https://doi.org/10.1145/1278901.1278904,https://semanticscholar.org/paper/2b6c94174c6624302b1ace990e39cf6b970afd41,http://unsworks.unsw.edu.au/bitstreams/94f8a2a4-ebc8-4cde-be02-46aad8ac013f/download,"As computer systems become increasingly mission-critical, used in life-critical situations, and relied upon to protect intellectual property, operating-system reliability is becoming an ever growing concern. In the past, mission- and life-critical embedded systems consisted of simple microcontrollers running a small amount of software that could be validated using traditional and informal techniques. However, with the growth of software complexity, traditional techniques for ensuring software reliability have not been able to keep up, leading to an overall degradation of reliability. This paper argues that microkernels are the best approach for delivering truly trustworthy computer systems in the foreseeable future. It presents the NICTA operating-systems research vision, centred around the L4 microkernel and based on four core projects. The seL4 project is designing an improved API for a secure microkernel, L4, verified will produce a full formal verification of the microkernel, Potoroo combines execution-time measurements with static analysis to determine the worst case execution profiles of the kernel, and CAmkES provides a component architecture for building systems that use the microkernel. Through close collaboration with Open Kernel Labs (a NICTA spinoff) the research output of these projects will make its way into products over the next few years.",,
Trusted Hardware: Can It Be Trustworthy?,Trusted hardware development faces challenges including developing methods to measure trust and trustworthy systems.,Search,2007,43,"Cynthia E. Irvine, Karl N. Levitt",2007 44th ACM/IEEE Design Automation Conference,,10.1145/1278480.1278482,https://doi.org/10.1145/1278480.1278482,https://semanticscholar.org/paper/255e2db85ee42e68a7f0f61662b6340e3029af3b,,"Processing and storage of confidential or critical information is an every day occurrence in computing systems. The trustworthiness of computing devices has become an important consideration during hardware design and fabrication. For instance, devices are increasingly required to store confidential information. This includes data such as cryptographic keys, personal information, and the intellectual property (IP) in the device's design. Furthermore, computing systems in critical applications must work as specified. Therefore it is important that hardware be designed and fabricated to be trustworthy. Many potential attacks can be used to exploit a computing device. Physical attacks, that monitor power, timing, electromagnetic radiation, etc. can be used to steal confidential information from the system. A ""malicious"" foundry can perform a number of devious activities including stealing the mask, reverse engineering IP, subverting the hardware through back doors and time bombs, and overproducing counterfeit chips. Design tools can be subverted to insert malicious circuitry, and chip packagers can modify selected devices with their own that provide similar functionality, in addition to underhanded behavior, e.g. stealing information or malfunctioning at critical junctures. The notions of trust and trustworthiness are presented. Although major challenges still confront secure software system development, there has been substantial progress.Techniques that have been useful in the context of software systems are described and their relevance to the hardware domain is discussed. Challenges to trusted hardware development are then explored.",,
Trustworthy Hardware: Trojan Detection and Design-for-Trust Challenges,Globalization of the semiconductor industry and associated supply chains has made integrated circuits increasingly vulnerable to Trojans.,Search,2011,83,"Mark Mohammad Tehranipoor, Hassan  Salmani, Xuehui  Zhang, Michel  Wang, Ramesh  Karri, Jeyavijayan  Rajendran, Kurt  Rosenfeld",Computer,,10.1109/MC.2010.369,https://doi.org/10.1109/MC.2010.369,https://semanticscholar.org/paper/c67bc7b2f10e1893a79719fdc8d4211025d796bd,,Globalization of the semiconductor industry and associated supply chains have made integrated circuits increasingly vulnerable to Trojans. Researchers must expand efforts to verify trust in intellectual property cores and ICs.,,
Hardware assistance for trustworthy systems through 3-D integration,"A separate integrated circuit can provide monitoring, access control, and other useful security functions on commodity integrated circuits.",Search,2010,24,"Jonathan  Valamehr, Mohit  Tiwari, Timothy  Sherwood, Ryan  Kastner, Ted  Huffmire, Cynthia E. Irvine, Timothy E. Levin",ACSAC '10,,10.1145/1920261.1920292,https://doi.org/10.1145/1920261.1920292,https://semanticscholar.org/paper/6f45ab51391f1f0010ad54c06a47abaf208a2396,https://calhoun.nps.edu/bitstream/handle/10945/7171/10paper_hw_assist_3d.pdf%3Bjsessionid%3D575D148A99F3D048450E1809B85E6C66?sequence%3D3,"Hardware resources are abundant; state-of-the-art processors have over one billion transistors. Yet for a variety of reasons, specialized hardware functions for high assurance processing are seldom (i.e., a couple of features per vendor over twenty years) integrated into these commodity processors, despite a small flurry of late (e.g., ARM TrustZone, Intel VT-x/VT-d and AMD-V/AMD-Vi, Intel TXT and AMD SVM, and Intel AES-NI). Furthermore, as chips increase in complexity, trustworthy processing of sensitive information can become increasingly difficult to achieve due to extensive on-chip resource sharing and the lack of corresponding protection mechanisms. In this paper, we introduce a method to enhance the security of commodity integrated circuits, using minor modifications, in conjunction with a separate integrated circuit that can provide monitoring, access control, and other useful security functions. We introduce a new architecture using a separate control plane, stacked using 3D integration, that allows for the function and economics of specialized security mechanisms, not available from a co-processor alone, to be integrated with the underlying commodity computing hardware. We first describe a general methodology to modify the host computation plane by attaching an optional control plane using 3-D integration. In a developed example we show how this approach can increase system trustworthiness, through mitigating the cache-based side channel problem by routing signals from the computation plane through a cache monitor in the 3-D control plane. We show that the overhead of our example application, in terms of area, delay and performance impact, is negligible.",,
Special issue on trustworthy systems and software,The development of trustworthy systems in industry is still very challenging.,Search,2019,1,"Sudipto  Ghosh, Zhenyu  Chen",Software Quality Journal,,10.1007/s11219-019-09450-9,https://doi.org/10.1007/s11219-019-09450-9,https://semanticscholar.org/paper/e9a6ae4fb56aa72e82240d1eb47b0fff40f9add0,https://link.springer.com/content/pdf/10.1007/s11219-019-09450-9.pdf,"Today in many fields and tasks, systems and software play a critical role and can sometimes replace humans to improve efficiency and safety. The world has come to depend on local and wide-area software systems to support essential economic, social, and government services. However, severe consequences such as loss of life and property can be caused by compromised systems and defective software. To make systems and software more robust, reliable, and trustable, and to protect them from various threats such as security intrusion, misuse, and unauthorized access, both academia and industry are seeking novel techniques, tools, and applications to produce dependable and trustworthy systems and their applications in a more cost-effective way. However, in spite of decades of research and practical experience in software testing and the evolution of underlying theories, methods, and tools, the development of trustworthy systems in industry is still very challenging. In this Special Issue on Trustworthy Systems and Software, four papers are presented that investigate issues in diverse areas ranging from defect prediction, API trustworthiness, fault tree analysis, and cross-architecture vulnerability search in firmware. The first paper, “A New Weighted Naive Bayes Method Based on Information Diffusion for Software Defect Prediction,” by Haijin Ji, Song Huang, Yaning Wu, Zhanwei Hui, and Changyou Zheng proposes an approach to identify the most defect-prone modules for allocating limited testing resources. The second paper, “API Trustworthiness: An Ontological Approach for Software Library Adoption,” by Ellis E. Eghan, Sultan S. Alqahtani, Christopher Forbes, and Juergen Rilling proposes an Ontological Trustworthiness Assessment Model to analyze and assess trustworthiness attributes of libraries and APIs in open-source systems, and their impact on the quality and trustworthiness of the project in which they are used. The third paper, “A Minimization Algorithm for Automata Generated Fault Trees with Priority Gates,” by Nidhal Mahmud proposes an approach to reduce the fault tree expressions that are generated from automata representations of failure behaviors. The minimal",,